{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import pandas as pd\n",
    "# with open('1_input_data/config.json', 'r') as file:\n",
    "#         config = json.load(file)\n",
    "# image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])\n",
    "\n",
    "# image_opportunity_df['SatID'] = image_opportunity_df['SatID'].astype(str)\n",
    "# image_opportunity_df['OpportunityStartOffset'] = image_opportunity_df['OpportunityStartOffset'].astype(int)\n",
    "# image_opportunity_df['OpportunityEndOffset'] = image_opportunity_df['OpportunityEndOffset'].astype(int)\n",
    "# image_opportunity_df_copy = image_opportunity_df.copy()\n",
    "# image_opportunity_df_copy['X'] = image_opportunity_df_copy[['OpportunityStartTime','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['OpportunityStartTime']) - pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)\n",
    "# image_opportunity_df_copy['Y'] = image_opportunity_df_copy[['OpportunityEndTime','OpportunityEndOffset']].apply(lambda a: pd.to_datetime(a['OpportunityEndTime']) - pd.DateOffset(seconds=a['OpportunityEndOffset']),axis=1)\n",
    "# base_time_stamp = image_opportunity_df_copy[\"X\"].to_list()[0]\n",
    "\n",
    "# image_opportunity_df['base_time'] = base_time_stamp\n",
    "# image_opportunity_df['req_date'] = image_opportunity_df[['base_time','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)#pd.to_datetime(image_opportunity_df['base_time']) + pd.to_timedelta(image_opportunity_df['OpportunityStartOffset'])\n",
    "# image_opportunity_df[['req_date','OpportunityStartTime','base_time','OpportunityStartOffset']]\n",
    "\n",
    "# image_opportunity_df['x'] = image_opportunity_df[['Priority','StripID']].apply(lambda a: a['Priority'] if a['Priority']<=0 else a['StripID'],axis=1)\n",
    "# image_opportunity_df[['Priority','StripID','x']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- ------------------\n",
      "aext-assistant                    4.0.15\n",
      "aext-assistant-server             4.0.15\n",
      "aext-core                         4.0.15\n",
      "aext-core-server                  4.0.15\n",
      "aext-panels                       4.0.15\n",
      "aext-panels-server                4.0.15\n",
      "aext-share-notebook               4.0.15\n",
      "aext-share-notebook-server        4.0.15\n",
      "aext-shared                       4.0.15\n",
      "aiobotocore                       2.12.3\n",
      "aiohttp                           3.9.5\n",
      "aioitertools                      0.7.1\n",
      "aiosignal                         1.2.0\n",
      "alabaster                         0.7.16\n",
      "altair                            5.0.1\n",
      "anaconda-anon-usage               0.4.4\n",
      "anaconda-catalogs                 0.2.0\n",
      "anaconda-client                   1.12.3\n",
      "anaconda-cloud-auth               0.5.1\n",
      "anaconda-navigator                2.6.0\n",
      "anaconda-project                  0.11.1\n",
      "annotated-types                   0.6.0\n",
      "anyio                             4.2.0\n",
      "appdirs                           1.4.4\n",
      "applaunchservices                 0.3.0\n",
      "appnope                           0.1.3\n",
      "appscript                         1.1.2\n",
      "archspec                          0.2.3\n",
      "argon2-cffi                       21.3.0\n",
      "argon2-cffi-bindings              21.2.0\n",
      "arrow                             1.2.3\n",
      "astroid                           2.14.2\n",
      "astropy                           6.1.0\n",
      "astropy-iers-data                 0.2024.6.3.0.31.14\n",
      "asttokens                         2.0.5\n",
      "async-lru                         2.0.4\n",
      "atomicwrites                      1.4.0\n",
      "attrs                             23.1.0\n",
      "Automat                           20.2.0\n",
      "autopep8                          2.0.4\n",
      "Babel                             2.11.0\n",
      "bcrypt                            3.2.0\n",
      "beautifulsoup4                    4.12.3\n",
      "binaryornot                       0.4.4\n",
      "black                             24.4.2\n",
      "bleach                            4.1.0\n",
      "blinker                           1.6.2\n",
      "bokeh                             3.4.1\n",
      "boltons                           23.0.0\n",
      "botocore                          1.34.69\n",
      "Bottleneck                        1.3.7\n",
      "Brotli                            1.0.9\n",
      "cachetools                        5.3.3\n",
      "certifi                           2024.8.30\n",
      "cffi                              1.16.0\n",
      "chardet                           4.0.0\n",
      "charset-normalizer                2.0.4\n",
      "click                             8.1.7\n",
      "cloudpickle                       2.2.1\n",
      "colorama                          0.4.6\n",
      "colorcet                          3.1.0\n",
      "comm                              0.2.1\n",
      "conda                             24.11.0\n",
      "conda-build                       24.5.1\n",
      "conda-content-trust               0.2.0\n",
      "conda_index                       0.5.0\n",
      "conda-libmamba-solver             24.1.0\n",
      "conda-pack                        0.7.1\n",
      "conda-package-handling            2.3.0\n",
      "conda_package_streaming           0.10.0\n",
      "conda-repo-cli                    1.0.88\n",
      "conda-token                       0.5.0+1.g2209e04\n",
      "constantly                        23.10.4\n",
      "contourpy                         1.2.0\n",
      "cookiecutter                      2.6.0\n",
      "cryptography                      42.0.5\n",
      "cssselect                         1.2.0\n",
      "cycler                            0.11.0\n",
      "cytoolz                           0.12.2\n",
      "dask                              2024.5.0\n",
      "dask-expr                         1.1.0\n",
      "datashader                        0.16.2\n",
      "debugpy                           1.6.7\n",
      "decorator                         5.1.1\n",
      "deepdiff                          8.0.1\n",
      "defusedxml                        0.7.1\n",
      "diff-match-patch                  20200713\n",
      "dill                              0.3.8\n",
      "distributed                       2024.5.0\n",
      "distro                            1.9.0\n",
      "docstring-to-markdown             0.11\n",
      "docutils                          0.18.1\n",
      "entrypoints                       0.4\n",
      "et-xmlfile                        1.1.0\n",
      "executing                         0.8.3\n",
      "fastjsonschema                    2.16.2\n",
      "filelock                          3.13.1\n",
      "flake8                            7.0.0\n",
      "Flask                             3.0.3\n",
      "fonttools                         4.51.0\n",
      "frozendict                        2.4.2\n",
      "frozenlist                        1.4.0\n",
      "fsspec                            2024.3.1\n",
      "gensim                            4.3.2\n",
      "gethighs                          0.1.0\n",
      "gitdb                             4.0.7\n",
      "GitPython                         3.1.37\n",
      "greenlet                          3.0.1\n",
      "h11                               0.14.0\n",
      "h5py                              3.11.0\n",
      "HeapDict                          1.0.1\n",
      "highspy                           1.8.1\n",
      "holoviews                         1.19.0\n",
      "httpcore                          1.0.2\n",
      "httpx                             0.27.0\n",
      "hvplot                            0.10.0\n",
      "hyperlink                         21.0.0\n",
      "idna                              3.7\n",
      "imagecodecs                       2023.1.23\n",
      "imageio                           2.33.1\n",
      "imagesize                         1.4.1\n",
      "imbalanced-learn                  0.12.3\n",
      "importlib-metadata                7.0.1\n",
      "incremental                       22.10.0\n",
      "inflection                        0.5.1\n",
      "iniconfig                         1.1.1\n",
      "intake                            0.7.0\n",
      "intervaltree                      3.1.0\n",
      "ipykernel                         6.28.0\n",
      "ipython                           8.25.0\n",
      "ipython-genutils                  0.2.0\n",
      "ipywidgets                        7.8.1\n",
      "isort                             5.13.2\n",
      "itemadapter                       0.3.0\n",
      "itemloaders                       1.1.0\n",
      "itsdangerous                      2.2.0\n",
      "jaraco.classes                    3.2.1\n",
      "jedi                              0.18.1\n",
      "jellyfish                         1.0.1\n",
      "Jinja2                            3.1.4\n",
      "jmespath                          1.0.1\n",
      "joblib                            1.4.2\n",
      "json5                             0.9.6\n",
      "jsonpatch                         1.33\n",
      "jsonpointer                       2.1\n",
      "jsonschema                        4.19.2\n",
      "jsonschema-specifications         2023.7.1\n",
      "jupyter                           1.0.0\n",
      "jupyter_client                    8.6.0\n",
      "jupyter-console                   6.6.3\n",
      "jupyter_core                      5.7.2\n",
      "jupyter-events                    0.10.0\n",
      "jupyter-lsp                       2.2.0\n",
      "jupyter_server                    2.14.1\n",
      "jupyter_server_terminals          0.4.4\n",
      "jupyterlab                        4.0.11\n",
      "jupyterlab-pygments               0.1.2\n",
      "jupyterlab_server                 2.25.1\n",
      "jupyterlab-widgets                1.0.0\n",
      "keyring                           24.3.1\n",
      "kiwisolver                        1.4.4\n",
      "lazy_loader                       0.4\n",
      "lazy-object-proxy                 1.10.0\n",
      "lckr_jupyterlab_variableinspector 3.1.0\n",
      "libarchive-c                      2.9\n",
      "libmambapy                        1.5.8\n",
      "linkify-it-py                     2.0.0\n",
      "llvmlite                          0.42.0\n",
      "lmdb                              1.4.1\n",
      "locket                            1.0.0\n",
      "lxml                              5.2.1\n",
      "lz4                               4.3.2\n",
      "Markdown                          3.4.1\n",
      "markdown-it-py                    2.2.0\n",
      "MarkupSafe                        2.1.3\n",
      "matplotlib                        3.8.4\n",
      "matplotlib-inline                 0.1.6\n",
      "mccabe                            0.7.0\n",
      "mdit-py-plugins                   0.3.0\n",
      "mdurl                             0.1.0\n",
      "menuinst                          2.1.1\n",
      "mistune                           2.0.4\n",
      "more-itertools                    10.1.0\n",
      "mpmath                            1.3.0\n",
      "msgpack                           1.0.3\n",
      "multidict                         6.0.4\n",
      "multipledispatch                  0.6.0\n",
      "mypy                              1.10.0\n",
      "mypy-extensions                   1.0.0\n",
      "navigator-updater                 0.5.1\n",
      "nbclient                          0.8.0\n",
      "nbconvert                         7.10.0\n",
      "nbformat                          5.9.2\n",
      "nest-asyncio                      1.6.0\n",
      "networkx                          3.2.1\n",
      "nltk                              3.8.1\n",
      "notebook                          7.0.8\n",
      "notebook_shim                     0.2.3\n",
      "numba                             0.59.1\n",
      "numexpr                           2.8.7\n",
      "numpy                             1.26.4\n",
      "numpydoc                          1.7.0\n",
      "openpyxl                          3.1.2\n",
      "orderly-set                       5.2.2\n",
      "overrides                         7.4.0\n",
      "packaging                         23.2\n",
      "panadas                           0.2\n",
      "pandas                            2.2.2\n",
      "pandocfilters                     1.5.0\n",
      "panel                             1.4.4\n",
      "param                             2.1.0\n",
      "parsel                            1.8.1\n",
      "parso                             0.8.3\n",
      "partd                             1.4.1\n",
      "pathspec                          0.10.3\n",
      "patsy                             0.5.6\n",
      "pexpect                           4.8.0\n",
      "pickleshare                       0.7.5\n",
      "pillow                            10.3.0\n",
      "pip                               24.0\n",
      "pkce                              1.0.3\n",
      "pkginfo                           1.10.0\n",
      "platformdirs                      3.10.0\n",
      "plotly                            5.22.0\n",
      "pluggy                            1.0.0\n",
      "ply                               3.11\n",
      "prometheus-client                 0.14.1\n",
      "prompt-toolkit                    3.0.43\n",
      "Protego                           0.1.16\n",
      "protobuf                          3.20.3\n",
      "psutil                            5.9.0\n",
      "ptyprocess                        0.7.0\n",
      "PuLP                              2.9.0\n",
      "pure-eval                         0.2.2\n",
      "py-cpuinfo                        9.0.0\n",
      "pyarrow                           14.0.2\n",
      "pyasn1                            0.4.8\n",
      "pyasn1-modules                    0.2.8\n",
      "pycodestyle                       2.11.1\n",
      "pycosat                           0.6.6\n",
      "pycparser                         2.21\n",
      "pyct                              0.5.0\n",
      "pycurl                            7.45.2\n",
      "pydantic                          2.5.3\n",
      "pydantic_core                     2.14.6\n",
      "pydeck                            0.8.0\n",
      "PyDispatcher                      2.0.5\n",
      "pydocstyle                        6.3.0\n",
      "pyerfa                            2.0.1.4\n",
      "pyflakes                          3.2.0\n",
      "Pygments                          2.15.1\n",
      "PyJWT                             2.8.0\n",
      "pylint                            2.16.2\n",
      "pylint-venv                       3.0.3\n",
      "pyls-spyder                       0.4.0\n",
      "pyobjc-core                       10.1\n",
      "pyobjc-framework-Cocoa            10.1\n",
      "pyobjc-framework-CoreServices     10.1\n",
      "pyobjc-framework-FSEvents         10.1\n",
      "pyodbc                            5.0.1\n",
      "Pyomo                             6.8.1\n",
      "pyOpenSSL                         24.0.0\n",
      "pyparsing                         3.0.9\n",
      "PyQt5                             5.15.10\n",
      "PyQt5-sip                         12.13.0\n",
      "PyQtWebEngine                     5.15.6\n",
      "PySocks                           1.7.1\n",
      "pytest                            7.4.4\n",
      "python-dateutil                   2.9.0.post0\n",
      "python-dotenv                     0.21.0\n",
      "python-json-logger                2.0.7\n",
      "python-lsp-black                  2.0.0\n",
      "python-lsp-jsonrpc                1.1.2\n",
      "python-lsp-server                 1.10.0\n",
      "python-slugify                    5.0.2\n",
      "python-snappy                     0.6.1\n",
      "pytoolconfig                      1.2.6\n",
      "pytz                              2024.1\n",
      "pyviz_comms                       3.0.2\n",
      "pywavelets                        1.5.0\n",
      "PyYAML                            6.0.1\n",
      "pyzmq                             25.1.2\n",
      "QDarkStyle                        3.2.3\n",
      "qstylizer                         0.2.2\n",
      "QtAwesome                         1.2.2\n",
      "qtconsole                         5.5.1\n",
      "QtPy                              2.4.1\n",
      "queuelib                          1.6.2\n",
      "referencing                       0.30.2\n",
      "regex                             2023.10.3\n",
      "requests                          2.32.2\n",
      "requests-file                     1.5.1\n",
      "requests-toolbelt                 1.0.0\n",
      "rfc3339-validator                 0.1.4\n",
      "rfc3986-validator                 0.1.1\n",
      "rich                              13.3.5\n",
      "rope                              1.12.0\n",
      "rpds-py                           0.10.6\n",
      "Rtree                             1.0.1\n",
      "ruamel.yaml                       0.17.21\n",
      "ruamel-yaml-conda                 0.17.21\n",
      "s3fs                              2024.3.1\n",
      "scikit-image                      0.23.2\n",
      "scikit-learn                      1.4.2\n",
      "scipy                             1.13.1\n",
      "Scrapy                            2.11.1\n",
      "seaborn                           0.13.2\n",
      "semver                            3.0.2\n",
      "Send2Trash                        1.8.2\n",
      "service-identity                  18.1.0\n",
      "setuptools                        69.5.1\n",
      "sip                               6.7.12\n",
      "six                               1.16.0\n",
      "smart-open                        5.2.1\n",
      "smmap                             4.0.0\n",
      "sniffio                           1.3.0\n",
      "snowballstemmer                   2.2.0\n",
      "sortedcontainers                  2.4.0\n",
      "soupsieve                         2.5\n",
      "Sphinx                            7.3.7\n",
      "sphinxcontrib-applehelp           1.0.2\n",
      "sphinxcontrib-devhelp             1.0.2\n",
      "sphinxcontrib-htmlhelp            2.0.0\n",
      "sphinxcontrib-jsmath              1.0.1\n",
      "sphinxcontrib-qthelp              1.0.3\n",
      "sphinxcontrib-serializinghtml     1.1.10\n",
      "spyder                            5.5.1\n",
      "spyder-kernels                    2.5.0\n",
      "SQLAlchemy                        2.0.30\n",
      "stack-data                        0.2.0\n",
      "statsmodels                       0.14.2\n",
      "streamlit                         1.32.0\n",
      "sympy                             1.12\n",
      "tables                            3.9.2\n",
      "tabulate                          0.9.0\n",
      "tblib                             1.7.0\n",
      "tenacity                          8.2.2\n",
      "terminado                         0.17.1\n",
      "text-unidecode                    1.3\n",
      "textdistance                      4.2.1\n",
      "threadpoolctl                     2.2.0\n",
      "three-merge                       0.1.1\n",
      "tifffile                          2023.4.12\n",
      "tinycss2                          1.2.1\n",
      "tldextract                        3.2.0\n",
      "toml                              0.10.2\n",
      "tomli                             2.0.1\n",
      "tomlkit                           0.11.1\n",
      "toolz                             0.12.0\n",
      "tornado                           6.4.1\n",
      "tqdm                              4.66.4\n",
      "traitlets                         5.14.3\n",
      "truststore                        0.8.0\n",
      "Twisted                           23.10.0\n",
      "typing_extensions                 4.11.0\n",
      "tzdata                            2023.3\n",
      "uc-micro-py                       1.0.1\n",
      "ujson                             5.10.0\n",
      "unicodedata2                      15.1.0\n",
      "Unidecode                         1.2.0\n",
      "urllib3                           2.2.2\n",
      "w3lib                             2.1.2\n",
      "watchdog                          4.0.1\n",
      "wcwidth                           0.2.5\n",
      "webencodings                      0.5.1\n",
      "websocket-client                  1.8.0\n",
      "Werkzeug                          3.0.3\n",
      "whatthepatch                      1.0.2\n",
      "wheel                             0.43.0\n",
      "widgetsnbextension                3.6.6\n",
      "wrapt                             1.14.1\n",
      "wurlitzer                         3.0.2\n",
      "xarray                            2023.6.0\n",
      "xlwings                           0.31.4\n",
      "xyzservices                       2022.9.0\n",
      "yapf                              0.40.2\n",
      "yarl                              1.9.3\n",
      "zict                              3.0.0\n",
      "zipp                              3.17.0\n",
      "zope.interface                    5.4.0\n",
      "zstandard                         0.22.0\n"
     ]
    }
   ],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_opportunity_df.columns\n",
    "result_dict = {'a':2,'b':66,'c':43}\n",
    "result_dict.update({'d':55,'ww':222})\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_solving\n",
      "Running HiGHS 1.8.1 (git hash: 4a7f24a): Copyright (c) 2024 HiGHS under MIT licence terms\n",
      "Coefficient ranges:\n",
      "  Matrix [1e+00, 1e+09]\n",
      "  Cost   [1e+00, 1e+00]\n",
      "  Bound  [1e+00, 1e+00]\n",
      "  RHS    [9e+04, 1e+09]\n",
      "Presolving model\n",
      "335 rows, 250 cols, 750 nonzeros  0s\n",
      "169 rows, 167 cols, 418 nonzeros  0s\n",
      "77 rows, 75 cols, 188 nonzeros  0s\n",
      "\n",
      "Solving MIP model with:\n",
      "   77 rows\n",
      "   75 cols (37 binary, 0 integer, 0 implied int., 38 continuous)\n",
      "   188 nonzeros\n",
      "MIP-Timing:     0.00061 - starting analytic centre calculation\n",
      "\n",
      "Src: B => Branching; C => Central rounding; F => Feasibility pump; H => Heuristic; L => Sub-MIP;\n",
      "     P => Empty MIP; R => Randomized rounding; S => Solve LP; T => Evaluate node; U => Unbounded;\n",
      "     z => Trivial zero; l => Trivial lower; u => Trivial upper; p => Trivial point\n",
      "\n",
      "        Nodes      |    B&B Tree     |            Objective Bounds              |  Dynamic Constraints |       Work      \n",
      "Src  Proc. InQueue |  Leaves   Expl. | BestBound       BestSol              Gap |   Cuts   InLp Confl. | LpIters     Time\n",
      "\n",
      "         0       0         0   0.00%   -inf            inf                  inf        0      0      0         0     0.0s\n",
      " R       0       0         0   0.00%   -3001279.839525 -34044          8715.88%        0      0      0        76     0.0s\n",
      " C       0       0         0   0.00%   -45431          -45431             0.00%       42     37      0       152     0.0s\n",
      "         1       0         1 100.00%   -45431          -45431             0.00%       42     37      0       152     0.0s\n",
      "\n",
      "Solving report\n",
      "  Status            Optimal\n",
      "  Primal bound      -45431\n",
      "  Dual bound        -45431\n",
      "  Gap               0% (tolerance: 0.01%)\n",
      "  P-D integral      0.0360576352878\n",
      "  Solution status   feasible\n",
      "                    -45431 (objective)\n",
      "                    0 (bound viol.)\n",
      "                    0 (int. viol.)\n",
      "                    0 (row viol.)\n",
      "  Timing            0.00 (total)\n",
      "                    0.00 (presolve)\n",
      "                    0.00 (solve)\n",
      "                    0.00 (postsolve)\n",
      "  Max sub-MIP depth 0\n",
      "  Nodes             1\n",
      "  Repair LPs        0 (0 feasible; 0 iterations)\n",
      "  LP iterations     152 (total)\n",
      "                    0 (strong br.)\n",
      "                    76 (separation)\n",
      "                    0 (heuristics)\n",
      "status= Optimal\n",
      "image_capture_plan_starting\n",
      "===========\n",
      "===========\n",
      "===========\n",
      "len_before_eclipse_transition_divide= 437\n",
      "len_after_eclipse_transition_divide= 517\n",
      "Before_Ambiguous_evnet_transition_divide = 517\n",
      "Empty DataFrame\n",
      "Columns: [SatID, encoded_stripId, start_time, end_time, Eclipse, TW_index, gsID, till_now_max, prev_max, global_TW, Memory_global_TW_index, concat_sat_MGWI, EcStEnd_list, len_EcStEnd_list, new_eclipse, new_start_time, new_end_time]\n",
      "Index: []\n",
      "After_len_of_ambiguous_evnet_transition_divide = 517\n",
      "[1 2 3]\n",
      "len_power_based_memory_based= 372 len_power_based_memory_based= 145\n",
      "final_len_power_based= 517\n",
      "GS_Pass_time_objective\n",
      "only gs check  FF01 1.0 [1.0]\n",
      "only gs check  FF02 1.0 [1.0]\n",
      "only gs check  FF03 1.0 [1.0]\n",
      "Running HiGHS 1.8.1 (git hash: 4a7f24a): Copyright (c) 2024 HiGHS under MIT licence terms\n",
      "Coefficient ranges:\n",
      "  Matrix [8e-01, 1e+06]\n",
      "  Cost   [1e+00, 7e+02]\n",
      "  Bound  [1e+00, 7e+08]\n",
      "  RHS    [1e+00, 2e+08]\n",
      "Presolving model\n",
      "14869 rows, 4981 cols, 42733 nonzeros  0s\n",
      "8647 rows, 4364 cols, 26526 nonzeros  0s\n",
      "8647 rows, 4364 cols, 23724 nonzeros  0s\n",
      "\n",
      "Solving MIP model with:\n",
      "   8647 rows\n",
      "   4364 cols (3155 binary, 0 integer, 0 implied int., 1209 continuous)\n",
      "   23724 nonzeros\n",
      "MIP-Timing:       0.038 - starting analytic centre calculation\n",
      "\n",
      "Src: B => Branching; C => Central rounding; F => Feasibility pump; H => Heuristic; L => Sub-MIP;\n",
      "     P => Empty MIP; R => Randomized rounding; S => Solve LP; T => Evaluate node; U => Unbounded;\n",
      "     z => Trivial zero; l => Trivial lower; u => Trivial upper; p => Trivial point\n",
      "\n",
      "        Nodes      |    B&B Tree     |            Objective Bounds              |  Dynamic Constraints |       Work      \n",
      "Src  Proc. InQueue |  Leaves   Expl. | BestBound       BestSol              Gap |   Cuts   InLp Confl. | LpIters     Time\n",
      "\n",
      "         0       0         0   0.00%   -141207         inf                  inf        0      0      0         0     0.0s\n",
      "         0       0         0   0.00%   -91588          inf                  inf        0      0      3      4347     0.1s\n",
      " C       0       0         0   0.00%   -84980.666667   -35884           136.82%      121     75     19      4680     0.4s\n",
      " L       0       0         0   0.00%   -67781.53365    -45191            49.99%      741    287     19      7294     1.9s\n",
      " L       0       0         0   0.00%   -67781.53365    -46008            47.33%      689    213     19      8173     2.2s\n",
      " T       0       0         0   0.00%   -67781.53365    -47467            42.80%      689    213     19      8804     2.6s\n",
      " L     160     155         1   0.00%   -67781.53365    -47756            41.93%      876    296     19     10333     2.9s\n",
      " L     681     627        17   0.00%   -65383.779777   -48052            36.07%     1129    148    940     26268     7.8s\n",
      " L     808     733        27   0.00%   -65160.465491   -48094            35.49%     1214    182   1559     32462     9.2s\n",
      " L     922     750        65   0.00%   -65153.717872   -48130            35.37%     1242    146   3502     45012    11.5s\n",
      " L    1049     742       126   0.01%   -65152.384539   -48271            34.97%     1394    170   4849     56291    13.8s\n",
      "      1314     791       211   0.01%   -64953.722084   -48271            34.56%     1282    221   8824     87997    19.3s\n",
      "      1682     849       327   0.04%   -64953.722084   -48271            34.56%     1480    224   9400    113141    24.6s\n",
      "\n",
      "Restarting search from the root node\n",
      "Model after restart has 4423 rows, 1555 cols (352 bin., 0 int., 0 impl., 1203 cont.), and 12465 nonzeros\n",
      "\n",
      "      1892       0         0   0.00%   -49662          -48271             2.88%      245      0      0    120293    26.1s\n",
      "      1892       0         0   0.00%   -49662          -48271             2.88%      245    167      2    120907    26.1s\n",
      "      2498       0       289 100.00%   -48271          -48271             0.00%     2391     73   2042    146496    29.0s\n",
      "\n",
      "Solving report\n",
      "  Status            Optimal\n",
      "  Primal bound      -48271\n",
      "  Dual bound        -48271\n",
      "  Gap               0%\n",
      "  P-D integral      10.3346651218\n",
      "  Solution status   feasible\n",
      "                    -48271 (objective)\n",
      "                    0 (bound viol.)\n",
      "                    8.70052329502e-17 (int. viol.)\n",
      "                    0 (row viol.)\n",
      "  Timing            29.02 (total)\n",
      "                    0.00 (presolve)\n",
      "                    0.00 (solve)\n",
      "                    0.00 (postsolve)\n",
      "  Max sub-MIP depth 5\n",
      "  Nodes             2498\n",
      "  Repair LPs        0 (0 feasible; 0 iterations)\n",
      "  LP iterations     146496 (total)\n",
      "                    12820 (strong br.)\n",
      "                    8478 (separation)\n",
      "                    77484 (heuristics)\n",
      "status= Optimal\n",
      "Downlink_plan_starting\n",
      "downlink_schedule_has_some_error\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import os\n",
    "from preprocess_1.preprocess_GSpassSelecion import GSPassPreprocess\n",
    "from model_3.MILP_GSpassSelection_v3 import GSpassSelection\n",
    "from postprocess_4.postprocess_GSpassSelection import GSpasspostprocess\n",
    "\n",
    "from preprocess_1.preprocess_imageAqusuition_test import ImageAquisitionProcess #preprocess_imageAqusuition_test,preprocess_imageAquisition_v3_18112024\n",
    "from model_3.MILP_imageCapture_v3_17112024 import ImageCapturePlan # MILP_imageCapture_v2_16102024,MILP_imageCapture_v2_25102024 # MILP_imageCapture_v2_07112024 #MILP_imageCapture_v3_17112024\n",
    "from postprocess_4.image_capture_postprocess_V3_17112024 import ImagecapturePostProcess # image_capture_postprocess_V3_17112024# image_capture_postprocess_v2_18102024\n",
    "\n",
    "from preprocess_1.preprocess_downlink_WIP import DownlinkingPreProcess\n",
    "from model_3.MILP_downlink import ImageDownlinkPlan\n",
    "from postprocess_4.postprocess_downlink import ImageDownlinkPostProcess\n",
    "\n",
    "from result_interpret import interpret_result\n",
    "from utils import *\n",
    "\n",
    "# script_dir = os.path.abspath( os.path.dirname( __file__ ) )\n",
    "# print(\"script directory: \",script_dir)\n",
    "'''\n",
    "readout is happening after the last image and before entering the eclipse region.\n",
    "Any heating operation will start if the temp reaches around intial tempertaure.\n",
    "Higher number of Global priority is assumed to be Higher prior Important image.\n",
    "if end date of due date is less than 24 hrs from the reference time offset then it is going to assured tasking.\n",
    "Need offset from when scheduling is started. Example if scheduling is  needed from 10:00AM to 11 PM . Then offset is needed from 10:00 AM or 09:59 AM. Due date based assured tasking is the reason.\n",
    "Iniial Camera Memory is needed at the start of the any oppr imaging/gsPass whichever is first. \n",
    "Iniial Readout Memory is needed at the start of the readout oppr.\n",
    "Initial power is needed at start of the opportunity(imaging/gspass).For Now (since power constraint is not there for readout)\n",
    "Iniial thermal value is needed before the start of the oppr imaging/gsPass/readout according to device (for NCCms:readout , for camera detector: Imaging ,For XBT : gs Pass oppr).\n",
    "Eclipse Event should be starting from first oppr either gsPass/Imaging. Readout is happening after the first imaging so i guess not needed at readout.\n",
    "'''\n",
    "'''\n",
    "Need offset from when scheduling is started. Example if scheduling is  needed from 10:00AM to 11 PM . Then offset is needed from 10:00 AM or 09:59 AM.\n",
    "Iniial Memory,power and thermal value is needed at 10:00 AM\n",
    "'''\n",
    "def select_gs_pass_oppr(GS_pass_df,config):\n",
    "\n",
    "    obj_preprocess = GSPassPreprocess(GS_pass_df)\n",
    "    data = obj_preprocess.preprocess()\n",
    "\n",
    "    obj_model = GSpassSelection(data,config)\n",
    "    result,thermal_profile_gsPass = GSpasspostprocess(obj_model,data,config).get_gsPasses()# 21 seconds\n",
    "\n",
    "    try :\n",
    "        result['duration'] = result['end_time'] - result['start_time']\n",
    "        result = result[result['duration']> 0]\n",
    "    except:\n",
    "        print(\"model is not converged or infeasible or not solved\")\n",
    "\n",
    "    return result\n",
    "    \n",
    "\n",
    "def select_img_opprtunity(image_opportunity_df,gs_pass_result_df,eclipse_df_dict,config):\n",
    "\n",
    "    #basic flters\n",
    "    #image_opportunity_df = image_opportunity_df[image_opportunity_df['OpportunityEndOffset']<config['scheduled_Hrs']*3600]\n",
    "    image_opportunity_df = image_opportunity_df[image_opportunity_df['CloudCoverLimit']>image_opportunity_df['CloudCover']]\n",
    "    image_opportunity_df = image_opportunity_df[image_opportunity_df['OffNadirLimit']>image_opportunity_df['OffNadir']]\n",
    "\n",
    "    obj_preprocess = ImageAquisitionProcess(image_opportunity_df,gs_pass_result_df,eclipse_df_dict,config)\n",
    "    data = obj_preprocess.preprocess()\n",
    "    #print(data['cs1j2k2Domainlist__cs1j1k1'])\n",
    "\n",
    "    #++++++++++++++++++++++++++  STEP 0  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    '''\n",
    "    hard code some data\n",
    "    '''\n",
    "    data['camera_memory_capacity__s'] = {s:v for s,v in data['camera_memory_capacity__s'].items() }\n",
    "    data['readout_memory_capacity__s'] = {s:v for s,v in data['readout_memory_capacity__s'].items() }\n",
    "    data['power_capacity__s']  = {s:720000000 for s,v in data['power_capacity__s'].items() }\n",
    "    data['initial_power_value__s']  = {s:v*0.3 for s,v in data['power_capacity__s'].items() }\n",
    "    #++++++++++++++++++++++++++  STEP 1  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    config['objective']['GS_Pass_time'] = True\n",
    "    config['objective']['total_priority'] = False\n",
    "    config['objective']['total_readout_memory'] = False\n",
    "    obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    #Readout Schedule \n",
    "    # data['GS_Pass_time_objective'] = obj_model.prob.objective.value()\n",
    "    # config['objective']['GS_Pass_time'] = False\n",
    "    # config['objective']['total_priority'] = False\n",
    "    # config['objective']['total_readout_memory'] = True\n",
    "    # obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    #++++++++++++++++++++++++++  STEP 2  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    # config['objective']['GS_Pass_time'] = False\n",
    "    # config['objective']['total_priority'] = True\n",
    "    # #config['objective']['total_readout_memory'] = False\n",
    "\n",
    "    # obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    # data['total_priority_objective'] = obj_model.prob.objective.value()\n",
    "    #++++++++++++++++++++++++++  STEP 3  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    # config['objective']['total_priority'] = False\n",
    "    # config['objective']['total_readout_memory'] = True\n",
    "\n",
    "    # obj_model = ImageCapturePlan(data,config)\n",
    "    #++++++++++++++++++++++++++  PostProcess  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    post_obj = ImagecapturePostProcess(obj_model,data)\n",
    "    img_capture_result= post_obj.get_schedule()\n",
    "    #.isnull().sum()\n",
    "    return img_capture_result,data\n",
    "    \n",
    "\n",
    "    #======================================================================================================================================================================================================\n",
    "\n",
    "    pass\n",
    "\n",
    "def get_aps_success_metric(img_capture_result,data):\n",
    "    after_aps_plan_df = img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "    criteria_list = ['total_opprtunities_ratio','GP_ratio','LP_ratio','conflictImg_gsPass']\n",
    "\n",
    "    total_conflict_images_list= [data['success_metric_before']['conflict_images']]\n",
    "    GP_before = data['success_metric_before']['original_Total_GP']\n",
    "    LP_before = data['success_metric_before']['original_Total_LP']\n",
    "    TOppr_before = data['success_metric_before']['total_opportunities'] \n",
    "    before_list = [TOppr_before,GP_before,LP_before,total_conflict_images_list]\n",
    "\n",
    "    GP_after= after_aps_plan_df['mean_global_priority'].sum()\n",
    "    LP_after = after_aps_plan_df['mean_local_priority'].sum()\n",
    "    TOppr_after= after_aps_plan_df['encoded_strip_id'].nunique()\n",
    "    fraction_conflict_images_list = [list(after_aps_plan_df[after_aps_plan_df['encoded_strip_id'].isin(total_conflict_images_list)]['encoded_strip_id'].unique())]\n",
    "    after_list = [TOppr_after,GP_after,LP_after,fraction_conflict_images_list]\n",
    "\n",
    "    APS_success_metric_df = pd.DataFrame({'criteria':criteria_list,'potential_input':before_list,'APS_selected':after_list})\n",
    "    #APS_success_metric_df['percentage'] = APS_success_metric_df['APS_selected'] / APS_success_metric_df['potential_input']\n",
    "    APS_success_metric_df1 = APS_success_metric_df[:-1]\n",
    "    APS_success_metric_df1['percentage'] = APS_success_metric_df1['APS_selected'] / APS_success_metric_df1['potential_input'] * 100\n",
    "    APS_success_metric_df2 = APS_success_metric_df[-1:]\n",
    "\n",
    "    APS_success_metric_df = pd.concat([APS_success_metric_df1,APS_success_metric_df2])\n",
    "\n",
    "    return APS_success_metric_df\n",
    "    \n",
    "\n",
    "def get_downlink_schedule(image_downlink_df,img_capture_result,config):\n",
    "\n",
    "    downlink_operation_list  = ['downlinking_from_camera','downlinking_from_Readout']\n",
    "    img_capture_result_downlink = img_capture_result[img_capture_result['operation'].isin(downlink_operation_list)]\n",
    "    DownlinkingPreProcessObj = DownlinkingPreProcess(image_downlink_df,img_capture_result_downlink,config)\n",
    "    data_downlink = DownlinkingPreProcessObj.preprocess()\n",
    "    \n",
    "    if config['downlink_schedule_OnlyJustsortImgID']:\n",
    "        downlink_result = pd.DataFrame(data_downlink['LP_DD_Priority_imgID'].items(),columns=['ImageID','computed_priority']).\\\n",
    "            sort_values(by='computed_priority',ascending=False)\n",
    "    else:\n",
    "        obj_downlink_model = ImageDownlinkPlan(data_downlink,config)\n",
    "        downlink_result = ImageDownlinkPostProcess(obj_downlink_model,data_downlink).get_schedule()\n",
    "        downlink_result = downlink_result[downlink_result['TileStripNo_downLoad']!=0]\n",
    "\n",
    "    return downlink_result\n",
    "    \n",
    "def schedule():\n",
    "\n",
    "    pass\n",
    "\n",
    "def get_input_files(config):\n",
    "    # GS PASS\n",
    "    GS_pass_df = pd.read_csv(config[\"csv_file_path\"][\"gs_pass_opportunity\"])#APS_gsPasses_TV1#GS_Passes_mock1#GS_Passes_live1#GS_Passes_new (1)\n",
    "    GS_pass_df['SatID'] = GS_pass_df['SatID'].astype(str)\n",
    "    GS_pass_df['AOSOffset'] = GS_pass_df['AOSOffset'].astype(int)\n",
    "    GS_pass_df['LOSOffset'] = GS_pass_df['LOSOffset'].astype(int)\n",
    "\n",
    "    # image Opprtunity\n",
    "    image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])#Imaging_mock1#APS_imagingOpportunities_TV1#Imaging_live#Imaging_new (1)\n",
    "    # change made priority ulta\n",
    "    #image_opportunity_df['Priority'] = 1/image_opportunity_df['Priority']\n",
    "    \n",
    "    image_opportunity_df['SatID'] = image_opportunity_df['SatID'].astype(str)\n",
    "    image_opportunity_df['OpportunityStartOffset'] = image_opportunity_df['OpportunityStartOffset'].astype(int)\n",
    "    image_opportunity_df['OpportunityEndOffset'] = image_opportunity_df['OpportunityEndOffset'].astype(int)\n",
    "    image_opportunity_df_copy = image_opportunity_df.copy()\n",
    "    image_opportunity_df_copy['X'] = image_opportunity_df_copy[['OpportunityStartTime','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['OpportunityStartTime']) - pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)\n",
    "    image_opportunity_df_copy['Y'] = image_opportunity_df_copy[['OpportunityEndTime','OpportunityEndOffset']].apply(lambda a: pd.to_datetime(a['OpportunityEndTime']) - pd.DateOffset(seconds=a['OpportunityEndOffset']),axis=1)\n",
    "    base_time_stamp = image_opportunity_df_copy[\"X\"].to_list()[0]\n",
    "    config['base_time_stamp_downlink'] = base_time_stamp\n",
    "\n",
    "    #image Downlink\n",
    "    image_downlink_df = pd.read_csv(config[\"csv_file_path\"][\"image_downlink_file\"])\n",
    "    image_downlink_df['assured_downlink_flag'] = [0,0] +[0]*(len(image_downlink_df)-2)\n",
    "    image_downlink_df['delivery_type'] = 'standard_delivery' # expedited_delivery,super_expedited_delivery\n",
    "    union_list_of_sat = list(set(image_opportunity_df['SatID']).union(set(GS_pass_df['SatID'])).union(set(image_downlink_df['SatID'])))\n",
    "    hrs = config['scheduled_Hrs']\n",
    "\n",
    "    # get dummy eclipse data close to reality\n",
    "    #eclipse_df = pd.DataFrame()\n",
    "    #for sat in satellite_list:\n",
    "        #this_eclipse_df = eclipse_event_df[eclipse_event_df['SatID']==sat]\n",
    "        #that_eclipse_df = get_eclipse_data(this_eclipse_df,config)\n",
    "        #eclipse_df = pd.concat([that_eclipse_df,eclipse_df])\n",
    "        \n",
    "    min_time_index= min([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "    max_time_index= max([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "\n",
    "    hrs = (max_time_index - min_time_index)/3600\n",
    "    hrs = math.ceil(hrs)\n",
    "    while True:\n",
    "        hrs += 1\n",
    "        if hrs % 1.5==0:\n",
    "            break\n",
    "\n",
    "\n",
    "    in_orbit_eclipse_event = [1 for i in range(int(1.5*3600*0.6))] + [0 for i in range(int(1.5*3600*0.4))] #\n",
    "    eclipse_df  = pd.DataFrame({'time_index': [i for i in range(min_time_index,min_time_index+hrs*3600)] ,\"eclipse\" : in_orbit_eclipse_event*int(hrs/1.5)})\n",
    "    eclipse_df['SatID']= [union_list_of_sat] *len(eclipse_df)\n",
    "    eclipse_df = eclipse_df.explode('SatID')\n",
    "    eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "\n",
    "    #eclipse_df = pd.DataFrame()\n",
    "    #for sat in satellite_list:\n",
    "        #this_eclipse_df = eclipse_event_df[eclipse_event_df['SatID']==sat]\n",
    "        #that_eclipse_df = get_eclipse_data(this_eclipse_df,config)\n",
    "        #eclipse_df = pd.concat([that_eclipse_df,eclipse_df])\n",
    "   #eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "\n",
    "    \n",
    "    # get dummy data for assured tasking\n",
    "    image_opportunity_df['encoded_stripId'] =   image_opportunity_df['StripID'].astype(str)+ '_' + image_opportunity_df['AoiID'].astype(str)\n",
    "    total_capture_list = list(image_opportunity_df['encoded_stripId'].unique())\n",
    "    no_of_list = len(total_capture_list)\n",
    "    assured_capture_df = pd.DataFrame({'encoded_stripId':total_capture_list,'assured_task':[0,0]+[0]*(no_of_list-2)})\n",
    "    image_opportunity_df = pd.merge(image_opportunity_df,assured_capture_df,on='encoded_stripId',how='left')\n",
    "    image_opportunity_df = image_opportunity_df.drop(columns=['encoded_stripId'])\n",
    "\n",
    "    # further processing eclipse data to align with gs pass where entire gs pass is assumed to be in eclipse region\n",
    "    gsPassInput_df_copy = pd.read_csv(config[\"csv_file_path\"][\"gs_pass_opportunity\"])\n",
    "    gsPassInput_df_copy['SatID'] = gsPassInput_df_copy['SatID'].astype(str)\n",
    "    gsPassInput_df_copy['AOSOffset'] = gsPassInput_df_copy['AOSOffset'].astype(int)\n",
    "    gsPassInput_df_copy['LOSOffset'] = gsPassInput_df_copy['LOSOffset'].astype(int)\n",
    "    gsPassInput_df_copy['list'] =  gsPassInput_df_copy[['AOSOffset','LOSOffset']].apply(lambda a : [i for i in range(a['AOSOffset'],a['LOSOffset']+1)],axis =1 )\n",
    "\n",
    "    gsPassInput_df_copy1 = gsPassInput_df_copy[['SatID','list']]\n",
    "    gsPassInput_df_copy1 = gsPassInput_df_copy1.explode('list')\n",
    "    gsPassInput_df_grouped_copy1 = gsPassInput_df_copy1.groupby('SatID').agg(time_index_list = ('list',list)).reset_index()\n",
    "    gsPasstimeIndexList__s = dict(zip(gsPassInput_df_grouped_copy1['SatID'],gsPassInput_df_grouped_copy1['time_index_list']))\n",
    "    for k,v in eclipse_df_dict.items():\n",
    "        if k in gsPasstimeIndexList__s.keys():\n",
    "            this_time_index_list = gsPasstimeIndexList__s[k]\n",
    "            v.loc[v[\"time_index\"].isin(this_time_index_list), \"eclipse\"] = 1\n",
    "            eclipse_df_dict[k] = v\n",
    "\n",
    "    return {\n",
    "            'GS_pass_df':GS_pass_df,\\\n",
    "            'image_opportunity_df':image_opportunity_df,\\\n",
    "            'image_downlink_df':image_downlink_df,\\\n",
    "            \"eclipse_df_dict\": eclipse_df_dict,\n",
    "            \"config\":config\n",
    "            }\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Open and read the JSON file\n",
    "    with open('1_input_data/config.json', 'r') as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "    # if memory constraint False then thermal_constraint is also False\n",
    "        config['constraints']['thermal_constraint_readout'] = config['constraints']['memory_constrant'] and config['constraints']['thermal_constraint_readout']\n",
    "        config['constraints']['thermal_constraint_imaging'] = config['constraints']['memory_constrant'] and config['constraints']['thermal_constraint_imaging']\n",
    "\n",
    "    #======================================================================================================================================================================================================\n",
    "    # read_input\n",
    "    input_dict = get_input_files(config)\n",
    "    config = input_dict['config']\n",
    "    #======================================================================================================================================================================================================\n",
    "    #gs pass_selection\n",
    "    gs_pass_result_df = select_gs_pass_oppr(input_dict['GS_pass_df'],config)\n",
    "    gs_pass_result_df['Eclipse'] = 1 ## dummy\n",
    "    gs_pass_result_df['duration'] = gs_pass_result_df['end_time'] - gs_pass_result_df['start_time']\n",
    "    gs_pass_result_df = gs_pass_result_df[gs_pass_result_df['duration']> 0]\n",
    "    interpret_gs_pass_result_df_copy = gs_pass_result_df.copy()# this not the gsPass result as it is to be get filtered after due to other factors in image capture plan.It is just to get require info in interpret result.\n",
    "\n",
    "    print(\"image_capture_plan_starting\")\n",
    "    #======================================================================================================================================================================================================\n",
    "    #image_selection\n",
    "    img_capture_result,capture_plan_data_input= select_img_opprtunity(input_dict['image_opportunity_df'],gs_pass_result_df,input_dict['eclipse_df_dict'],config)\n",
    "    img_capture_result['base_time'] = config['base_time_stamp_downlink']\n",
    "    #img_capture_result = img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "    #readout_result = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "    interpret_img_capture_resul_copy = img_capture_result.copy()\n",
    "    #======================================================================================================================================================================================================\n",
    "    # get APS success metrics \n",
    "    APS_success_metric_df = get_aps_success_metric(img_capture_result,capture_plan_data_input)\n",
    "    #======================================================================================================================================================================================================\n",
    "    print(\"Downlink_plan_starting\")\n",
    "    try:\n",
    "        print(dfd)\n",
    "        downlink_result = get_downlink_schedule(input_dict['image_downlink_df'],img_capture_result,config)\n",
    "    except:\n",
    "        print(\"downlink_schedule_has_some_error\")\n",
    "        downlink_result = pd.DataFrame()\n",
    "    downlink_result['base_time'] = config['base_time_stamp_downlink']\n",
    "    #======================================================================================================================================================================================================\n",
    "    #img_capture_result[img_capture_result['download_from_']]\n",
    "    gs_pass_result_df.to_csv(\"5_output_data/gs_pass_result_df.csv\",index=None)\n",
    "    img_capture_result.to_csv(\"5_output_data/img_capture_schedule.csv\",index=None)\n",
    "    APS_success_metric_df.to_csv(\"5_output_data/APS_success_metric.csv\",index = None)\n",
    "    downlink_result.to_csv(\"5_output_data/downlink_result.csv\",index = None)\n",
    "\n",
    "    interpret_image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])\n",
    "    interpret_result_dict = interpret_result(interpret_image_opportunity_df,interpret_gs_pass_result_df_copy,interpret_img_capture_resul_copy,config)\n",
    "    for k,v in interpret_result_dict.items():\n",
    "        v['base_time'] = config['base_time_stamp_downlink']\n",
    "        v.to_csv(\"5_output_data/\"+k+\".csv\",index = None)\n",
    "\n",
    "    \n",
    "    only_img_capture_result = img_capture_result[img_capture_result['operation']=='Imaging'][['SatID','start_time','end_time','AoiID','StripID','base_time']]\n",
    "    only_img_capture_result['start_time'] = only_img_capture_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "    only_img_capture_result['end_time'] = only_img_capture_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "    only_readout_result = img_capture_result[img_capture_result['operation']=='Readout'][['SatID','start_time','end_time','base_time']]\n",
    "    only_readout_result['start_time'] = only_readout_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "    only_readout_result['end_time'] = only_readout_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "    result_dict = {\"only_readout_result\":only_readout_result,\\\n",
    "                  \"only_img_capture_result\":only_img_capture_result}\n",
    "    result_dict.update(interpret_result_dict)\n",
    "\n",
    "    #print(only_img_capture_result,only_readout_result,downlink_result)\n",
    "#config['constraints'] = ['Thermal_constraints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture_plan_data_input['']\n",
    "#-48283.5824309\n",
    "#-48271\n",
    "#result_dict['interpret_selected_oppr_conflict_comparision_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_result_dict['interpret_selected_oppr_conflict_comparision_df']#['conflic_strip_flag_named'].nunique()##['interpret_selected_oppr_conflict_comparision_df']#['interpret_extracted_raw_file_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downlink_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = 'extracted_raw_file_df', 'selected_oppr_conflict_comparision_df', 'KPI_df'\n",
    "df111 = interpret_result_dict['extracted_raw_file_df']#.columns\n",
    "interpret_result_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = img_capture_result[img_capture_result['operation']=='Imaging']#['StripID']#.nunique()\n",
    "Z = img_capture_result[img_capture_result['operation']=='downlinking_from_Readout']\n",
    "Z['duration'] = Z['end_time']- Z['start_time']\n",
    "#Y[Y['StripID']=='']\n",
    "\n",
    "#Y[Y['encoded_strip_id']=='Order 1 - Strip 0_Area 0']\n",
    "Y['StripID'].nunique(),len(Y),len(Z),Z['duration'].sum(),gs_pass_result_df['duration'].sum(),len(gs_pass_result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['SatID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI = Y[Y['SatID']=='FF03']\n",
    "RZO = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "CR = RZO[RZO['SatID']=='FF03']\n",
    "pd.concat([CI,CR]).sort_values(by='start_time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Order 1 - Strip 0_Area 0'\n",
    "RZO = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "RZO[RZO['SatID']=='FF01']\n",
    "RZO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RZ = capture_plan_data_input['dedicated_readout_df']\n",
    "len(RZ[RZ['SatID']=='FF01'].sort_values(by='start_time')),len(RZ[RZ['SatID']=='FF02'].sort_values(by='start_time')),len(RZ[RZ['SatID']=='FF03'].sort_values(by='start_time'))\n",
    "RZ[RZ['SatID']=='FF01'].sort_values(by='start_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_capture_result['operation'].unique()\n",
    "\n",
    "[ item for item in capture_plan_data_input['Memory_NoimageGs_TW_list'] if item[2]=='FF01']\n",
    "#capture_plan_data_input['dedicatedReadoutTWlist__concat_sat_memoryTWindex']['FF01_136.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['active_assured_strip_id_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_eclipse_data.csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eclipse_df[eclipse_df['eclipse']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse_df.sort_values(by='time_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SatID,start_time,end_time,eclipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['GS_pass_df', 'image_opportunity_df', 'image_downlink_df', 'eclipse_df_dict', 'config']\n",
    "#input_dict['eclipse_df_dict']['FF02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['readout_memory_capacity__s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['imgery_sat_id_list']#.keys()\n",
    "[s+'_'+str(n) for s in capture_plan_data_input['imgery_sat_id_list']+capture_plan_data_input['only_gs_sat_id_list'] \\\n",
    " if s in capture_plan_data_input['dedicatedReadoutTWIndex__sat'].keys() for n in capture_plan_data_input['dedicatedReadoutTWIndex__sat'][s]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "\n",
    "#eclipse_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['active_assured_strip_id_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['assured_tasking_based_on_input_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['cs1j2k2Domainlist__cs1j1k1']['FF01_Order 1 - Strip 0_Area 0_1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['GS_Pass_time_objective'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(img_capture_result[img_capture_result['operation']=='Imaging'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
