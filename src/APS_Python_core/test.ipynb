{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import pandas as pd\n",
    "# with open('1_input_data/config.json', 'r') as file:\n",
    "#         config = json.load(file)\n",
    "# image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])\n",
    "\n",
    "# image_opportunity_df['SatID'] = image_opportunity_df['SatID'].astype(str)\n",
    "# image_opportunity_df['OpportunityStartOffset'] = image_opportunity_df['OpportunityStartOffset'].astype(int)\n",
    "# image_opportunity_df['OpportunityEndOffset'] = image_opportunity_df['OpportunityEndOffset'].astype(int)\n",
    "# image_opportunity_df_copy = image_opportunity_df.copy()\n",
    "# image_opportunity_df_copy['X'] = image_opportunity_df_copy[['OpportunityStartTime','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['OpportunityStartTime']) - pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)\n",
    "# image_opportunity_df_copy['Y'] = image_opportunity_df_copy[['OpportunityEndTime','OpportunityEndOffset']].apply(lambda a: pd.to_datetime(a['OpportunityEndTime']) - pd.DateOffset(seconds=a['OpportunityEndOffset']),axis=1)\n",
    "# base_time_stamp = image_opportunity_df_copy[\"X\"].to_list()[0]\n",
    "\n",
    "# image_opportunity_df['base_time'] = base_time_stamp\n",
    "# image_opportunity_df['req_date'] = image_opportunity_df[['base_time','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)#pd.to_datetime(image_opportunity_df['base_time']) + pd.to_timedelta(image_opportunity_df['OpportunityStartOffset'])\n",
    "# image_opportunity_df[['req_date','OpportunityStartTime','base_time','OpportunityStartOffset']]\n",
    "\n",
    "# image_opportunity_df['x'] = image_opportunity_df[['Priority','StripID']].apply(lambda a: a['Priority'] if a['Priority']<=0 else a['StripID'],axis=1)\n",
    "# image_opportunity_df[['Priority','StripID','x']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/robin/Documents/Schedule_plan/git_APS_Python_core_develop/APS_Python_core/src/APS_Python_core', '/opt/anaconda3/lib/python312.zip', '/opt/anaconda3/lib/python3.12', '/opt/anaconda3/lib/python3.12/lib-dynload', '', '/opt/anaconda3/lib/python3.12/site-packages', '/opt/anaconda3/lib/python3.12/site-packages/aeosa']\n",
      "['/Users/robin/Documents/Schedule_plan/git_APS_Python_core_develop/APS_Python_core/src/APS_Python_core', '/opt/anaconda3/lib/python312.zip', '/opt/anaconda3/lib/python3.12', '/opt/anaconda3/lib/python3.12/lib-dynload', '', '/opt/anaconda3/lib/python3.12/site-packages', '/opt/anaconda3/lib/python3.12/site-packages/aeosa', '../']\n"
     ]
    }
   ],
   "source": [
    "#!pip list\n",
    "import os \n",
    "os.getcwd()\n",
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': 66, 'c': 43, 'd': 55, 'ww': 222}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_opportunity_df.columns\n",
    "result_dict = {'a':2,'b':66,'c':43}\n",
    "result_dict.update({'d':55,'ww':222})\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "# from APS_Python_core.preprocess_1.preprocess_GSpassSelecion import GSPassPreprocess\n",
    "# from model_3.MILP_GSpassSelection_v3 import GSpassSelection\n",
    "# from postprocess_4.postprocess_GSpassSelection import GSpasspostprocess\n",
    "\n",
    "# from preprocess_1.preprocess_imageAqusuition_test import ImageAquisitionProcess #preprocess_imageAqusuition_test,preprocess_imageAquisition_v3_18112024\n",
    "# from model_3.MILP_imageCapture_v3_17112024_copy import ImageCapturePlan # MILP_imageCapture_v2_16102024,MILP_imageCapture_v2_25102024 # MILP_imageCapture_v2_07112024 #MILP_imageCapture_v3_17112024\n",
    "# from postprocess_4.image_capture_postprocess_V3_17112024 import ImagecapturePostProcess # image_capture_postprocess_V3_17112024# image_capture_postprocess_v2_18102024\n",
    "\n",
    "# from preprocess_1.preprocess_downlink_WIP import DownlinkingPreProcess\n",
    "# from model_3.MILP_downlink import ImageDownlinkPlan\n",
    "# from postprocess_4.postprocess_downlink import ImageDownlinkPostProcess\n",
    "\n",
    "# from result_interpret import interpret_result\n",
    "# from utils import *\n",
    "\n",
    "from APS_Python_core.preprocess_1.preprocess_GSpassSelecion import GSPassPreprocess\n",
    "from APS_Python_core.model_3.MILP_GSpassSelection_v3 import GSpassSelection\n",
    "from APS_Python_core.postprocess_4.postprocess_GSpassSelection import GSpasspostprocess\n",
    "\n",
    "from APS_Python_core.preprocess_1.preprocess_imageAqusuition_test import ImageAquisitionProcess #preprocess_imageAqusuition_test,preprocess_imageAquisition_v3_18112024\n",
    "from APS_Python_core.model_3.MILP_imageCapture_v3_17112024 import ImageCapturePlan # MILP_imageCapture_v3_17112024_copy#MILP_imageCapture_v2_16102024,MILP_imageCapture_v2_25102024 # MILP_imageCapture_v2_07112024 #MILP_imageCapture_v3_17112024# \n",
    "from APS_Python_core.postprocess_4.image_capture_postprocess_V3_17112024 import ImagecapturePostProcess # image_capture_postprocess_V3_17112024# image_capture_postprocess_v2_18102024\n",
    "\n",
    "from APS_Python_core.preprocess_1.preprocess_downlink_WIP import DownlinkingPreProcess\n",
    "from APS_Python_core.model_3.MILP_downlink import ImageDownlinkPlan\n",
    "from APS_Python_core.postprocess_4.postprocess_downlink import ImageDownlinkPostProcess\n",
    "\n",
    "from APS_Python_core.result_interpret import interpret_result\n",
    "from APS_Python_core.utils import *\n",
    "\n",
    "# script_dir = os.path.abspath( os.path.dirname( __file__ ) )\n",
    "# print(\"script directory: \",script_dir)\n",
    "'''\n",
    "readout is happening after the last image and before entering the eclipse region.\n",
    "Any heating operation will start if the temp reaches around intial tempertaure.\n",
    "Higher number of Global priority is assumed to be Higher prior Important image.\n",
    "if end date of due date is less than 24 hrs from the reference time offset then it is going to assured tasking.\n",
    "Need offset from when scheduling is started. Example if scheduling is  needed from 10:00AM to 11 PM . Then offset is needed from 10:00 AM or 09:59 AM. Due date based assured tasking is the reason.\n",
    "Iniial Camera Memory is needed at the start of the any oppr imaging/gsPass whichever is first. \n",
    "Iniial Readout Memory is needed at the start of the readout oppr.\n",
    "Initial power is needed at start of the opportunity(imaging/gspass).For Now (since power constraint is not there for readout)\n",
    "Iniial thermal value is needed before the start of the oppr imaging/gsPass/readout according to device (for NCCms:readout , for camera detector: Imaging ,For XBT : gs Pass oppr).\n",
    "Eclipse Event should be starting from first oppr either gsPass/Imaging. Readout is happening after the first imaging so i guess not needed at readout.\n",
    "'''\n",
    "'''\n",
    "Need offset from when scheduling is started. Example if scheduling is  needed from 10:00AM to 11 PM . Then offset is needed from 10:00 AM or 09:59 AM.\n",
    "Iniial Memory,power and thermal value is needed at 10:00 AM\n",
    "'''\n",
    "def select_gs_pass_oppr(GS_pass_df,config):\n",
    "\n",
    "    obj_preprocess = GSPassPreprocess(GS_pass_df)\n",
    "    data = obj_preprocess.preprocess()\n",
    "    #print(data['SG1K1G2K2_pair']['domain_of_csgk'])\n",
    "\n",
    "    obj_model = GSpassSelection(data,config)\n",
    "    result,thermal_profile_gsPass = GSpasspostprocess(obj_model,data,config).get_gsPasses()# 21 seconds\n",
    "\n",
    "    try :\n",
    "        result['duration'] = result['end_time'] - result['start_time']\n",
    "        result = result[result['duration']> 0]\n",
    "    except:\n",
    "        print(\"model is not converged or infeasible or not solved\")\n",
    "\n",
    "    return result\n",
    "    \n",
    "\n",
    "def select_img_opprtunity(image_opportunity_df,gs_pass_result_df,eclipse_df_dict,config):\n",
    "\n",
    "    #basic flters\n",
    "    #image_opportunity_df = image_opportunity_df[image_opportunity_df['OpportunityEndOffset']<config['scheduled_Hrs']*3600]\n",
    "    image_opportunity_df = image_opportunity_df[image_opportunity_df['CloudCoverLimit']>image_opportunity_df['CloudCover']]\n",
    "    image_opportunity_df = image_opportunity_df[image_opportunity_df['OffNadirLimit']>image_opportunity_df['OffNadir']]\n",
    "\n",
    "    obj_preprocess = ImageAquisitionProcess(image_opportunity_df,gs_pass_result_df,eclipse_df_dict,config)\n",
    "    data = obj_preprocess.preprocess()\n",
    "    #print(data['cs1j2k2Domainlist__cs1j1k1'])\n",
    "\n",
    "    #++++++++++++++++++++++++++  STEP 0  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    '''\n",
    "    hard code some data\n",
    "    '''\n",
    "    data['camera_memory_capacity__s'] = {s:v for s,v in data['camera_memory_capacity__s'].items() }\n",
    "    data['readout_memory_capacity__s'] = {s:v for s,v in data['readout_memory_capacity__s'].items() }\n",
    "    data['power_capacity__s']  = {s:720000000 for s,v in data['power_capacity__s'].items() }\n",
    "    data['initial_power_value__s']  = {s:v*0.3 for s,v in data['power_capacity__s'].items() }\n",
    "    #++++++++++++++++++++++++++  STEP 1  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    config['objective']['GS_Pass_and_Imaging'] = True\n",
    "    config['objective']['total_readout_memory'] = False\n",
    "    obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    #Readout Schedule \n",
    "    data['GS_Pass_time_objective'] = obj_model.prob.objective.value()\n",
    "    config['objective']['GS_Pass_and_Imaging'] = False\n",
    "    config['objective']['total_readout_memory'] = True\n",
    "    obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    #++++++++++++++++++++++++++  PostProcess  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    post_obj = ImagecapturePostProcess(obj_model,data)\n",
    "    img_capture_result= post_obj.get_schedule()\n",
    "    #.isnull().sum()\n",
    "    return img_capture_result,data\n",
    "    #======================================================================================================================================================================================================\n",
    "\n",
    "    pass\n",
    "\n",
    "def get_aps_success_metric(img_capture_result,data):\n",
    "    after_aps_plan_df = img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "    criteria_list = ['total_opprtunities_ratio','GP_ratio','LP_ratio','conflictImg_gsPass']\n",
    "\n",
    "    total_conflict_images_list= [data['success_metric_before']['conflict_images']]\n",
    "    GP_before = data['success_metric_before']['original_Total_GP']\n",
    "    LP_before = data['success_metric_before']['original_Total_LP']\n",
    "    TOppr_before = data['success_metric_before']['total_opportunities'] \n",
    "    before_list = [TOppr_before,GP_before,LP_before,total_conflict_images_list]\n",
    "\n",
    "    GP_after= after_aps_plan_df['mean_global_priority'].sum()\n",
    "    LP_after = after_aps_plan_df['mean_local_priority'].sum()\n",
    "    TOppr_after= after_aps_plan_df['encoded_strip_id'].nunique()\n",
    "    fraction_conflict_images_list = [list(after_aps_plan_df[after_aps_plan_df['encoded_strip_id'].isin(total_conflict_images_list)]['encoded_strip_id'].unique())]\n",
    "    after_list = [TOppr_after,GP_after,LP_after,fraction_conflict_images_list]\n",
    "\n",
    "    APS_success_metric_df = pd.DataFrame({'criteria':criteria_list,'potential_input':before_list,'APS_selected':after_list})\n",
    "    #APS_success_metric_df['percentage'] = APS_success_metric_df['APS_selected'] / APS_success_metric_df['potential_input']\n",
    "    APS_success_metric_df1 = APS_success_metric_df[:-1]\n",
    "    APS_success_metric_df1['percentage'] = APS_success_metric_df1['APS_selected'] / APS_success_metric_df1['potential_input'] * 100\n",
    "    APS_success_metric_df2 = APS_success_metric_df[-1:]\n",
    "\n",
    "    APS_success_metric_df = pd.concat([APS_success_metric_df1,APS_success_metric_df2])\n",
    "\n",
    "    return APS_success_metric_df\n",
    "    \n",
    "\n",
    "def get_downlink_schedule(image_downlink_df,img_capture_result,config):\n",
    "\n",
    "    downlink_operation_list  = ['downlinking_from_camera','downlinking_from_Readout']\n",
    "    img_capture_result_downlink = img_capture_result[img_capture_result['operation'].isin(downlink_operation_list)]\n",
    "    DownlinkingPreProcessObj = DownlinkingPreProcess(image_downlink_df,img_capture_result_downlink,config)\n",
    "    data_downlink = DownlinkingPreProcessObj.preprocess()\n",
    "    \n",
    "    if config['downlink_schedule_OnlyJustsortImgID']:\n",
    "        downlink_result = pd.DataFrame(data_downlink['LP_DD_Priority_imgID'].items(),columns=['ImageID','computed_priority']).\\\n",
    "            sort_values(by='computed_priority',ascending=False)\n",
    "    else:\n",
    "        obj_downlink_model = ImageDownlinkPlan(data_downlink,config)\n",
    "        downlink_result = ImageDownlinkPostProcess(obj_downlink_model,data_downlink).get_schedule()\n",
    "        downlink_result = downlink_result[downlink_result['TileStripNo_downLoad']!=0]\n",
    "\n",
    "    return downlink_result\n",
    "    \n",
    "def schedule():\n",
    "\n",
    "    pass\n",
    "\n",
    "def get_input_files(config,GS_pass_df,image_opportunity_df,image_downlink_df):\n",
    "    # GS PASS\n",
    "    #GS_pass_df = pd.read_csv(config[\"csv_file_path\"][\"gs_pass_opportunity\"])#APS_gsPasses_TV1#GS_Passes_mock1#GS_Passes_live1#GS_Passes_new (1)\n",
    "    \n",
    "    #GS_pass_df = pd.read_csv(\"1_input_data/GS_Passes_new (1).csv\")\n",
    "    GS_pass_df_original = GS_pass_df.copy()\n",
    "    GS_pass_df['SatID'] = GS_pass_df['SatID'].astype(str)\n",
    "    GS_pass_df['AOSOffset'] = GS_pass_df['AOSOffset'].astype(int)\n",
    "    GS_pass_df['LOSOffset'] = GS_pass_df['LOSOffset'].astype(int)\n",
    "\n",
    "    # image Opprtunity\n",
    "    #image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])#Imaging_mock1#APS_imagingOpportunities_TV1#Imaging_live#Imaging_new (1)\n",
    "    # change made priority ulta\n",
    "    #image_opportunity_df['Priority'] = 1/image_opportunity_df['Priority']\n",
    "    \n",
    "    image_opportunity_df['SatID'] = image_opportunity_df['SatID'].astype(str)\n",
    "    image_opportunity_df['OpportunityStartOffset'] = image_opportunity_df['OpportunityStartOffset'].astype(int)\n",
    "    image_opportunity_df['OpportunityEndOffset'] = image_opportunity_df['OpportunityEndOffset'].astype(int)\n",
    "    image_opportunity_df_copy = image_opportunity_df.copy()\n",
    "    image_opportunity_df_copy['X'] = image_opportunity_df_copy[['OpportunityStartTime','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['OpportunityStartTime']) - pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)\n",
    "    image_opportunity_df_copy['Y'] = image_opportunity_df_copy[['OpportunityEndTime','OpportunityEndOffset']].apply(lambda a: pd.to_datetime(a['OpportunityEndTime']) - pd.DateOffset(seconds=a['OpportunityEndOffset']),axis=1)\n",
    "    base_time_stamp = image_opportunity_df_copy[\"X\"].to_list()[0]\n",
    "    config['base_time_stamp_downlink'] = base_time_stamp\n",
    "\n",
    "    #image Downlink\n",
    "    #image_downlink_df = pd.read_csv(config[\"csv_file_path\"][\"image_downlink_file\"])\n",
    "    image_downlink_df['assured_downlink_flag'] = [0,0] +[0]*(len(image_downlink_df)-2)\n",
    "    image_downlink_df['delivery_type'] = 'standard_delivery' # expedited_delivery,super_expedited_delivery\n",
    "    union_list_of_sat = list(set(image_opportunity_df['SatID']).union(set(GS_pass_df['SatID'])).union(set(image_downlink_df['SatID'])))\n",
    "    hrs = config['scheduled_Hrs']\n",
    "\n",
    "    # get dummy eclipse data close to reality\n",
    "    #eclipse_df = pd.DataFrame()\n",
    "    #for sat in satellite_list:\n",
    "        #this_eclipse_df = eclipse_event_df[eclipse_event_df['SatID']==sat]\n",
    "        #that_eclipse_df = get_eclipse_data(this_eclipse_df,config)\n",
    "        #eclipse_df = pd.concat([that_eclipse_df,eclipse_df])\n",
    "        \n",
    "    min_time_index= min([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "    max_time_index= max([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "\n",
    "    hrs = (max_time_index - min_time_index)/3600\n",
    "    hrs = math.ceil(hrs)\n",
    "    while True:\n",
    "        hrs += 1\n",
    "        if hrs % 1.5==0:\n",
    "            break\n",
    "\n",
    "\n",
    "    in_orbit_eclipse_event = [1 for i in range(int(1.5*3600*0.4))] + [0 for i in range(int(1.5*3600*0.6))] #\n",
    "    eclipse_df  = pd.DataFrame({'time_index': [i for i in range(min_time_index,min_time_index+hrs*3600)] ,\"eclipse\" : in_orbit_eclipse_event*int(hrs/1.5)})\n",
    "    eclipse_df['SatID']= [union_list_of_sat] *len(eclipse_df)\n",
    "    eclipse_df = eclipse_df.explode('SatID')\n",
    "    eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "\n",
    "    #eclipse_df = pd.DataFrame()\n",
    "    #for sat in satellite_list:\n",
    "        #this_eclipse_df = eclipse_event_df[eclipse_event_df['SatID']==sat]\n",
    "        #that_eclipse_df = get_eclipse_data(this_eclipse_df,config)\n",
    "        #eclipse_df = pd.concat([that_eclipse_df,eclipse_df])\n",
    "   #eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "\n",
    "    \n",
    "    # get dummy data for assured tasking\n",
    "    image_opportunity_df['encoded_stripId'] =   image_opportunity_df['StripID'].astype(str)+ '_' + image_opportunity_df['AoiID'].astype(str)\n",
    "    total_capture_list = list(image_opportunity_df['encoded_stripId'].unique())\n",
    "    no_of_list = len(total_capture_list)\n",
    "    assured_capture_df = pd.DataFrame({'encoded_stripId':total_capture_list,'assured_task':[0,0]+[0]*(no_of_list-2)})\n",
    "    image_opportunity_df = pd.merge(image_opportunity_df,assured_capture_df,on='encoded_stripId',how='left')\n",
    "    image_opportunity_df = image_opportunity_df.drop(columns=['encoded_stripId'])\n",
    "\n",
    "    # further processing eclipse data to align with gs pass where entire gs pass is assumed to be in eclipse region\n",
    "    gsPassInput_df_copy = GS_pass_df_original\n",
    "    gsPassInput_df_copy['SatID'] = gsPassInput_df_copy['SatID'].astype(str)\n",
    "    gsPassInput_df_copy['AOSOffset'] = gsPassInput_df_copy['AOSOffset'].astype(int)\n",
    "    gsPassInput_df_copy['LOSOffset'] = gsPassInput_df_copy['LOSOffset'].astype(int)\n",
    "    gsPassInput_df_copy['list'] =  gsPassInput_df_copy[['AOSOffset','LOSOffset']].apply(lambda a : [i for i in range(a['AOSOffset'],a['LOSOffset']+1)],axis =1 )\n",
    "\n",
    "    gsPassInput_df_copy1 = gsPassInput_df_copy[['SatID','list']]\n",
    "    gsPassInput_df_copy1 = gsPassInput_df_copy1.explode('list')\n",
    "    gsPassInput_df_grouped_copy1 = gsPassInput_df_copy1.groupby('SatID').agg(time_index_list = ('list',list)).reset_index()\n",
    "    gsPasstimeIndexList__s = dict(zip(gsPassInput_df_grouped_copy1['SatID'],gsPassInput_df_grouped_copy1['time_index_list']))\n",
    "    for k,v in eclipse_df_dict.items():\n",
    "        if k in gsPasstimeIndexList__s.keys():\n",
    "            this_time_index_list = gsPasstimeIndexList__s[k]\n",
    "            v.loc[v[\"time_index\"].isin(this_time_index_list), \"eclipse\"] = 1\n",
    "            eclipse_df_dict[k] = v\n",
    "\n",
    "    return {\n",
    "            'GS_pass_df':GS_pass_df,\\\n",
    "            'image_opportunity_df':image_opportunity_df,\\\n",
    "            'image_downlink_df':image_downlink_df,\\\n",
    "            \"eclipse_df_dict\": eclipse_df_dict,\n",
    "            \"config\":config\n",
    "            }\n",
    "    \n",
    "def get_schedule(config,GS_pass_df,image_opportunity_df,image_downlink_df):\n",
    "\n",
    "    # Open and read the JSON file\n",
    "    #APS_Python_core/src/APS_Python_core/1_input_data/config.json\n",
    "    #with open('APS_Python_core/src/APS_Python_core/1_input_data/config.json', 'r') as file:\n",
    "    #with open('../1_input_data/config.json', 'r') as file:\n",
    "        #config = json.load(file)\n",
    "    original_image_opportunity_df = image_opportunity_df.copy()\n",
    "    # if memory constraint False then thermal_constraint is also False\n",
    "    #config['constraints']['thermal_constraint_readout'] = config['constraints']['memory_constrant'] and config['constraints']['thermal_constraint_readout']\n",
    "    #config['constraints']['thermal_constraint_imaging'] = config['constraints']['memory_constrant'] and config['constraints']['thermal_constraint_imaging']\n",
    "\n",
    "    #======================================================================================================================================================================================================\n",
    "    # read_input\n",
    "    input_dict = get_input_files(config,GS_pass_df,image_opportunity_df,image_downlink_df)\n",
    "    config = input_dict['config']\n",
    "    #======================================================================================================================================================================================================\n",
    "    #gs pass_selection\n",
    "    gs_pass_result_df = select_gs_pass_oppr(input_dict['GS_pass_df'],config)\n",
    "    gs_pass_result_df['Eclipse'] = 1 ## dummy\n",
    "    gs_pass_result_df['duration'] = gs_pass_result_df['end_time'] - gs_pass_result_df['start_time']\n",
    "    gs_pass_result_df = gs_pass_result_df[gs_pass_result_df['duration']> 0]\n",
    "    interpret_gs_pass_result_df_copy = gs_pass_result_df.copy()# this not the gsPass result as it is to be get filtered after due to other factors in image capture plan.It is just to get require info in interpret result.\n",
    "\n",
    "    print(\"image_capture_plan_starting\")\n",
    "    #======================================================================================================================================================================================================\n",
    "    #image_selection\n",
    "    img_capture_result,capture_plan_data_input= select_img_opprtunity(input_dict['image_opportunity_df'],gs_pass_result_df,input_dict['eclipse_df_dict'],config)\n",
    "    img_capture_result['base_time'] = config['base_time_stamp_downlink']\n",
    "    #img_capture_result = img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "    #readout_result = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "    interpret_img_capture_resul_copy = img_capture_result.copy()\n",
    "    #======================================================================================================================================================================================================\n",
    "    # get APS success metrics \n",
    "    APS_success_metric_df = get_aps_success_metric(img_capture_result,capture_plan_data_input)\n",
    "    #======================================================================================================================================================================================================\n",
    "    print(\"Downlink_plan_starting\")\n",
    "    downlink_result = get_downlink_schedule(input_dict['image_downlink_df'],img_capture_result,config)\n",
    "    downlink_result['base_time'] = config['base_time_stamp_downlink']\n",
    "    #======================================================================================================================================================================================================\n",
    "    #img_capture_result[img_capture_result['download_from_']]\n",
    "    # gs_pass_result_df.to_csv(\"APS_Python_core/src/APS_Python_core/5_output_data/gs_pass_result_df.csv\",index=None)\n",
    "    # img_capture_result.to_csv(\"APS_Python_core/src/APS_Python_core/5_output_data/img_capture_schedule.csv\",index=None)\n",
    "    # APS_success_metric_df.to_csv(\"APS_Python_core/src/APS_Python_core/5_output_data/APS_success_metric.csv\",index = None)\n",
    "    # downlink_result.to_csv(\"APS_Python_core/src/APS_Python_core/5_output_data/downlink_result.csv\",index = None)\n",
    "\n",
    "    interpret_image_opportunity_df = original_image_opportunity_df\n",
    "    interpret_result_dict = interpret_result(interpret_image_opportunity_df,interpret_gs_pass_result_df_copy,interpret_img_capture_resul_copy,config)\n",
    "    for k,v in interpret_result_dict.items():\n",
    "        v['base_time'] = config['base_time_stamp_downlink']\n",
    "        #v.to_csv(\"APS_Python_core/src/APS_Python_core/5_output_data/\"+k+\".csv\",index = None)\n",
    "    \n",
    "    only_img_capture_result = img_capture_result[img_capture_result['operation']=='Imaging'][['SatID','start_time','end_time','AoiID','StripID','base_time']]\n",
    "    only_img_capture_result['start_time'] = only_img_capture_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "    only_img_capture_result['end_time'] = only_img_capture_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "    only_readout_result = img_capture_result[img_capture_result['operation']=='Readout'][['SatID','start_time','end_time','base_time']]\n",
    "    print(\"len_of_readout=\",len(only_readout_result),only_readout_result)\n",
    "    if len(only_readout_result):\n",
    "        only_readout_result['start_time'] = only_readout_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "        only_readout_result['end_time'] = only_readout_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "    only_gsPass_result = img_capture_result[img_capture_result['operation']=='downlinking_from_Readout'][['SatID','start_time','end_time','gsID','base_time']]\n",
    "    only_gsPass_result['start_time'] = only_gsPass_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "    only_gsPass_result['end_time'] = only_gsPass_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "\n",
    "    result_dict = {\"only_readout_result\":only_readout_result,\\\n",
    "                  \"only_img_capture_result\":only_img_capture_result,\\\n",
    "                  \"only_gsPass_result\":only_gsPass_result,\\\n",
    "                  \"combined_result\":img_capture_result}\n",
    "    result_dict.update(interpret_result_dict)\n",
    "    #return result_dict\n",
    "    return result_dict\n",
    "\n",
    "    #print(only_img_capture_result,only_readout_result,downlink_result)\n",
    "#config['constraints'] = ['Thermal_constraints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/robin/Documents/Schedule_plan/git_APS_Python_core_develop/APS_Python_core/src/APS_Python_core'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_solving\n",
      "Running HiGHS 1.8.1 (git hash: 4a7f24a): Copyright (c) 2024 HiGHS under MIT licence terms\n",
      "Coefficient ranges:\n",
      "  Matrix [1e+00, 1e+09]\n",
      "  Cost   [1e+00, 1e+00]\n",
      "  Bound  [1e+00, 1e+00]\n",
      "  RHS    [9e+04, 1e+09]\n",
      "Presolving model\n",
      "335 rows, 250 cols, 750 nonzeros  0s\n",
      "169 rows, 167 cols, 418 nonzeros  0s\n",
      "77 rows, 75 cols, 188 nonzeros  0s\n",
      "\n",
      "Solving MIP model with:\n",
      "   77 rows\n",
      "   75 cols (37 binary, 0 integer, 0 implied int., 38 continuous)\n",
      "   188 nonzeros\n",
      "MIP-Timing:     0.00073 - starting analytic centre calculation\n",
      "\n",
      "Src: B => Branching; C => Central rounding; F => Feasibility pump; H => Heuristic; L => Sub-MIP;\n",
      "     P => Empty MIP; R => Randomized rounding; S => Solve LP; T => Evaluate node; U => Unbounded;\n",
      "     z => Trivial zero; l => Trivial lower; u => Trivial upper; p => Trivial point\n",
      "\n",
      "        Nodes      |    B&B Tree     |            Objective Bounds              |  Dynamic Constraints |       Work      \n",
      "Src  Proc. InQueue |  Leaves   Expl. | BestBound       BestSol              Gap |   Cuts   InLp Confl. | LpIters     Time\n",
      "\n",
      "         0       0         0   0.00%   -inf            inf                  inf        0      0      0         0     0.0s\n",
      " R       0       0         0   0.00%   -3001279.839525 -34044          8715.88%        0      0      0        76     0.0s\n",
      " C       0       0         0   0.00%   -45431          -45431             0.00%       42     37      0       152     0.0s\n",
      "         1       0         1 100.00%   -45431          -45431             0.00%       42     37      0       152     0.0s\n",
      "\n",
      "Solving report\n",
      "  Status            Optimal\n",
      "  Primal bound      -45431\n",
      "  Dual bound        -45431\n",
      "  Gap               0% (tolerance: 0.01%)\n",
      "  P-D integral      0.0358447296726\n",
      "  Solution status   feasible\n",
      "                    -45431 (objective)\n",
      "                    0 (bound viol.)\n",
      "                    0 (int. viol.)\n",
      "                    0 (row viol.)\n",
      "  Timing            0.00 (total)\n",
      "                    0.00 (presolve)\n",
      "                    0.00 (solve)\n",
      "                    0.00 (postsolve)\n",
      "  Max sub-MIP depth 0\n",
      "  Nodes             1\n",
      "  Repair LPs        0 (0 feasible; 0 iterations)\n",
      "  LP iterations     152 (total)\n",
      "                    0 (strong br.)\n",
      "                    76 (separation)\n",
      "                    0 (heuristics)\n",
      "status= Optimal\n",
      "image_capture_plan_starting\n",
      "=====IMAGING THEMAL======\n",
      "=====READOUT THERMAL======\n",
      "len_before_eclipse_transition_divide= 437\n",
      "len_after(after explode)_eclipse_transition_divide= 519\n",
      "Before_Ambiguous_event_transition_divide = 519\n",
      "Empty DataFrame\n",
      "Columns: [SatID, encoded_stripId, start_time, end_time, Eclipse, TW_index, gsID, till_now_max, prev_max, global_TW, Memory_global_TW_index, concat_sat_MGWI, EcStEnd_list, len_EcStEnd_list, new_eclipse, new_start_time, new_end_time]\n",
      "Index: []\n",
      "After_len_of_ambiguous_event_transition_divide = 519\n",
      "list of unique lenths of eclipse_transition_divide(bifurcation) =  [1 2 3]\n",
      "len_power_based_memory_based= 373 len_power_based_memory_based= 146\n",
      "final_len_power_based= 519\n",
      "GS_Pass_time_objective\n",
      "only gs check  FF01 1.0 [1.0]\n",
      "only gs check  FF02 1.0 [1.0]\n",
      "only gs check  FF03 1.0 [1.0]\n",
      "Running HiGHS 1.8.1 (git hash: 4a7f24a): Copyright (c) 2024 HiGHS under MIT licence terms\n",
      "Coefficient ranges:\n",
      "  Matrix [8e-01, 1e+06]\n",
      "  Cost   [1e+00, 7e+02]\n",
      "  Bound  [1e+00, 7e+08]\n",
      "  RHS    [1e+00, 2e+08]\n",
      "Presolving model\n",
      "15731 rows, 5003 cols, 44436 nonzeros  0s\n",
      "9539 rows, 4431 cols, 28143 nonzeros  0s\n",
      "7321 rows, 3030 cols, 18349 nonzeros  0s\n",
      "4519 rows, 1629 cols, 12745 nonzeros  0s\n",
      "4515 rows, 1629 cols, 12737 nonzeros  0s\n",
      "\n",
      "Solving MIP model with:\n",
      "   4515 rows\n",
      "   1629 cols (353 binary, 0 integer, 2 implied int., 1274 continuous)\n",
      "   12737 nonzeros\n",
      "MIP-Timing:       0.075 - starting analytic centre calculation\n",
      "\n",
      "Src: B => Branching; C => Central rounding; F => Feasibility pump; H => Heuristic; L => Sub-MIP;\n",
      "     P => Empty MIP; R => Randomized rounding; S => Solve LP; T => Evaluate node; U => Unbounded;\n",
      "     z => Trivial zero; l => Trivial lower; u => Trivial upper; p => Trivial point\n",
      "\n",
      "        Nodes      |    B&B Tree     |            Objective Bounds              |  Dynamic Constraints |       Work      \n",
      "Src  Proc. InQueue |  Leaves   Expl. | BestBound       BestSol              Gap |   Cuts   InLp Confl. | LpIters     Time\n",
      "\n",
      "         0       0         0   0.00%   -60380.263555   inf                  inf        0      0      0         0     0.1s\n",
      " R       0       0         0   0.00%   -56964.605569   -45107.304019     26.29%        0      0      0      1115     0.1s\n",
      " C       0       0         0   0.00%   -55353.388157   -45934.933365     20.50%      336     65      0      1389     0.2s\n",
      " L       0       0         0 100.00%   -48283.582431   -48283.582431      0.00%      590    126      0      1881     0.3s\n",
      "         1       0         1 100.00%   -48283.582431   -48283.582431      0.00%      590    126      0      2122     0.3s\n",
      "\n",
      "Solving report\n",
      "  Status            Optimal\n",
      "  Primal bound      -48283.5824309\n",
      "  Dual bound        -48283.5824309\n",
      "  Gap               0%\n",
      "  P-D integral      0.027018725093\n",
      "  Solution status   feasible\n",
      "                    -48283.5824309 (objective)\n",
      "                    0 (bound viol.)\n",
      "                    2.98079978305e-14 (int. viol.)\n",
      "                    0 (row viol.)\n",
      "  Timing            0.29 (total)\n",
      "                    0.00 (presolve)\n",
      "                    0.00 (solve)\n",
      "                    0.00 (postsolve)\n",
      "  Max sub-MIP depth 1\n",
      "  Nodes             1\n",
      "  Repair LPs        0 (0 feasible; 0 iterations)\n",
      "  LP iterations     2122 (total)\n",
      "                    0 (strong br.)\n",
      "                    766 (separation)\n",
      "                    241 (heuristics)\n",
      "status= Optimal\n",
      "total_readout_memory_objective\n",
      "only gs check  FF01 1.0 [1.0]\n",
      "only gs check  FF02 1.0 [1.0]\n",
      "only gs check  FF03 1.0 [1.0]\n",
      "Running HiGHS 1.8.1 (git hash: 4a7f24a): Copyright (c) 2024 HiGHS under MIT licence terms\n",
      "Coefficient ranges:\n",
      "  Matrix [8e-01, 1e+06]\n",
      "  Cost   [6e-02, 1e+00]\n",
      "  Bound  [1e+00, 7e+08]\n",
      "  RHS    [1e+00, 2e+08]\n",
      "Presolving model\n",
      "15732 rows, 5003 cols, 44742 nonzeros  0s\n",
      "9540 rows, 4431 cols, 28449 nonzeros  0s\n",
      "7322 rows, 3030 cols, 18655 nonzeros  0s\n",
      "4520 rows, 1629 cols, 13051 nonzeros  0s\n",
      "4516 rows, 1629 cols, 13043 nonzeros  0s\n",
      "\n",
      "Solving MIP model with:\n",
      "   4516 rows\n",
      "   1629 cols (353 binary, 0 integer, 2 implied int., 1274 continuous)\n",
      "   13043 nonzeros\n",
      "MIP-Timing:       0.075 - starting analytic centre calculation\n",
      "\n",
      "Src: B => Branching; C => Central rounding; F => Feasibility pump; H => Heuristic; L => Sub-MIP;\n",
      "     P => Empty MIP; R => Randomized rounding; S => Solve LP; T => Evaluate node; U => Unbounded;\n",
      "     z => Trivial zero; l => Trivial lower; u => Trivial upper; p => Trivial point\n",
      "\n",
      "        Nodes      |    B&B Tree     |            Objective Bounds              |  Dynamic Constraints |       Work      \n",
      "Src  Proc. InQueue |  Leaves   Expl. | BestBound       BestSol              Gap |   Cuts   InLp Confl. | LpIters     Time\n",
      "\n",
      "         0       0         0   0.00%   -10915.740299   inf                  inf        0      0      0         0     0.1s\n",
      "         0       0         0   0.00%   -8954.28521     inf                  inf        0      0      2       981     0.1s\n",
      " R       0       0         0   0.00%   -8783.740299    -8783.740299       0.00%      465    179     90      1951     0.3s\n",
      "         1       0         1 100.00%   -8783.740299    -8783.740299       0.00%      465    179     90      1951     0.3s\n",
      "\n",
      "Solving report\n",
      "  Status            Optimal\n",
      "  Primal bound      -8783.74029892\n",
      "  Dual bound        -8783.74029892\n",
      "  Gap               0%\n",
      "  P-D integral      0\n",
      "  Solution status   feasible\n",
      "                    -8783.74029892 (objective)\n",
      "                    0 (bound viol.)\n",
      "                    0 (int. viol.)\n",
      "                    0 (row viol.)\n",
      "  Timing            0.27 (total)\n",
      "                    0.00 (presolve)\n",
      "                    0.00 (solve)\n",
      "                    0.00 (postsolve)\n",
      "  Max sub-MIP depth 0\n",
      "  Nodes             1\n",
      "  Repair LPs        0 (0 feasible; 0 iterations)\n",
      "  LP iterations     1951 (total)\n",
      "                    0 (strong br.)\n",
      "                    970 (separation)\n",
      "                    0 (heuristics)\n",
      "status= Optimal\n",
      "Downlink_plan_starting\n",
      "len_of_readout= 4   SatID  start_time  end_time           base_time\n",
      "0  FF01     91429.0   92164.0 2024-11-13 12:30:44\n",
      "1  FF02     91539.0   92164.0 2024-11-13 12:30:44\n",
      "2  FF01     95331.0   95383.5 2024-11-13 12:30:44\n",
      "3  FF02     95975.0   96137.5 2024-11-13 12:30:44\n"
     ]
    }
   ],
   "source": [
    "GS_pass_df = GS_pass_df = pd.read_csv(\"1_input_data/GS_Passes_new (1).csv\")\n",
    "image_opportunity_df = pd.read_csv(\"1_input_data/Imaging_new (1) copy.csv\")\n",
    "image_downlink_df = pd.read_csv(\"1_input_data/APS_imageTable_TV1.csv\")\n",
    "with open('1_input_data/config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "result_dict = get_schedule(config,GS_pass_df,image_opportunity_df,image_downlink_df)\n",
    "for k,v in result_dict.items():\n",
    "    v.to_csv('5_output_data/'+k+'.csv',index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-48283.5824309=25 strips 83 gspasses,-48283.5824309=25 strips 83 gspasses,-48283.5824309=26 strips 83 gspasses ,  -48283.5824309= 24 strips 82 gspasses , -48283.5824309 25 strips 82 gs PASss,-48283.5824309 24 strips 83 gs PASss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GS_pass_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(image_opportunity_df['Priority'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['only_readout_result', 'only_img_capture_result', 'only_gsPass_result', 'combined_result', 'interpret_extracted_raw_file_df', 'interpret_selected_oppr_conflict_comparision_df', 'interpret_KPI_df'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 83)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['only_img_capture_result']['StripID'].nunique(),len(result_dict['only_gsPass_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SatID</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>encoded_strip_id</th>\n",
       "      <th>gsID</th>\n",
       "      <th>operation</th>\n",
       "      <th>camera_memory_value_endofTW</th>\n",
       "      <th>delta_camera_memory_value_in_this_TW</th>\n",
       "      <th>SSD_memory_value_endofTW</th>\n",
       "      <th>delta_SSD_memory_value_in_this_TW</th>\n",
       "      <th>global_priority</th>\n",
       "      <th>local_priority</th>\n",
       "      <th>mean_global_priority</th>\n",
       "      <th>mean_local_priority</th>\n",
       "      <th>StripID</th>\n",
       "      <th>AoiID</th>\n",
       "      <th>base_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FF01</td>\n",
       "      <td>86765.0</td>\n",
       "      <td>87250.0</td>\n",
       "      <td></td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FF01</td>\n",
       "      <td>87651.0</td>\n",
       "      <td>88294.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FF01</td>\n",
       "      <td>89594.0</td>\n",
       "      <td>89610.0</td>\n",
       "      <td>Order 57 - Strip 0_Area 36</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>132.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2002.468247</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2002.468247</td>\n",
       "      <td>Order 57 - Strip 0</td>\n",
       "      <td>Area 36</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FF01</td>\n",
       "      <td>91217.0</td>\n",
       "      <td>91428.0</td>\n",
       "      <td></td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FF01</td>\n",
       "      <td>91429.0</td>\n",
       "      <td>92164.0</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>Readout</td>\n",
       "      <td>888.0</td>\n",
       "      <td>-588.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FF01</td>\n",
       "      <td>92455.0</td>\n",
       "      <td>93065.0</td>\n",
       "      <td></td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>888.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FF01</td>\n",
       "      <td>93421.0</td>\n",
       "      <td>94054.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>888.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FF01</td>\n",
       "      <td>95314.0</td>\n",
       "      <td>95330.0</td>\n",
       "      <td>Order 30 - Strip 0_Area 27</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>771.416143</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>771.416143</td>\n",
       "      <td>Order 30 - Strip 0</td>\n",
       "      <td>Area 27</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FF01</td>\n",
       "      <td>95331.0</td>\n",
       "      <td>95383.5</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FF01</td>\n",
       "      <td>99178.0</td>\n",
       "      <td>99810.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FF01</td>\n",
       "      <td>104936.0</td>\n",
       "      <td>105578.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>FF01</td>\n",
       "      <td>109082.0</td>\n",
       "      <td>109433.0</td>\n",
       "      <td></td>\n",
       "      <td>MAU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FF01</td>\n",
       "      <td>110713.0</td>\n",
       "      <td>111359.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FF01</td>\n",
       "      <td>111535.0</td>\n",
       "      <td>111569.0</td>\n",
       "      <td>Order 47 - Strip 5_Area 35</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>895.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>750.0</td>\n",
       "      <td>993.655904</td>\n",
       "      <td>750.0</td>\n",
       "      <td>993.655904</td>\n",
       "      <td>Order 47 - Strip 5</td>\n",
       "      <td>Area 35</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FF01</td>\n",
       "      <td>111784.0</td>\n",
       "      <td>111799.0</td>\n",
       "      <td>Order 67 - Strip 0_Area 6</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1254.852547</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1254.852547</td>\n",
       "      <td>Order 67 - Strip 0</td>\n",
       "      <td>Area 6</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>FF01</td>\n",
       "      <td>116531.0</td>\n",
       "      <td>117153.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>FF01</td>\n",
       "      <td>119041.0</td>\n",
       "      <td>119088.0</td>\n",
       "      <td></td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>FF01</td>\n",
       "      <td>122404.0</td>\n",
       "      <td>122956.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>FF01</td>\n",
       "      <td>124758.0</td>\n",
       "      <td>124893.0</td>\n",
       "      <td></td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>FF01</td>\n",
       "      <td>128338.0</td>\n",
       "      <td>128766.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>FF01</td>\n",
       "      <td>134323.0</td>\n",
       "      <td>134586.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>FF01</td>\n",
       "      <td>135150.0</td>\n",
       "      <td>135777.0</td>\n",
       "      <td></td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>888.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FF01</td>\n",
       "      <td>136480.0</td>\n",
       "      <td>136496.0</td>\n",
       "      <td>Order 22 - Strip 3_Area 21</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>813.377134</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>813.377134</td>\n",
       "      <td>Order 22 - Strip 3</td>\n",
       "      <td>Area 21</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>FF01</td>\n",
       "      <td>140302.0</td>\n",
       "      <td>140450.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>FF01</td>\n",
       "      <td>141008.0</td>\n",
       "      <td>141403.0</td>\n",
       "      <td></td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>FF01</td>\n",
       "      <td>146165.0</td>\n",
       "      <td>146244.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>888.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FF01</td>\n",
       "      <td>147302.0</td>\n",
       "      <td>147318.0</td>\n",
       "      <td>Order 64 - Strip 3_Area 37</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>779.772297</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>779.772297</td>\n",
       "      <td>Order 64 - Strip 3</td>\n",
       "      <td>Area 37</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>FF01</td>\n",
       "      <td>147793.0</td>\n",
       "      <td>148309.0</td>\n",
       "      <td></td>\n",
       "      <td>MAU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>FF01</td>\n",
       "      <td>151985.0</td>\n",
       "      <td>152204.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>FF01</td>\n",
       "      <td>153534.0</td>\n",
       "      <td>154085.0</td>\n",
       "      <td></td>\n",
       "      <td>MAU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>FF01</td>\n",
       "      <td>157795.0</td>\n",
       "      <td>158347.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FF01</td>\n",
       "      <td>159555.0</td>\n",
       "      <td>159572.0</td>\n",
       "      <td>Order 11 - Strip 1_Area 13</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>776.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1023.477782</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1023.477782</td>\n",
       "      <td>Order 11 - Strip 1</td>\n",
       "      <td>Area 13</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FF01</td>\n",
       "      <td>159741.0</td>\n",
       "      <td>159773.0</td>\n",
       "      <td>Order 71 - Strip 1_Area 8</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1082.120595</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1082.120595</td>\n",
       "      <td>Order 71 - Strip 1</td>\n",
       "      <td>Area 8</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>FF01</td>\n",
       "      <td>163598.0</td>\n",
       "      <td>164219.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>FF01</td>\n",
       "      <td>167058.0</td>\n",
       "      <td>167651.0</td>\n",
       "      <td></td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>FF01</td>\n",
       "      <td>169392.0</td>\n",
       "      <td>169611.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SatID  start_time  end_time            encoded_strip_id        gsID  \\\n",
       "30   FF01     86765.0   87250.0                                  JEJU01   \n",
       "31   FF01     87651.0   88294.0                              SVALBARD01   \n",
       "4    FF01     89594.0   89610.0  Order 57 - Strip 0_Area 36               \n",
       "35   FF01     91217.0   91428.0                                AWARUA01   \n",
       "0    FF01     91429.0   92164.0                   no_i_no_g   no_i_no_g   \n",
       "37   FF01     92455.0   93065.0                                  JEJU01   \n",
       "38   FF01     93421.0   94054.0                              SVALBARD01   \n",
       "6    FF01     95314.0   95330.0  Order 30 - Strip 0_Area 27               \n",
       "2    FF01     95331.0   95383.5                   no_i_no_g   no_i_no_g   \n",
       "42   FF01     99178.0   99810.0                              SVALBARD01   \n",
       "45   FF01    104936.0  105578.0                              SVALBARD01   \n",
       "50   FF01    109082.0  109433.0                                   MAU01   \n",
       "51   FF01    110713.0  111359.0                              SVALBARD01   \n",
       "13   FF01    111535.0  111569.0  Order 47 - Strip 5_Area 35               \n",
       "14   FF01    111784.0  111799.0   Order 67 - Strip 0_Area 6               \n",
       "57   FF01    116531.0  117153.0                              SVALBARD01   \n",
       "60   FF01    119041.0  119088.0                                AWARUA01   \n",
       "63   FF01    122404.0  122956.0                              SVALBARD01   \n",
       "66   FF01    124758.0  124893.0                                AWARUA01   \n",
       "69   FF01    128338.0  128766.0                              SVALBARD01   \n",
       "75   FF01    134323.0  134586.0                              SVALBARD01   \n",
       "76   FF01    135150.0  135777.0                                  JEJU01   \n",
       "18   FF01    136480.0  136496.0  Order 22 - Strip 3_Area 21               \n",
       "81   FF01    140302.0  140450.0                              SVALBARD01   \n",
       "82   FF01    141008.0  141403.0                                  JEJU01   \n",
       "86   FF01    146165.0  146244.0                              SVALBARD01   \n",
       "20   FF01    147302.0  147318.0  Order 64 - Strip 3_Area 37               \n",
       "87   FF01    147793.0  148309.0                                   MAU01   \n",
       "92   FF01    151985.0  152204.0                              SVALBARD01   \n",
       "93   FF01    153534.0  154085.0                                   MAU01   \n",
       "97   FF01    157795.0  158347.0                              SVALBARD01   \n",
       "24   FF01    159555.0  159572.0  Order 11 - Strip 1_Area 13               \n",
       "25   FF01    159741.0  159773.0   Order 71 - Strip 1_Area 8               \n",
       "101  FF01    163598.0  164219.0                              SVALBARD01   \n",
       "104  FF01    167058.0  167651.0                                AWARUA01   \n",
       "107  FF01    169392.0  169611.0                              SVALBARD01   \n",
       "\n",
       "                    operation  camera_memory_value_endofTW  \\\n",
       "30   downlinking_from_Readout                         20.0   \n",
       "31   downlinking_from_Readout                         20.0   \n",
       "4                     Imaging                        132.0   \n",
       "35   downlinking_from_Readout                        132.0   \n",
       "0                     Readout                        888.0   \n",
       "37   downlinking_from_Readout                        888.0   \n",
       "38   downlinking_from_Readout                        888.0   \n",
       "6                     Imaging                       1000.0   \n",
       "2                     Readout                          0.0   \n",
       "42   downlinking_from_Readout                          0.0   \n",
       "45   downlinking_from_Readout                          0.0   \n",
       "50   downlinking_from_Readout                        657.0   \n",
       "51   downlinking_from_Readout                        657.0   \n",
       "13                    Imaging                        895.0   \n",
       "14                    Imaging                       1000.0   \n",
       "57   downlinking_from_Readout                          0.0   \n",
       "60   downlinking_from_Readout                          0.0   \n",
       "63   downlinking_from_Readout                          0.0   \n",
       "66   downlinking_from_Readout                          0.0   \n",
       "69   downlinking_from_Readout                          0.0   \n",
       "75   downlinking_from_Readout                          0.0   \n",
       "76   downlinking_from_Readout                        888.0   \n",
       "18                    Imaging                       1000.0   \n",
       "81   downlinking_from_Readout                       1000.0   \n",
       "82   downlinking_from_Readout                          0.0   \n",
       "86   downlinking_from_Readout                        888.0   \n",
       "20                    Imaging                       1000.0   \n",
       "87   downlinking_from_Readout                       1000.0   \n",
       "92   downlinking_from_Readout                          0.0   \n",
       "93   downlinking_from_Readout                          0.0   \n",
       "97   downlinking_from_Readout                        657.0   \n",
       "24                    Imaging                        776.0   \n",
       "25                    Imaging                       1000.0   \n",
       "101  downlinking_from_Readout                          0.0   \n",
       "104  downlinking_from_Readout                          0.0   \n",
       "107  downlinking_from_Readout                          0.0   \n",
       "\n",
       "     delta_camera_memory_value_in_this_TW SSD_memory_value_endofTW  \\\n",
       "30                                    0.0                       NA   \n",
       "31                                    0.0                       NA   \n",
       "4                                   112.0                       NA   \n",
       "35                                    0.0                       NA   \n",
       "0                                  -588.0                    938.0   \n",
       "37                                    0.0                       NA   \n",
       "38                                    0.0                       NA   \n",
       "6                                   112.0                       NA   \n",
       "2                                   -42.0                    980.0   \n",
       "42                                    0.0                       NA   \n",
       "45                                    0.0                       NA   \n",
       "50                                    0.0                       NA   \n",
       "51                                    0.0                       NA   \n",
       "13                                  238.0                       NA   \n",
       "14                                  105.0                       NA   \n",
       "57                                    0.0                       NA   \n",
       "60                                    0.0                       NA   \n",
       "63                                    0.0                       NA   \n",
       "66                                    0.0                       NA   \n",
       "69                                    0.0                       NA   \n",
       "75                                    0.0                       NA   \n",
       "76                                    0.0                       NA   \n",
       "18                                  112.0                       NA   \n",
       "81                                    0.0                       NA   \n",
       "82                                    0.0                       NA   \n",
       "86                                    0.0                       NA   \n",
       "20                                  112.0                       NA   \n",
       "87                                    0.0                       NA   \n",
       "92                                    0.0                       NA   \n",
       "93                                    0.0                       NA   \n",
       "97                                    0.0                       NA   \n",
       "24                                  119.0                       NA   \n",
       "25                                  224.0                       NA   \n",
       "101                                   0.0                       NA   \n",
       "104                                   0.0                       NA   \n",
       "107                                   0.0                       NA   \n",
       "\n",
       "    delta_SSD_memory_value_in_this_TW global_priority local_priority  \\\n",
       "30                                 NA       no_i_no_g      no_i_no_g   \n",
       "31                                 NA       no_i_no_g      no_i_no_g   \n",
       "4                                  NA          1000.0    2002.468247   \n",
       "35                                 NA       no_i_no_g      no_i_no_g   \n",
       "0                               588.0       no_i_no_g      no_i_no_g   \n",
       "37                                 NA       no_i_no_g      no_i_no_g   \n",
       "38                                 NA       no_i_no_g      no_i_no_g   \n",
       "6                                  NA          1000.0     771.416143   \n",
       "2                                42.0       no_i_no_g      no_i_no_g   \n",
       "42                                 NA       no_i_no_g      no_i_no_g   \n",
       "45                                 NA       no_i_no_g      no_i_no_g   \n",
       "50                                 NA       no_i_no_g      no_i_no_g   \n",
       "51                                 NA       no_i_no_g      no_i_no_g   \n",
       "13                                 NA           750.0     993.655904   \n",
       "14                                 NA          1000.0    1254.852547   \n",
       "57                                 NA       no_i_no_g      no_i_no_g   \n",
       "60                                 NA       no_i_no_g      no_i_no_g   \n",
       "63                                 NA       no_i_no_g      no_i_no_g   \n",
       "66                                 NA       no_i_no_g      no_i_no_g   \n",
       "69                                 NA       no_i_no_g      no_i_no_g   \n",
       "75                                 NA       no_i_no_g      no_i_no_g   \n",
       "76                                 NA       no_i_no_g      no_i_no_g   \n",
       "18                                 NA          1000.0     813.377134   \n",
       "81                                 NA       no_i_no_g      no_i_no_g   \n",
       "82                                 NA       no_i_no_g      no_i_no_g   \n",
       "86                                 NA       no_i_no_g      no_i_no_g   \n",
       "20                                 NA          1000.0     779.772297   \n",
       "87                                 NA       no_i_no_g      no_i_no_g   \n",
       "92                                 NA       no_i_no_g      no_i_no_g   \n",
       "93                                 NA       no_i_no_g      no_i_no_g   \n",
       "97                                 NA       no_i_no_g      no_i_no_g   \n",
       "24                                 NA           500.0    1023.477782   \n",
       "25                                 NA           500.0    1082.120595   \n",
       "101                                NA       no_i_no_g      no_i_no_g   \n",
       "104                                NA       no_i_no_g      no_i_no_g   \n",
       "107                                NA       no_i_no_g      no_i_no_g   \n",
       "\n",
       "    mean_global_priority mean_local_priority             StripID    AoiID  \\\n",
       "30             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "31             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "4                 1000.0         2002.468247  Order 57 - Strip 0  Area 36   \n",
       "35             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "0              no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "37             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "38             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "6                 1000.0          771.416143  Order 30 - Strip 0  Area 27   \n",
       "2              no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "42             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "45             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "50             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "51             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "13                 750.0          993.655904  Order 47 - Strip 5  Area 35   \n",
       "14                1000.0         1254.852547  Order 67 - Strip 0   Area 6   \n",
       "57             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "60             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "63             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "66             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "69             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "75             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "76             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "18                1000.0          813.377134  Order 22 - Strip 3  Area 21   \n",
       "81             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "82             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "86             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "20                1000.0          779.772297  Order 64 - Strip 3  Area 37   \n",
       "87             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "92             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "93             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "97             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "24                 500.0         1023.477782  Order 11 - Strip 1  Area 13   \n",
       "25                 500.0         1082.120595  Order 71 - Strip 1   Area 8   \n",
       "101            no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "104            no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "107            no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "\n",
       "              base_time  \n",
       "30  2024-11-13 12:30:44  \n",
       "31  2024-11-13 12:30:44  \n",
       "4   2024-11-13 12:30:44  \n",
       "35  2024-11-13 12:30:44  \n",
       "0   2024-11-13 12:30:44  \n",
       "37  2024-11-13 12:30:44  \n",
       "38  2024-11-13 12:30:44  \n",
       "6   2024-11-13 12:30:44  \n",
       "2   2024-11-13 12:30:44  \n",
       "42  2024-11-13 12:30:44  \n",
       "45  2024-11-13 12:30:44  \n",
       "50  2024-11-13 12:30:44  \n",
       "51  2024-11-13 12:30:44  \n",
       "13  2024-11-13 12:30:44  \n",
       "14  2024-11-13 12:30:44  \n",
       "57  2024-11-13 12:30:44  \n",
       "60  2024-11-13 12:30:44  \n",
       "63  2024-11-13 12:30:44  \n",
       "66  2024-11-13 12:30:44  \n",
       "69  2024-11-13 12:30:44  \n",
       "75  2024-11-13 12:30:44  \n",
       "76  2024-11-13 12:30:44  \n",
       "18  2024-11-13 12:30:44  \n",
       "81  2024-11-13 12:30:44  \n",
       "82  2024-11-13 12:30:44  \n",
       "86  2024-11-13 12:30:44  \n",
       "20  2024-11-13 12:30:44  \n",
       "87  2024-11-13 12:30:44  \n",
       "92  2024-11-13 12:30:44  \n",
       "93  2024-11-13 12:30:44  \n",
       "97  2024-11-13 12:30:44  \n",
       "24  2024-11-13 12:30:44  \n",
       "25  2024-11-13 12:30:44  \n",
       "101 2024-11-13 12:30:44  \n",
       "104 2024-11-13 12:30:44  \n",
       "107 2024-11-13 12:30:44  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = result_dict['combined_result']\n",
    "A[A['SatID']=='FF01'].sort_values(by='start_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#capture_plan_data_input['']\n",
    "#-48283.5824309\n",
    "#-48271\n",
    "len(result_dict['interpret_selected_oppr_conflict_comparision_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conflic_strip_flag_named</th>\n",
       "      <th>max_Norm_TP</th>\n",
       "      <th>this_flag_norm_TP</th>\n",
       "      <th>max_Norm_GP</th>\n",
       "      <th>this_flag_norm_GP</th>\n",
       "      <th>max_Norm_LPDD</th>\n",
       "      <th>this_flag_norm_LLDD</th>\n",
       "      <th>base_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FF01_Order 11 - Strip 1_Area 13_1.0</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FF01_Order 22 - Strip 3_Area 21_1.0</td>\n",
       "      <td>568</td>\n",
       "      <td>568</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FF01_Order 30 - Strip 0_Area 27_1.0</td>\n",
       "      <td>555</td>\n",
       "      <td>555</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FF01_Order 47 - Strip 5_Area 35_1.0</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FF01_Order 57 - Strip 0_Area 36_1.0</td>\n",
       "      <td>725</td>\n",
       "      <td>725</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>FF01_Order 64 - Strip 3_Area 37_1.0</td>\n",
       "      <td>555</td>\n",
       "      <td>555</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>FF01_Order 67 - Strip 0_Area 6_1.0</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>FF01_Order 71 - Strip 1_Area 8_1.0</td>\n",
       "      <td>420</td>\n",
       "      <td>420</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>FF02_Order 4 - Strip 3_Area 0_1.0</td>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>FF02_Order 14 - Strip 3_Area 18_1.0</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>FF02_Order 28 - Strip 3_Area 24_1.0</td>\n",
       "      <td>401</td>\n",
       "      <td>401</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>FF02_Order 29 - Strip 0_Area 26_1.0</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>FF02_Order 44 - Strip 3_Area 35_1.0</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>FF02_Order 46 - Strip 3_Area 35_1.0</td>\n",
       "      <td>542</td>\n",
       "      <td>542</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>FF02_Order 53 - Strip 3_Area 36_1.0</td>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>FF03_Order 0 - Strip 4_Area 0_1.0</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>FF03_Order 9 - Strip 3_Area 13_1.0</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>FF03_Order 18 - Strip 1_Area 18_1.0</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>FF03_Order 20 - Strip 3_Area 20_1.0</td>\n",
       "      <td>552</td>\n",
       "      <td>552</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>FF03_Order 23 - Strip 1_Area 23_1.0</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>FF03_Order 41 - Strip 1_Area 34_1.0</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>FF03_Order 45 - Strip 0_Area 35_1.0</td>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>FF03_Order 48 - Strip 1_Area 35_1.0</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>FF03_Order 59 - Strip 3_Area 36_1.0</td>\n",
       "      <td>570</td>\n",
       "      <td>570</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>FF03_Order 65 - Strip 2_Area 37_1.0</td>\n",
       "      <td>587</td>\n",
       "      <td>587</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>FF03_Order 72 - Strip 3_Area 8_1.0</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                conflic_strip_flag_named  max_Norm_TP  this_flag_norm_TP  \\\n",
       "0    FF01_Order 11 - Strip 1_Area 13_1.0          403                403   \n",
       "6    FF01_Order 22 - Strip 3_Area 21_1.0          568                568   \n",
       "11   FF01_Order 30 - Strip 0_Area 27_1.0          555                555   \n",
       "16   FF01_Order 47 - Strip 5_Area 35_1.0          506                506   \n",
       "28   FF01_Order 57 - Strip 0_Area 36_1.0          725                725   \n",
       "49   FF01_Order 64 - Strip 3_Area 37_1.0          555                555   \n",
       "56    FF01_Order 67 - Strip 0_Area 6_1.0          700                700   \n",
       "72    FF01_Order 71 - Strip 1_Area 8_1.0          420                420   \n",
       "80     FF02_Order 4 - Strip 3_Area 0_1.0          525                525   \n",
       "91   FF02_Order 14 - Strip 3_Area 18_1.0          554                554   \n",
       "95   FF02_Order 28 - Strip 3_Area 24_1.0          401                401   \n",
       "96   FF02_Order 29 - Strip 0_Area 26_1.0          409                409   \n",
       "98   FF02_Order 44 - Strip 3_Area 35_1.0          488                488   \n",
       "105  FF02_Order 46 - Strip 3_Area 35_1.0          542                542   \n",
       "118  FF02_Order 53 - Strip 3_Area 36_1.0          591                591   \n",
       "131    FF03_Order 0 - Strip 4_Area 0_1.0          504                504   \n",
       "151   FF03_Order 9 - Strip 3_Area 13_1.0          404                404   \n",
       "156  FF03_Order 18 - Strip 1_Area 18_1.0          612                612   \n",
       "170  FF03_Order 20 - Strip 3_Area 20_1.0          552                552   \n",
       "171  FF03_Order 23 - Strip 1_Area 23_1.0          491                491   \n",
       "181  FF03_Order 41 - Strip 1_Area 34_1.0          701                701   \n",
       "196  FF03_Order 45 - Strip 0_Area 35_1.0          485                485   \n",
       "200  FF03_Order 48 - Strip 1_Area 35_1.0          498                498   \n",
       "209  FF03_Order 59 - Strip 3_Area 36_1.0          570                570   \n",
       "226  FF03_Order 65 - Strip 2_Area 37_1.0          587                587   \n",
       "233   FF03_Order 72 - Strip 3_Area 8_1.0          403                403   \n",
       "\n",
       "     max_Norm_GP  this_flag_norm_GP  max_Norm_LPDD  this_flag_norm_LLDD  \\\n",
       "0          500.0              500.0    1000.000000          1000.000000   \n",
       "6         1000.0             1000.0     752.280794           752.280794   \n",
       "11        1000.0             1000.0     752.280794           752.280794   \n",
       "16         750.0              750.0     908.001084           908.001084   \n",
       "28        1000.0             1000.0     752.280794           752.280794   \n",
       "49        1000.0             1000.0     752.280794           752.280794   \n",
       "56        1000.0             1000.0     908.001084           752.280794   \n",
       "72         500.0              500.0    1000.000000          1000.000000   \n",
       "80         750.0              750.0     908.001084           908.001084   \n",
       "91        1000.0             1000.0     752.280794           752.280794   \n",
       "95         500.0              500.0    1000.000000          1000.000000   \n",
       "96         500.0              500.0    1000.000000          1000.000000   \n",
       "98         750.0              750.0     908.001084           908.001084   \n",
       "105        750.0              750.0     908.001084           908.001084   \n",
       "118       1000.0             1000.0     752.280794           752.280794   \n",
       "131        750.0              750.0     908.001084           908.001084   \n",
       "151        500.0              500.0    1000.000000          1000.000000   \n",
       "156       1000.0             1000.0     752.280794           752.280794   \n",
       "170       1000.0             1000.0     752.280794           752.280794   \n",
       "171        750.0              750.0     908.001084           908.001084   \n",
       "181        500.0              500.0    1000.000000          1000.000000   \n",
       "196        750.0              750.0     908.001084           908.001084   \n",
       "200        750.0              750.0     908.001084           908.001084   \n",
       "209       1000.0             1000.0     752.280794           752.280794   \n",
       "226       1000.0             1000.0     752.280794           752.280794   \n",
       "233        500.0              500.0    1000.000000          1000.000000   \n",
       "\n",
       "              base_time  \n",
       "0   2024-11-13 12:30:44  \n",
       "6   2024-11-13 12:30:44  \n",
       "11  2024-11-13 12:30:44  \n",
       "16  2024-11-13 12:30:44  \n",
       "28  2024-11-13 12:30:44  \n",
       "49  2024-11-13 12:30:44  \n",
       "56  2024-11-13 12:30:44  \n",
       "72  2024-11-13 12:30:44  \n",
       "80  2024-11-13 12:30:44  \n",
       "91  2024-11-13 12:30:44  \n",
       "95  2024-11-13 12:30:44  \n",
       "96  2024-11-13 12:30:44  \n",
       "98  2024-11-13 12:30:44  \n",
       "105 2024-11-13 12:30:44  \n",
       "118 2024-11-13 12:30:44  \n",
       "131 2024-11-13 12:30:44  \n",
       "151 2024-11-13 12:30:44  \n",
       "156 2024-11-13 12:30:44  \n",
       "170 2024-11-13 12:30:44  \n",
       "171 2024-11-13 12:30:44  \n",
       "181 2024-11-13 12:30:44  \n",
       "196 2024-11-13 12:30:44  \n",
       "200 2024-11-13 12:30:44  \n",
       "209 2024-11-13 12:30:44  \n",
       "226 2024-11-13 12:30:44  \n",
       "233 2024-11-13 12:30:44  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['interpret_selected_oppr_conflict_comparision_df']#['conflic_strip_flag_named'].nunique()##['interpret_selected_oppr_conflict_comparision_df']#['interpret_extracted_raw_file_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downlink_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'extracted_raw_file_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m l1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_raw_file_df\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected_oppr_conflict_comparision_df\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKPI_df\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df111 \u001b[38;5;241m=\u001b[39m result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_raw_file_df\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'extracted_raw_file_df'"
     ]
    }
   ],
   "source": [
    "l1 = 'extracted_raw_file_df', 'selected_oppr_conflict_comparision_df', 'KPI_df'\n",
    "df111 = result_dict['extracted_raw_file_df']#.columns\n",
    "#interpret_result_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = img_capture_result[img_capture_result['operation']=='Imaging']#['StripID']#.nunique()\n",
    "Z = img_capture_result[img_capture_result['operation']=='downlinking_from_Readout']\n",
    "Z['duration'] = Z['end_time']- Z['start_time']\n",
    "#Y[Y['StripID']=='']\n",
    "\n",
    "#Y[Y['encoded_strip_id']=='Order 1 - Strip 0_Area 0']\n",
    "Y['StripID'].nunique(),len(Y),len(Z),Z['duration'].sum(),gs_pass_result_df['duration'].sum(),len(gs_pass_result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['SatID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI = Y[Y['SatID']=='FF03']\n",
    "RZO = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "CR = RZO[RZO['SatID']=='FF03']\n",
    "pd.concat([CI,CR]).sort_values(by='start_time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Order 1 - Strip 0_Area 0'\n",
    "RZO = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "RZO[RZO['SatID']=='FF01']\n",
    "RZO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RZ = capture_plan_data_input['dedicated_readout_df']\n",
    "len(RZ[RZ['SatID']=='FF01'].sort_values(by='start_time')),len(RZ[RZ['SatID']=='FF02'].sort_values(by='start_time')),len(RZ[RZ['SatID']=='FF03'].sort_values(by='start_time'))\n",
    "RZ[RZ['SatID']=='FF01'].sort_values(by='start_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_capture_result['operation'].unique()\n",
    "\n",
    "[ item for item in capture_plan_data_input['Memory_NoimageGs_TW_list'] if item[2]=='FF01']\n",
    "#capture_plan_data_input['dedicatedReadoutTWlist__concat_sat_memoryTWindex']['FF01_136.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['active_assured_strip_id_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_eclipse_data.csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eclipse_df[eclipse_df['eclipse']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse_df.sort_values(by='time_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SatID,start_time,end_time,eclipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['GS_pass_df', 'image_opportunity_df', 'image_downlink_df', 'eclipse_df_dict', 'config']\n",
    "#input_dict['eclipse_df_dict']['FF02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['readout_memory_capacity__s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['imgery_sat_id_list']#.keys()\n",
    "[s+'_'+str(n) for s in capture_plan_data_input['imgery_sat_id_list']+capture_plan_data_input['only_gs_sat_id_list'] \\\n",
    " if s in capture_plan_data_input['dedicatedReadoutTWIndex__sat'].keys() for n in capture_plan_data_input['dedicatedReadoutTWIndex__sat'][s]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "\n",
    "#eclipse_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['active_assured_strip_id_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['assured_tasking_based_on_input_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['cs1j2k2Domainlist__cs1j1k1']['FF01_Order 1 - Strip 0_Area 0_1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['GS_Pass_time_objective'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(img_capture_result[img_capture_result['operation']=='Imaging'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run till here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "memory_plot_df = result_dict['combined_result']\n",
    "\n",
    "#memory_plot_df.columns\n",
    "#memory_plot_df[['SatID','camera_memory_value_endofTW','delta_camera_memory_value_in_this_TW','base_time','OpportunityStartOffset','OpportunityEndOffset#']]\n",
    "memory_plot_df = memory_plot_df[['SatID','start_time','end_time','operation','camera_memory_value_endofTW','delta_camera_memory_value_in_this_TW','base_time']]\n",
    "memory_plot_df.sort_values(by=['SatID','start_time'],inplace=True)\n",
    "\n",
    "memory_plot_df['till_now_max'] = memory_plot_df.groupby('SatID')['end_time'].cummax()\n",
    "memory_plot_df['prev_max'] = memory_plot_df.groupby('SatID')['till_now_max'].shift(1)\n",
    "\n",
    "memory_plot_df1 = memory_plot_df[memory_plot_df['start_time'] > memory_plot_df['prev_max'] + 1] \n",
    "memory_plot_df1['start_time1'] = memory_plot_df1['prev_max'] + 1 #TODO1 +1 is okay ?\n",
    "memory_plot_df1['end_time1'] = memory_plot_df1['start_time'] - 1\n",
    "memory_plot_df1['operation'] = 'idle'\n",
    "\n",
    "memory_plot_df1 = memory_plot_df1[['SatID','start_time1','end_time1','operation','base_time']]\n",
    "\n",
    "#memory_plot_df1 = memory_plot_df1.drop(['start_time', 'end_time','till_now_max','prev_max'], axis=1)\n",
    "memory_plot_df1.rename(columns={'start_time1':'start_time','end_time1':'end_time'},inplace=True)\n",
    "#imgGS_union_df1 ==> contains TW without img and without gs pass  table without eclipse divide\n",
    "final_memory_plot_df = pd.concat([memory_plot_df,memory_plot_df1])\n",
    "final_memory_plot_df.sort_values(by=['SatID','start_time'],inplace=True)\n",
    "\n",
    "final_memory_plot_df['camera_memory_value_endofTW'] = final_memory_plot_df['camera_memory_value_endofTW'].ffill()\n",
    "final_memory_plot_df['delta_camera_memory_value_in_this_TW'] = final_memory_plot_df['delta_camera_memory_value_in_this_TW'].fillna(0)\n",
    "final_memory_plot_df['start_time'] = final_memory_plot_df[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "final_memory_plot_df['end_time'] = final_memory_plot_df[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "final_memory_plot_df = final_memory_plot_df[['SatID','start_time','end_time','camera_memory_value_endofTW','delta_camera_memory_value_in_this_TW','operation','base_time']]\n",
    "sat_list = final_memory_plot_df['SatID'].unique()\n",
    "#sat_list = ['FF01']\n",
    "\n",
    "\n",
    "colors = {\n",
    "        \"Imaging\": \"blue\",\n",
    "        \"downlinking_from_Readout\": \"green\",\n",
    "        \"Readout\": \"red\",\n",
    "        \"idle\": \"gray\"\n",
    "    }\n",
    "\n",
    "\n",
    "for s in sat_list:\n",
    "    this_plot_df = final_memory_plot_df[final_memory_plot_df['SatID']==s]\n",
    "    start_time_list = this_plot_df['start_time'].to_list()\n",
    "    end_time_list = this_plot_df['end_time'].to_list()\n",
    "    operation_list = this_plot_df['operation'].to_list()\n",
    "\n",
    "    camera_memory_value_endofTW_list = this_plot_df['camera_memory_value_endofTW'].to_list()\n",
    "    this_plot_df['camera_memory_value_startofTW_list'] = this_plot_df['camera_memory_value_endofTW'].shift(1)\n",
    "\n",
    "    first_row_list = this_plot_df.values.tolist()[0]\n",
    "    first_row_operation = first_row_list[5]\n",
    "    first_row_memory_val = first_row_list[3]\n",
    "    ortherwise_memory_val =  first_row_list[3] - first_row_list[4]\n",
    "    if first_row_operation not in['Imaging','Readout']:\n",
    "        this_plot_df['camera_memory_value_startofTW_list'] = this_plot_df['camera_memory_value_startofTW_list'].fillna(first_row_memory_val)\n",
    "    else:\n",
    "        this_plot_df['camera_memory_value_startofTW_list'] = this_plot_df['camera_memory_value_startofTW_list'].fillna(ortherwise_memory_val)\n",
    "\n",
    "    camera_memory_value_StartofTW_list = this_plot_df['camera_memory_value_startofTW_list'].to_list()\n",
    "    \n",
    "    time_list = list(itertools.chain.from_iterable(zip(start_time_list,end_time_list )))\n",
    "    operation_list = list(itertools.chain.from_iterable(zip(operation_list,operation_list )))\n",
    "    camera_memory_value_list = list(itertools.chain.from_iterable(zip(camera_memory_value_StartofTW_list,camera_memory_value_endofTW_list )))\n",
    "    df = pd.DataFrame({'time':time_list,'operation':operation_list,'memory':camera_memory_value_list})\n",
    "\n",
    "    this_list = this_plot_df.values.tolist()\n",
    "    # Plot using Plotly Express\n",
    "    # fig = px.line(this_plot_df, x='start_time', y='camera_memory_value_endofTW', color='operation', line_group='operation',\n",
    "    #             title=\"Memory Usage of Different Operations\")\n",
    "    \n",
    "    # fig.add_trace(go.Scatter(\n",
    "    #                         x=time_list,\n",
    "    #                         y=camera_memory_value_list,\n",
    "    #                         mode='lines+markers+text',\n",
    "    #                         #name=operation_list,\n",
    "    #                         #line=dict(color=colors.get(operation, 'black'), width=2),\n",
    "    #                         #text=[f\"({start_time}, {current_memory:.2f})\", f\"({end_time}, {end_memory:.2f})\"],\n",
    "    #                         #textposition=text_position\n",
    "    #                     ))\n",
    "    \n",
    "    # fig.show()\n",
    "    \n",
    "    for item in this_list:\n",
    "            start_time = item[1]\n",
    "            end_time = item[2]\n",
    "            current_memory = item[6]\n",
    "            end_memory = item[3]\n",
    "            operation = item[5]\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                            x=[start_time, end_time],\n",
    "                            y=[current_memory, end_memory],\n",
    "                            mode='lines+markers+text',\n",
    "                            name=operation+'_'+s,\n",
    "                            line=dict(color=colors.get(operation, 'black'), width=2),\n",
    "                            #text=[f\"({start_time}, {current_memory:.2f})\", f\"({end_time}, {end_memory:.2f})\"],\n",
    "                            #textposition=text_position\n",
    "                        ))\n",
    "\n",
    "    #     # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"Memory Profile Over Time\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Memory\",\n",
    "        legend_title=\"Operations\",\n",
    "          )\n",
    "    # names = set()\n",
    "    # fig.for_each_trace(\n",
    "    #     lambda trace:\n",
    "    #         trace.update(showlegend=False)\n",
    "    #         if (trace.name in names) else names.add(trace.name))\n",
    "\n",
    "    # Save figure as HTML\n",
    "    html_filename = \"memory_profile_.html\"\n",
    "    fig.write_html('5_output_data'+'/'+html_filename)\n",
    "\n",
    "# final_memory_plot_df[final_memory_plot_df['SatID']=='FF01'].sort_values(by='start_time')\n",
    "\n",
    "import pygwalker as pyg\n",
    "pyg.walk(final_memory_plot_df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import os\n",
    "from preprocess_1.preprocess_GSpassSelecion import GSPassPreprocess\n",
    "from model_3.MILP_GSpassSelection_v3 import GSpassSelection\n",
    "from postprocess_4.postprocess_GSpassSelection import GSpasspostprocess\n",
    "\n",
    "from preprocess_1.preprocess_imageAqusuition_test import ImageAquisitionProcess #preprocess_imageAqusuition_test,preprocess_imageAquisition_v3_18112024\n",
    "from model_3.MILP_imageCapture_v3_17112024 import ImageCapturePlan # MILP_imageCapture_v2_16102024,MILP_imageCapture_v2_25102024 # MILP_imageCapture_v2_07112024 #MILP_imageCapture_v3_17112024\n",
    "from postprocess_4.image_capture_postprocess_V3_17112024 import ImagecapturePostProcess # image_capture_postprocess_V3_17112024# image_capture_postprocess_v2_18102024\n",
    "\n",
    "from preprocess_1.preprocess_downlink_WIP import DownlinkingPreProcess\n",
    "from model_3.MILP_downlink import ImageDownlinkPlan\n",
    "from postprocess_4.postprocess_downlink import ImageDownlinkPostProcess\n",
    "\n",
    "from result_interpret import interpret_result\n",
    "from utils import *\n",
    "\n",
    "# script_dir = os.path.abspath( os.path.dirname( __file__ ) )\n",
    "# print(\"script directory: \",script_dir)\n",
    "'''\n",
    "readout is happening after the last image and before entering the eclipse region.\n",
    "Any heating operation will start if the temp reaches around intial tempertaure.\n",
    "Higher number of Global priority is assumed to be Higher prior Important image.\n",
    "if end date of due date is less than 24 hrs from the reference time offset then it is going to assured tasking.\n",
    "Need offset from when scheduling is started. Example if scheduling is  needed from 10:00AM to 11 PM . Then offset is needed from 10:00 AM or 09:59 AM. Due date based assured tasking is the reason.\n",
    "Iniial Camera Memory is needed at the start of the any oppr imaging/gsPass whichever is first. \n",
    "Iniial Readout Memory is needed at the start of the readout oppr.\n",
    "Initial power is needed at start of the opportunity(imaging/gspass).For Now (since power constraint is not there for readout)\n",
    "Iniial thermal value is needed before the start of the oppr imaging/gsPass/readout according to device (for NCCms:readout , for camera detector: Imaging ,For XBT : gs Pass oppr).\n",
    "Eclipse Event should be starting from first oppr either gsPass/Imaging. Readout is happening after the first imaging so i guess not needed at readout.\n",
    "'''\n",
    "'''\n",
    "Need offset from when scheduling is started. Example if scheduling is  needed from 10:00AM to 11 PM . Then offset is needed from 10:00 AM or 09:59 AM.\n",
    "Iniial Memory,power and thermal value is needed at 10:00 AM\n",
    "'''\n",
    "def select_gs_pass_oppr(GS_pass_df,config):\n",
    "\n",
    "    obj_preprocess = GSPassPreprocess(GS_pass_df)\n",
    "    data = obj_preprocess.preprocess()\n",
    "\n",
    "    obj_model = GSpassSelection(data,config)\n",
    "    result,thermal_profile_gsPass = GSpasspostprocess(obj_model,data,config).get_gsPasses()# 21 seconds\n",
    "\n",
    "    try :\n",
    "        result['duration'] = result['end_time'] - result['start_time']\n",
    "        result = result[result['duration']> 0]\n",
    "    except:\n",
    "        print(\"model is not converged or infeasible or not solved\")\n",
    "\n",
    "    return result\n",
    "    \n",
    "\n",
    "def select_img_opprtunity(image_opportunity_df,gs_pass_result_df,eclipse_df_dict,config):\n",
    "\n",
    "    #basic flters\n",
    "    #image_opportunity_df = image_opportunity_df[image_opportunity_df['OpportunityEndOffset']<config['scheduled_Hrs']*3600]\n",
    "    image_opportunity_df = image_opportunity_df[image_opportunity_df['CloudCoverLimit']>image_opportunity_df['CloudCover']]\n",
    "    image_opportunity_df = image_opportunity_df[image_opportunity_df['OffNadirLimit']>image_opportunity_df['OffNadir']]\n",
    "\n",
    "    obj_preprocess = ImageAquisitionProcess(image_opportunity_df,gs_pass_result_df,eclipse_df_dict,config)\n",
    "    data = obj_preprocess.preprocess()\n",
    "    #print(data['cs1j2k2Domainlist__cs1j1k1'])\n",
    "\n",
    "    #++++++++++++++++++++++++++  STEP 0  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    '''\n",
    "    hard code some data\n",
    "    '''\n",
    "    data['camera_memory_capacity__s'] = {s:v for s,v in data['camera_memory_capacity__s'].items() }\n",
    "    data['readout_memory_capacity__s'] = {s:v for s,v in data['readout_memory_capacity__s'].items() }\n",
    "    data['power_capacity__s']  = {s:720000000 for s,v in data['power_capacity__s'].items() }\n",
    "    data['initial_power_value__s']  = {s:v*0.3 for s,v in data['power_capacity__s'].items() }\n",
    "    #++++++++++++++++++++++++++  STEP 1  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    config['objective']['GS_Pass_time'] = True\n",
    "    config['objective']['total_priority'] = False\n",
    "    config['objective']['total_readout_memory'] = False\n",
    "    obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    #Readout Schedule \n",
    "    # data['GS_Pass_time_objective'] = obj_model.prob.objective.value()\n",
    "    # config['objective']['GS_Pass_time'] = False\n",
    "    # config['objective']['total_priority'] = False\n",
    "    # config['objective']['total_readout_memory'] = True\n",
    "    # obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    #++++++++++++++++++++++++++  STEP 2  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    # config['objective']['GS_Pass_time'] = False\n",
    "    # config['objective']['total_priority'] = True\n",
    "    # #config['objective']['total_readout_memory'] = False\n",
    "\n",
    "    # obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    # data['total_priority_objective'] = obj_model.prob.objective.value()\n",
    "    #++++++++++++++++++++++++++  STEP 3  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    # config['objective']['total_priority'] = False\n",
    "    # config['objective']['total_readout_memory'] = True\n",
    "\n",
    "    # obj_model = ImageCapturePlan(data,config)\n",
    "    #++++++++++++++++++++++++++  PostProcess  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    post_obj = ImagecapturePostProcess(obj_model,data)\n",
    "    img_capture_result= post_obj.get_schedule()\n",
    "    #.isnull().sum()\n",
    "    return img_capture_result,data\n",
    "    \n",
    "\n",
    "    #======================================================================================================================================================================================================\n",
    "\n",
    "    pass\n",
    "\n",
    "def get_aps_success_metric(img_capture_result,data):\n",
    "    after_aps_plan_df = img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "    criteria_list = ['total_opprtunities_ratio','GP_ratio','LP_ratio','conflictImg_gsPass']\n",
    "\n",
    "    total_conflict_images_list= [data['success_metric_before']['conflict_images']]\n",
    "    GP_before = data['success_metric_before']['original_Total_GP']\n",
    "    LP_before = data['success_metric_before']['original_Total_LP']\n",
    "    TOppr_before = data['success_metric_before']['total_opportunities'] \n",
    "    before_list = [TOppr_before,GP_before,LP_before,total_conflict_images_list]\n",
    "\n",
    "    GP_after= after_aps_plan_df['mean_global_priority'].sum()\n",
    "    LP_after = after_aps_plan_df['mean_local_priority'].sum()\n",
    "    TOppr_after= after_aps_plan_df['encoded_strip_id'].nunique()\n",
    "    fraction_conflict_images_list = [list(after_aps_plan_df[after_aps_plan_df['encoded_strip_id'].isin(total_conflict_images_list)]['encoded_strip_id'].unique())]\n",
    "    after_list = [TOppr_after,GP_after,LP_after,fraction_conflict_images_list]\n",
    "\n",
    "    APS_success_metric_df = pd.DataFrame({'criteria':criteria_list,'potential_input':before_list,'APS_selected':after_list})\n",
    "    #APS_success_metric_df['percentage'] = APS_success_metric_df['APS_selected'] / APS_success_metric_df['potential_input']\n",
    "    APS_success_metric_df1 = APS_success_metric_df[:-1]\n",
    "    APS_success_metric_df1['percentage'] = APS_success_metric_df1['APS_selected'] / APS_success_metric_df1['potential_input'] * 100\n",
    "    APS_success_metric_df2 = APS_success_metric_df[-1:]\n",
    "\n",
    "    APS_success_metric_df = pd.concat([APS_success_metric_df1,APS_success_metric_df2])\n",
    "\n",
    "    return APS_success_metric_df\n",
    "    \n",
    "\n",
    "def get_downlink_schedule(image_downlink_df,img_capture_result,config):\n",
    "\n",
    "    downlink_operation_list  = ['downlinking_from_camera','downlinking_from_Readout']\n",
    "    img_capture_result_downlink = img_capture_result[img_capture_result['operation'].isin(downlink_operation_list)]\n",
    "    DownlinkingPreProcessObj = DownlinkingPreProcess(image_downlink_df,img_capture_result_downlink,config)\n",
    "    data_downlink = DownlinkingPreProcessObj.preprocess()\n",
    "    \n",
    "    if config['downlink_schedule_OnlyJustsortImgID']:\n",
    "        downlink_result = pd.DataFrame(data_downlink['LP_DD_Priority_imgID'].items(),columns=['ImageID','computed_priority']).\\\n",
    "            sort_values(by='computed_priority',ascending=False)\n",
    "    else:\n",
    "        obj_downlink_model = ImageDownlinkPlan(data_downlink,config)\n",
    "        downlink_result = ImageDownlinkPostProcess(obj_downlink_model,data_downlink).get_schedule()\n",
    "        downlink_result = downlink_result[downlink_result['TileStripNo_downLoad']!=0]\n",
    "\n",
    "    return downlink_result\n",
    "    \n",
    "def schedule():\n",
    "\n",
    "    pass\n",
    "\n",
    "def get_input_files(config):\n",
    "    # GS PASS\n",
    "    #GS_pass_df = pd.read_csv(config[\"csv_file_path\"][\"gs_pass_opportunity\"])#APS_gsPasses_TV1#GS_Passes_mock1#GS_Passes_live1#GS_Passes_new (1)\n",
    "    \n",
    "    GS_pass_df = pd.read_csv(\"1_input_data/GS_Passes_new (1).csv\")\n",
    "    GS_pass_df['SatID'] = GS_pass_df['SatID'].astype(str)\n",
    "    GS_pass_df['AOSOffset'] = GS_pass_df['AOSOffset'].astype(int)\n",
    "    GS_pass_df['LOSOffset'] = GS_pass_df['LOSOffset'].astype(int)\n",
    "\n",
    "    # image Opprtunity\n",
    "    image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])#Imaging_mock1#APS_imagingOpportunities_TV1#Imaging_live#Imaging_new (1)\n",
    "    # change made priority ulta\n",
    "    #image_opportunity_df['Priority'] = 1/image_opportunity_df['Priority']\n",
    "    \n",
    "    image_opportunity_df['SatID'] = image_opportunity_df['SatID'].astype(str)\n",
    "    image_opportunity_df['OpportunityStartOffset'] = image_opportunity_df['OpportunityStartOffset'].astype(int)\n",
    "    image_opportunity_df['OpportunityEndOffset'] = image_opportunity_df['OpportunityEndOffset'].astype(int)\n",
    "    image_opportunity_df_copy = image_opportunity_df.copy()\n",
    "    image_opportunity_df_copy['X'] = image_opportunity_df_copy[['OpportunityStartTime','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['OpportunityStartTime']) - pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)\n",
    "    image_opportunity_df_copy['Y'] = image_opportunity_df_copy[['OpportunityEndTime','OpportunityEndOffset']].apply(lambda a: pd.to_datetime(a['OpportunityEndTime']) - pd.DateOffset(seconds=a['OpportunityEndOffset']),axis=1)\n",
    "    base_time_stamp = image_opportunity_df_copy[\"X\"].to_list()[0]\n",
    "    config['base_time_stamp_downlink'] = base_time_stamp\n",
    "\n",
    "    #image Downlink\n",
    "    image_downlink_df = pd.read_csv(config[\"csv_file_path\"][\"image_downlink_file\"])\n",
    "    image_downlink_df['assured_downlink_flag'] = [0,0] +[0]*(len(image_downlink_df)-2)\n",
    "    image_downlink_df['delivery_type'] = 'standard_delivery' # expedited_delivery,super_expedited_delivery\n",
    "    union_list_of_sat = list(set(image_opportunity_df['SatID']).union(set(GS_pass_df['SatID'])).union(set(image_downlink_df['SatID'])))\n",
    "    hrs = config['scheduled_Hrs']\n",
    "\n",
    "    # get dummy eclipse data close to reality\n",
    "    #eclipse_df = pd.DataFrame()\n",
    "    #for sat in satellite_list:\n",
    "        #this_eclipse_df = eclipse_event_df[eclipse_event_df['SatID']==sat]\n",
    "        #that_eclipse_df = get_eclipse_data(this_eclipse_df,config)\n",
    "        #eclipse_df = pd.concat([that_eclipse_df,eclipse_df])\n",
    "        \n",
    "    min_time_index= min([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "    max_time_index= max([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "\n",
    "    hrs = (max_time_index - min_time_index)/3600\n",
    "    hrs = math.ceil(hrs)\n",
    "    while True:\n",
    "        hrs += 1\n",
    "        if hrs % 1.5==0:\n",
    "            break\n",
    "\n",
    "\n",
    "    in_orbit_eclipse_event = [1 for i in range(int(1.5*3600*0.6))] + [0 for i in range(int(1.5*3600*0.4))] #\n",
    "    eclipse_df  = pd.DataFrame({'time_index': [i for i in range(min_time_index,min_time_index+hrs*3600)] ,\"eclipse\" : in_orbit_eclipse_event*int(hrs/1.5)})\n",
    "    eclipse_df['SatID']= [union_list_of_sat] *len(eclipse_df)\n",
    "    eclipse_df = eclipse_df.explode('SatID')\n",
    "    eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "\n",
    "    #eclipse_df = pd.DataFrame()\n",
    "    #for sat in satellite_list:\n",
    "        #this_eclipse_df = eclipse_event_df[eclipse_event_df['SatID']==sat]\n",
    "        #that_eclipse_df = get_eclipse_data(this_eclipse_df,config)\n",
    "        #eclipse_df = pd.concat([that_eclipse_df,eclipse_df])\n",
    "   #eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "\n",
    "    \n",
    "    # get dummy data for assured tasking\n",
    "    image_opportunity_df['encoded_stripId'] =   image_opportunity_df['StripID'].astype(str)+ '_' + image_opportunity_df['AoiID'].astype(str)\n",
    "    total_capture_list = list(image_opportunity_df['encoded_stripId'].unique())\n",
    "    no_of_list = len(total_capture_list)\n",
    "    assured_capture_df = pd.DataFrame({'encoded_stripId':total_capture_list,'assured_task':[0,0]+[0]*(no_of_list-2)})\n",
    "    image_opportunity_df = pd.merge(image_opportunity_df,assured_capture_df,on='encoded_stripId',how='left')\n",
    "    image_opportunity_df = image_opportunity_df.drop(columns=['encoded_stripId'])\n",
    "\n",
    "    # further processing eclipse data to align with gs pass where entire gs pass is assumed to be in eclipse region\n",
    "    gsPassInput_df_copy = pd.read_csv(config[\"csv_file_path\"][\"gs_pass_opportunity\"])\n",
    "    gsPassInput_df_copy['SatID'] = gsPassInput_df_copy['SatID'].astype(str)\n",
    "    gsPassInput_df_copy['AOSOffset'] = gsPassInput_df_copy['AOSOffset'].astype(int)\n",
    "    gsPassInput_df_copy['LOSOffset'] = gsPassInput_df_copy['LOSOffset'].astype(int)\n",
    "    gsPassInput_df_copy['list'] =  gsPassInput_df_copy[['AOSOffset','LOSOffset']].apply(lambda a : [i for i in range(a['AOSOffset'],a['LOSOffset']+1)],axis =1 )\n",
    "\n",
    "    gsPassInput_df_copy1 = gsPassInput_df_copy[['SatID','list']]\n",
    "    gsPassInput_df_copy1 = gsPassInput_df_copy1.explode('list')\n",
    "    gsPassInput_df_grouped_copy1 = gsPassInput_df_copy1.groupby('SatID').agg(time_index_list = ('list',list)).reset_index()\n",
    "    gsPasstimeIndexList__s = dict(zip(gsPassInput_df_grouped_copy1['SatID'],gsPassInput_df_grouped_copy1['time_index_list']))\n",
    "    for k,v in eclipse_df_dict.items():\n",
    "        if k in gsPasstimeIndexList__s.keys():\n",
    "            this_time_index_list = gsPasstimeIndexList__s[k]\n",
    "            v.loc[v[\"time_index\"].isin(this_time_index_list), \"eclipse\"] = 1\n",
    "            eclipse_df_dict[k] = v\n",
    "\n",
    "    return {\n",
    "            'GS_pass_df':GS_pass_df,\\\n",
    "            'image_opportunity_df':image_opportunity_df,\\\n",
    "            'image_downlink_df':image_downlink_df,\\\n",
    "            \"eclipse_df_dict\": eclipse_df_dict,\n",
    "            \"config\":config\n",
    "            }\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Open and read the JSON file\n",
    "    with open('1_input_data/config.json', 'r') as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "    # if memory constraint False then thermal_constraint is also False\n",
    "        config['constraints']['thermal_constraint_readout'] = config['constraints']['memory_constrant'] and config['constraints']['thermal_constraint_readout']\n",
    "        config['constraints']['thermal_constraint_imaging'] = config['constraints']['memory_constrant'] and config['constraints']['thermal_constraint_imaging']\n",
    "\n",
    "    #======================================================================================================================================================================================================\n",
    "    # read_input\n",
    "    input_dict = get_input_files(config)\n",
    "    config = input_dict['config']\n",
    "    #======================================================================================================================================================================================================\n",
    "    #gs pass_selection\n",
    "    gs_pass_result_df = select_gs_pass_oppr(input_dict['GS_pass_df'],config)\n",
    "    gs_pass_result_df['Eclipse'] = 1 ## dummy\n",
    "    gs_pass_result_df['duration'] = gs_pass_result_df['end_time'] - gs_pass_result_df['start_time']\n",
    "    gs_pass_result_df = gs_pass_result_df[gs_pass_result_df['duration']> 0]\n",
    "    interpret_gs_pass_result_df_copy = gs_pass_result_df.copy()# this not the gsPass result as it is to be get filtered after due to other factors in image capture plan.It is just to get require info in interpret result.\n",
    "\n",
    "    print(\"image_capture_plan_starting\")\n",
    "    #======================================================================================================================================================================================================\n",
    "    #image_selection\n",
    "    img_capture_result,capture_plan_data_input= select_img_opprtunity(input_dict['image_opportunity_df'],gs_pass_result_df,input_dict['eclipse_df_dict'],config)\n",
    "    img_capture_result['base_time'] = config['base_time_stamp_downlink']\n",
    "    #img_capture_result = img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "    #readout_result = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "    interpret_img_capture_resul_copy = img_capture_result.copy()\n",
    "    #======================================================================================================================================================================================================\n",
    "    # get APS success metrics \n",
    "    APS_success_metric_df = get_aps_success_metric(img_capture_result,capture_plan_data_input)\n",
    "    #======================================================================================================================================================================================================\n",
    "    print(\"Downlink_plan_starting\")\n",
    "    try:\n",
    "        print(dfd)\n",
    "        downlink_result = get_downlink_schedule(input_dict['image_downlink_df'],img_capture_result,config)\n",
    "    except:\n",
    "        print(\"downlink_schedule_has_some_error\")\n",
    "        downlink_result = pd.DataFrame()\n",
    "    downlink_result['base_time'] = config['base_time_stamp_downlink']\n",
    "    #======================================================================================================================================================================================================\n",
    "    #img_capture_result[img_capture_result['download_from_']]\n",
    "    gs_pass_result_df.to_csv(\"5_output_data/gs_pass_result_df.csv\",index=None)\n",
    "    img_capture_result.to_csv(\"5_output_data/img_capture_schedule.csv\",index=None)\n",
    "    APS_success_metric_df.to_csv(\"5_output_data/APS_success_metric.csv\",index = None)\n",
    "    downlink_result.to_csv(\"5_output_data/downlink_result.csv\",index = None)\n",
    "\n",
    "    interpret_image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])\n",
    "    interpret_result_dict = interpret_result(interpret_image_opportunity_df,interpret_gs_pass_result_df_copy,interpret_img_capture_resul_copy,config)\n",
    "    for k,v in interpret_result_dict.items():\n",
    "        v['base_time'] = config['base_time_stamp_downlink']\n",
    "        v.to_csv(\"5_output_data/\"+k+\".csv\",index = None)\n",
    "\n",
    "    \n",
    "    only_img_capture_result = img_capture_result[img_capture_result['operation']=='Imaging'][['SatID','start_time','end_time','AoiID','StripID','base_time']]\n",
    "    only_img_capture_result['start_time'] = only_img_capture_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "    only_img_capture_result['end_time'] = only_img_capture_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "    only_readout_result = img_capture_result[img_capture_result['operation']=='Readout'][['SatID','start_time','end_time','base_time']]\n",
    "    only_readout_result['start_time'] = only_readout_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "    only_readout_result['end_time'] = only_readout_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "    result_dict = {\"only_readout_result\":only_readout_result,\\\n",
    "                  \"only_img_capture_result\":only_img_capture_result}\n",
    "    result_dict.update(interpret_result_dict)\n",
    "\n",
    "    #print(only_img_capture_result,only_readout_result,downlink_result)\n",
    "#config['constraints'] = ['Thermal_constraints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conflicting_dict(self,df,data_dict,different_setup_time,conflicting_on = 'GsID',concat_filter ='concat_gsid_satid_TWIndex',LOS_column='LOSOffset',AOS_column='AOSOffset'):\n",
    "\n",
    "    for on_item in df[conflicting_on].unique():\n",
    "        this_df = df[df[conflicting_on] == on_item ]\n",
    "        # if different_master_key:\n",
    "        #     data_dict[different_master_key]['sgk_list'] [on_item] = this_df[concat_filter].unique()\n",
    "        for csgk in this_df[concat_filter].unique():\n",
    "            that_df = this_df[this_df[concat_filter] == csgk]\n",
    "            this_LOS = list(that_df[LOS_column].unique())[0]\n",
    "            this_AOS = list(that_df[AOS_column].unique())[0]\n",
    "\n",
    "\n",
    "            that_df1 = this_df[this_df[AOS_column] >= different_setup_time  + this_LOS]\n",
    "            that_df2 = this_df[this_df[LOS_column] <= this_AOS - different_setup_time]\n",
    "            that_df3 = pd.concat([that_df1,that_df2])\n",
    "            \n",
    "            not_needed = list(that_df3[concat_filter].unique())\n",
    "            that_df = this_df[~this_df[concat_filter].isin(not_needed)]\n",
    "\n",
    "            that_df = that_df[that_df[concat_filter] != csgk]\n",
    "\n",
    "            # if different_master_key:\n",
    "            #     data_dict[different_master_key]['domain_of_csgk'] [csgk] = list(that_df[concat_filter].unique())\n",
    "            # else:\n",
    "            data_dict[csgk] = list(that_df[concat_filter].unique())\n",
    "                \n",
    "    return data_dict \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def evaluate_eqn(t,temp_eqn):\n",
    "    t = t\n",
    "    return eval(temp_eqn)\n",
    "\n",
    "\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "heat_eqn = \"0.0000000728690314 * t**3 - 0.000138692964 * t**2 + 0.103057817 * t  + 1.88504399 \"\n",
    "# y = \"math.exp(x)\"\n",
    "T = 25\n",
    "initial_temp = 25\n",
    "limit_temp = initial_temp + 3\n",
    "\n",
    "\n",
    "a20 = -13.339128\t\n",
    "b20 = 0.504271\t\n",
    "c20 = 0.581774\n",
    "\n",
    "a40 = -13.503356\t\n",
    "b40 = 0.655062\t\n",
    "c40 = 0.397629\n",
    "\n",
    "y20 = 54.9\n",
    "y40 = 70.6\n",
    "\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    " \n",
    "Y = [[-13.339128,-13.503356],[0.504271,0.655062],[0.581774,0.397629],[y20,y40]]\n",
    "X = [[20,40],[20,40],[20,40],[20,40]]\n",
    " \n",
    "# test value\n",
    "interpolate_x = initial_temp\n",
    " \n",
    "# Finding the interpolation\n",
    "l1 =[]\n",
    "for i in range(4):\n",
    "    y_interp = interp1d(X[i], Y[i])\n",
    "    l1.append(y_interp(interpolate_x))\n",
    "\n",
    "# print(\"Value of Y at x = {} is\".format(interpolate_x),\n",
    "#       y_interp(interpolate_x))\n",
    "cool_eqn = str(l1[2])+\"*math.exp(1*t*\"+str(l1[0])+\")+\"+str(l1[1])\n",
    "x = 2\n",
    "#eval(y)\n",
    "temp_profile_df = pd.DataFrame()\n",
    "for i in range(1):\n",
    "    df = pd.DataFrame({\"time_index\":[i for i in range(1,T*60)]})\n",
    "    df['epoch'] = str(i)+'_'+'heat'\n",
    "    df['delta_temp_heat'] = df['time_index'].apply(lambda a:evaluate_eqn(a,temp_eqn = heat_eqn) ) \n",
    "    df['initial_temp'] =  initial_temp\n",
    "    df['temp']=df['delta_temp_heat']  + df['initial_temp']\n",
    "    df = df[df['temp']<=70]\n",
    "    #print(df)\n",
    "    max_heat_temp = df['temp'].max()\n",
    "    print(max_heat_temp)\n",
    "    df_cool = pd.DataFrame({\"time_index\":[i for i in range(1,T*60)]})\n",
    "    df_cool['epoch'] = str(i)+'_'+'cool'\n",
    "    df_cool[\"time_index_new\"] = df_cool[\"time_index\"]/1800\n",
    "    df_cool['delta_temp'] = df_cool['time_index_new'].apply(lambda a:evaluate_eqn(a,temp_eqn = cool_eqn) ) \n",
    "    df_cool['y'] = df_cool['delta_temp']\n",
    "    df_cool['delta_temp'] = df_cool['delta_temp']* l1[3]\n",
    "    df_cool['initial_temp'] = max_heat_temp\n",
    "    df_cool['temp'] = df_cool['initial_temp'] - df_cool['delta_temp'] \n",
    "\n",
    "    df_cool['temp'] = df_cool['delta_temp']#* l1[3]\n",
    "    \n",
    "    df_cool_check = df_cool[df_cool['temp']<= limit_temp]\n",
    "    cooled_upto = df_cool_check['temp'].max()\n",
    "    #df_cool = df_cool[df_cool['temp']>=limit_temp]\n",
    "    initial_temp = cooled_upto\n",
    "    \n",
    "    this_df = pd.concat([df,df_cool])\n",
    "    temp_profile_df = pd.concat([temp_profile_df,this_df])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# df[\"time_index_new\"] = df[\"time_index\"]/60/1800\n",
    "# df['delta_temp'] = df['time_index_new'].apply(lambda a:evaluate_eqn(a,temp_eqn = cool_eqn) ) \n",
    "# #\n",
    "# xs = np.arange(10)\n",
    "# ys = 2*xs + 1\n",
    "\n",
    "# interp_func = interp1d(xs, ys)\n",
    "\n",
    "# newarr = interp_func(np.arange(2.1, 3, 0.1))\n",
    "\n",
    "# print(newarr)\n",
    "# eval(Y, globals, locals)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_eqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df#[df['time_index']<=25*60]\n",
    "df_cool['delta_temp'].max()\n",
    "df_cool\n",
    "temp_profile_df\n",
    "df_cool\n",
    "#df#[df['time_index']==1499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_profile_df[temp_profile_df['epoch']=='1_cool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"math.exp(x)\"\n",
    "x = 1\n",
    "eval(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
