{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import pandas as pd\n",
    "# with open('1_input_data/config.json', 'r') as file:\n",
    "#         config = json.load(file)\n",
    "# image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])\n",
    "\n",
    "# image_opportunity_df['SatID'] = image_opportunity_df['SatID'].astype(str)\n",
    "# image_opportunity_df['OpportunityStartOffset'] = image_opportunity_df['OpportunityStartOffset'].astype(int)\n",
    "# image_opportunity_df['OpportunityEndOffset'] = image_opportunity_df['OpportunityEndOffset'].astype(int)\n",
    "# image_opportunity_df_copy = image_opportunity_df.copy()\n",
    "# image_opportunity_df_copy['X'] = image_opportunity_df_copy[['OpportunityStartTime','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['OpportunityStartTime']) - pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)\n",
    "# image_opportunity_df_copy['Y'] = image_opportunity_df_copy[['OpportunityEndTime','OpportunityEndOffset']].apply(lambda a: pd.to_datetime(a['OpportunityEndTime']) - pd.DateOffset(seconds=a['OpportunityEndOffset']),axis=1)\n",
    "# base_time_stamp = image_opportunity_df_copy[\"X\"].to_list()[0]\n",
    "\n",
    "# image_opportunity_df['base_time'] = base_time_stamp\n",
    "# image_opportunity_df['req_date'] = image_opportunity_df[['base_time','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)#pd.to_datetime(image_opportunity_df['base_time']) + pd.to_timedelta(image_opportunity_df['OpportunityStartOffset'])\n",
    "# image_opportunity_df[['req_date','OpportunityStartTime','base_time','OpportunityStartOffset']]\n",
    "\n",
    "# image_opportunity_df['x'] = image_opportunity_df[['Priority','StripID']].apply(lambda a: a['Priority'] if a['Priority']<=0 else a['StripID'],axis=1)\n",
    "# image_opportunity_df[['Priority','StripID','x']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/robin/Documents/Schedule_plan/git_APS_Python_core_develop/APS_Python_core/src/APS_Python_core', '/opt/anaconda3/lib/python312.zip', '/opt/anaconda3/lib/python3.12', '/opt/anaconda3/lib/python3.12/lib-dynload', '', '/opt/anaconda3/lib/python3.12/site-packages', '/opt/anaconda3/lib/python3.12/site-packages/aeosa']\n",
      "['/Users/robin/Documents/Schedule_plan/git_APS_Python_core_develop/APS_Python_core/src/APS_Python_core', '/opt/anaconda3/lib/python312.zip', '/opt/anaconda3/lib/python3.12', '/opt/anaconda3/lib/python3.12/lib-dynload', '', '/opt/anaconda3/lib/python3.12/site-packages', '/opt/anaconda3/lib/python3.12/site-packages/aeosa', '../']\n"
     ]
    }
   ],
   "source": [
    "#!pip list\n",
    "import os \n",
    "os.getcwd()\n",
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': 66, 'c': 43, 'd': 55, 'ww': 222}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_opportunity_df.columns\n",
    "result_dict = {'a':2,'b':66,'c':43}\n",
    "result_dict.update({'d':55,'ww':222})\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "# from APS_Python_core.preprocess_1.preprocess_GSpassSelecion import GSPassPreprocess\n",
    "# from model_3.MILP_GSpassSelection_v3 import GSpassSelection\n",
    "# from postprocess_4.postprocess_GSpassSelection import GSpasspostprocess\n",
    "\n",
    "# from preprocess_1.preprocess_imageAqusuition_test import ImageAquisitionProcess #preprocess_imageAqusuition_test,preprocess_imageAquisition_v3_18112024\n",
    "# from model_3.MILP_imageCapture_v3_17112024_copy import ImageCapturePlan # MILP_imageCapture_v2_16102024,MILP_imageCapture_v2_25102024 # MILP_imageCapture_v2_07112024 #MILP_imageCapture_v3_17112024\n",
    "# from postprocess_4.image_capture_postprocess_V3_17112024 import ImagecapturePostProcess # image_capture_postprocess_V3_17112024# image_capture_postprocess_v2_18102024\n",
    "\n",
    "# from preprocess_1.preprocess_downlink_WIP import DownlinkingPreProcess\n",
    "# from model_3.MILP_downlink import ImageDownlinkPlan\n",
    "# from postprocess_4.postprocess_downlink import ImageDownlinkPostProcess\n",
    "\n",
    "# from result_interpret import interpret_result\n",
    "# from utils import *\n",
    "\n",
    "from APS_Python_core.preprocess_1.preprocess_GSpassSelecion import GSPassPreprocess\n",
    "from APS_Python_core.model_3.MILP_GSpassSelection_v3 import GSpassSelection\n",
    "from APS_Python_core.postprocess_4.postprocess_GSpassSelection import GSpasspostprocess\n",
    "\n",
    "from APS_Python_core.preprocess_1.preprocess_imageAqusuition_test import ImageAquisitionProcess #preprocess_imageAqusuition_test,preprocess_imageAquisition_v3_18112024\n",
    "from APS_Python_core.model_3.MILP_imageCapture_v3_17112024 import ImageCapturePlan # MILP_imageCapture_v3_17112024_copy#MILP_imageCapture_v2_16102024,MILP_imageCapture_v2_25102024 # MILP_imageCapture_v2_07112024 #MILP_imageCapture_v3_17112024# \n",
    "from APS_Python_core.postprocess_4.image_capture_postprocess_V3_17112024 import ImagecapturePostProcess # image_capture_postprocess_V3_17112024# image_capture_postprocess_v2_18102024\n",
    "\n",
    "from APS_Python_core.preprocess_1.preprocess_downlink_WIP import DownlinkingPreProcess\n",
    "from APS_Python_core.model_3.MILP_downlink import ImageDownlinkPlan\n",
    "from APS_Python_core.postprocess_4.postprocess_downlink import ImageDownlinkPostProcess\n",
    "\n",
    "from APS_Python_core.result_interpret import interpret_result\n",
    "from APS_Python_core.utils import *\n",
    "\n",
    "# script_dir = os.path.abspath( os.path.dirname( __file__ ) )\n",
    "# print(\"script directory: \",script_dir)\n",
    "\n",
    "def select_gs_pass_oppr(GS_pass_df,config):\n",
    "    ''' \n",
    "    this function selects gs pass based on basic constraints.\n",
    "    Input->Gs_pass_df['GsID', 'AOS', 'LOS', 'SatID', 'AOSOffset', 'LOSOffset']\n",
    "           config->{\"constraints\":{\"Thermal_constraints_GS_pass\":false}\n",
    "    Output->df[SatID,gsID,concat_sat_gs_k,start_time,end_time,TW_index,AOSoffset,LOSoffset,duration]\n",
    "\n",
    "    '''\n",
    "\n",
    "    obj_preprocess = GSPassPreprocess(GS_pass_df,config)\n",
    "    data = obj_preprocess.preprocess()\n",
    "    #print(data['SG1K1G2K2_pair']['domain_of_csgk'])\n",
    "    #print(max([v[2]  for s in data['satellite_id'] for k,v in data['heatTimeBucket_SCT_dict__s'][s].items() if v[1]<=650]))\n",
    "    #print([v for s in data['satellite_id'] for k,v in data['heatTimeBucket_SCT_dict__s'][s].items() if s=='FF01'])\n",
    "    print(\"optimization_model_starts\")\n",
    "    obj_model = GSpassSelection(data,config)\n",
    "    result,thermal_profile_gsPass = GSpasspostprocess(obj_model,data,config).get_gsPasses()# 21 seconds\n",
    "\n",
    "    try :\n",
    "        result['duration'] = result['end_time'] - result['start_time']\n",
    "        result = result[result['duration']> 0]\n",
    "    except:\n",
    "        print(\"model is not converged or infeasible or not solved\")\n",
    "\n",
    "    return result\n",
    "    \n",
    "\n",
    "def select_img_opprtunity(image_opportunity_df,gs_pass_result_df,eclipse_df_dict,config):\n",
    "    ''' \n",
    "    this function selects strip orpprtunity based on memory power thermal and varous priorities..\n",
    "    Input->gs_pass_result_df-->df[SatID,gsID,concat_sat_gs_k,start_time,end_time,TW_index,AOSoffset,LOSoffset,duration]\n",
    "           image_opportunity_df-->df[SatID','StripID','AoiID','OpportunityStartTime','OpportunityEndTime','OpportunityStartOffset','OpportunityEndOffset','OrderValidityEnd','CloudCover','OffNadir']\n",
    "           config->dict({\"constraints\":{...},\n",
    "                    \"objective\":{\"GS_Pass_and_Imaging\":true,\"total_readout_memory\":false},\n",
    "                    \"downlink_schedule_OnlyJustsortImgID\":true,\n",
    "                    \"GP_weight\":0.4,\n",
    "                    \"DDLP_weight\":0.2,\n",
    "                    \"CCLP_weight\":0.1,\n",
    "                    \"ONLP_weight\":0.3,\n",
    "                    \"min_readout_time_seconds\":50})\n",
    "\n",
    "           eclipse_df_dict-->dict{'sat':df['time_index','SatID','eclipse']}\n",
    "\n",
    "    Output->img_capture_result--> df[SatID,StripID,AoiID,encoded_strip_id,start_time,end_time,gsID,operation,\\\n",
    "                               camera_memory_value_endofTW,delta_camera_memory_value_in_this_TW,SSD_memory_value_endofTW,\\\n",
    "                                delta_SSD_memory_value_in_this_TW,global_priority,local_priority,mean_global_priority,mean_local_priority]\n",
    "\n",
    "            data--> dict(['encoded_stripId_list', 'imgery_sat_id_list', 'only_gs_sat_id_list', 'unique_img_opportunities_list', 'TW__csjk', \\\n",
    "                          'csjkList__j', 'csjkSet__s', 'cs1j2k2Domainlist__cs1j1k1', 'camera_memory_capacity__s', 'initial_camera_memory_value__s',\\\n",
    "                          'readout_memory_capacity__s', 'power_capacity__s', 'initial_power_value__s', 'initial_readout_camera_memory_value__s', \\\n",
    "                        'imaging_rate', 'Readout_rate', 'heatCameraTimeBucket_SCT_dict__s', 'heatTimeBucket_SCT_dict__s',\\\n",
    "                        'max_camera_heat_dict', 'max_readout_heat_dict', 'stripid__encodedstripID', 'AOIid__encodedstripID', \\\n",
    "                        'assured_tasking_basedOnDueDateEmergency_list', 'assured_tasking_based_on_input_list', \\\n",
    "                        'GlobalPriority__csjk', 'TotalPriority__csjk', 'Local_Priority__csjk', 'TotalPriority__csj', \\\n",
    "                        'GlobalPriority__csj', 'Local_Priority__csj', 'active_assured_strip_id_list', \\\n",
    "                        'PowerglobalTWindexSortedList__s', 'MemoryglobalTWindexSortedList__s', 'Power_GS_TW_list',\\\n",
    "                        'Memory_onlyGsTW_list', 'Power_image_TW_list', 'Memory_onlyImgTW_list', 'Power_NoimageGs_TW_list', \\\n",
    "                        'Memory_NoimageGs_TW_list', 'prev_tWList__s_TWI_dict__s', 'prev_ImagingTWList__s_TWI_dict__s', \\\n",
    "                        'prev_power_tWList__s_TWI_dict__s', 'TW_df_withoutEclipseDivide_df', 'TW_df_withEclipseDivide_df',\\\n",
    "                        'dedicatedReadoutTWlist__concat_sat_memoryTWindex', 'power_based_df', 'success_metric_before', \\\n",
    "                        'TW__csn', 'memory_based_df', 'dedicated_readout_df', 'dedicatedReadoutTWIndex__sat', \\\n",
    "                        'prev_dedicatedReadoutIndex__s_TWI_dict__s', 'DROPriority__concat_sat_memoryTWindex', 'GS_Pass_time_objective']))\n",
    "\n",
    "    '''\n",
    "\n",
    "    #basic flters\n",
    "    #image_opportunity_df = image_opportunity_df[image_opportunity_df['OpportunityEndOffset']<config['scheduled_Hrs']*3600]\n",
    "    #image_opportunity_df = image_opportunity_df[image_opportunity_df['CloudCoverLimit']>image_opportunity_df['CloudCover']]\n",
    "    #image_opportunity_df = image_opportunity_df[image_opportunity_df['OffNadirLimit']>image_opportunity_df['OffNadir']]\n",
    "\n",
    "    obj_preprocess = ImageAquisitionProcess(image_opportunity_df,gs_pass_result_df,eclipse_df_dict,config)\n",
    "    data = obj_preprocess.preprocess()\n",
    "    #print(data['cs1j2k2Domainlist__cs1j1k1'])\n",
    "\n",
    "    #++++++++++++++++++++++++++  STEP 0  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    '''\n",
    "    hard code some data\n",
    "    '''\n",
    "    data['camera_memory_capacity__s'] = {s:v for s,v in data['camera_memory_capacity__s'].items() }\n",
    "    data['readout_memory_capacity__s'] = {s:v for s,v in data['readout_memory_capacity__s'].items() }\n",
    "    data['power_capacity__s']  = {s:720000000 for s,v in data['power_capacity__s'].items() }\n",
    "    data['initial_power_value__s']  = {s:v*0.3 for s,v in data['power_capacity__s'].items() }\n",
    "    #++++++++++++++++++++++++++  STEP 1  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    config['objective']['GS_Pass_and_Imaging'] = True\n",
    "    config['objective']['total_readout_memory'] = False\n",
    "    obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    #Readout Schedule\n",
    "    if config['readout_schedule']:\n",
    "        data['GS_Pass_time_objective'] = obj_model.prob.objective.value()\n",
    "        config['objective']['GS_Pass_and_Imaging'] = False\n",
    "        config['objective']['total_readout_memory'] = True\n",
    "        obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    #++++++++++++++++++++++++++  PostProcess  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    post_obj = ImagecapturePostProcess(obj_model,data)\n",
    "    img_capture_result= post_obj.get_schedule()\n",
    "    #.isnull().sum()\n",
    "    return img_capture_result,data\n",
    "    #======================================================================================================================================================================================================\n",
    "\n",
    "    pass\n",
    "\n",
    "def get_aps_success_metric(img_capture_result,data):\n",
    "    after_aps_plan_df = img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "    criteria_list = ['total_opprtunities_ratio','GP_ratio','LP_ratio','conflictImg_gsPass']\n",
    "\n",
    "    total_conflict_images_list= [data['success_metric_before']['conflict_images']]\n",
    "    GP_before = data['success_metric_before']['original_Total_GP']\n",
    "    LP_before = data['success_metric_before']['original_Total_LP']\n",
    "    TOppr_before = data['success_metric_before']['total_opportunities'] \n",
    "    before_list = [TOppr_before,GP_before,LP_before,total_conflict_images_list]\n",
    "\n",
    "    GP_after= after_aps_plan_df['mean_global_priority'].sum()\n",
    "    LP_after = after_aps_plan_df['mean_local_priority'].sum()\n",
    "    TOppr_after= after_aps_plan_df['encoded_strip_id'].nunique()\n",
    "    fraction_conflict_images_list = [list(after_aps_plan_df[after_aps_plan_df['encoded_strip_id'].isin(total_conflict_images_list)]['encoded_strip_id'].unique())]\n",
    "    after_list = [TOppr_after,GP_after,LP_after,fraction_conflict_images_list]\n",
    "\n",
    "    APS_success_metric_df = pd.DataFrame({'criteria':criteria_list,'potential_input':before_list,'APS_selected':after_list})\n",
    "    #APS_success_metric_df['percentage'] = APS_success_metric_df['APS_selected'] / APS_success_metric_df['potential_input']\n",
    "    APS_success_metric_df1 = APS_success_metric_df[:-1]\n",
    "    APS_success_metric_df1['percentage'] = APS_success_metric_df1['APS_selected'] / APS_success_metric_df1['potential_input'] * 100\n",
    "    APS_success_metric_df2 = APS_success_metric_df[-1:]\n",
    "\n",
    "    APS_success_metric_df = pd.concat([APS_success_metric_df1,APS_success_metric_df2])\n",
    "\n",
    "    return APS_success_metric_df\n",
    "    \n",
    "\n",
    "def get_downlink_schedule(image_downlink_df,img_capture_result,config):\n",
    "\n",
    "    downlink_operation_list  = ['downlinking_from_camera','downlinking_from_Readout']\n",
    "    img_capture_result_downlink = img_capture_result[img_capture_result['operation'].isin(downlink_operation_list)]\n",
    "    DownlinkingPreProcessObj = DownlinkingPreProcess(image_downlink_df,img_capture_result_downlink,config)\n",
    "    data_downlink = DownlinkingPreProcessObj.preprocess()\n",
    "    \n",
    "    if config['downlink_schedule_OnlyJustsortImgID']:\n",
    "        downlink_result = pd.DataFrame(data_downlink['LP_DD_Priority_imgID'].items(),columns=['ImageID','computed_priority']).\\\n",
    "            sort_values(by='computed_priority',ascending=False)\n",
    "    else:\n",
    "        obj_downlink_model = ImageDownlinkPlan(data_downlink,config)\n",
    "        downlink_result = ImageDownlinkPostProcess(obj_downlink_model,data_downlink).get_schedule()\n",
    "        downlink_result = downlink_result[downlink_result['TileStripNo_downLoad']!=0]\n",
    "\n",
    "    return downlink_result\n",
    "    \n",
    "\n",
    "\n",
    "def get_input_files(config,GS_pass_df,image_opportunity_df,image_downlink_df,eclipse_event_df):\n",
    "    ''' \n",
    "    to read input files and preliminary preprocessing.\n",
    "    Input-->\n",
    "            GS_pass_df-->df['GsID', 'AOS', 'LOS', 'Eclipse', 'AOSOffset', 'LOSOffset','SatID']\n",
    "            image_opportunity_df-->df['SatID', 'OpportunityStartTime',\n",
    "                'OpportunityEndTime', 'StripID', 'OffNadir', 'SunInView', 'EarthInView',\n",
    "                'MoonInView','OrderValidityStart', 'OrderValidityEnd', 'AoiID','CloudCoverLimit', 'CloudCover',\n",
    "                'OffNadirLimit', 'Priority','OpportunityStartOffset',\n",
    "                'OpportunityEndOffset']\n",
    "            image_downlink_df-->df['ImageID', 'SatID', 'DueDate', 'Priority', 'Tilestrips', 'Sensors',\n",
    "                                   'Bands', 'EmergencyFlag', 'CaptureDate',delivery_type,assured_downlink_flag]\n",
    "    Output-->dict('GS_pass_df':df[..],\\\n",
    "                'image_opportunity_df':df[..],\\\n",
    "                'image_downlink_df':df[..],\\\n",
    "                \"eclipse_df_dict\": {'sat':df ,..},\n",
    "                \"config\":{..})\n",
    "    '''\n",
    "    # GS PASS\n",
    "    #GS_pass_df = pd.read_csv(config[\"csv_file_path\"][\"gs_pass_opportunity\"])#APS_gsPasses_TV1#GS_Passes_mock1#GS_Passes_live1#GS_Passes_new (1)\n",
    "    \n",
    "    #GS_pass_df = pd.read_csv(\"1_input_data/GS_Passes_new (1).csv\")\n",
    "    GS_pass_df_original = GS_pass_df.copy()\n",
    "    GS_pass_df['SatID'] = GS_pass_df['SatID'].astype(str)\n",
    "    GS_pass_df['AOSOffset'] = GS_pass_df['AOSOffset'].astype(int)\n",
    "    GS_pass_df['LOSOffset'] = GS_pass_df['LOSOffset'].astype(int)\n",
    "\n",
    "    # image Opprtunity\n",
    "    #image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])#Imaging_mock1#APS_imagingOpportunities_TV1#Imaging_live#Imaging_new (1)\n",
    "    # change made priority ulta\n",
    "    #image_opportunity_df['Priority'] = 1/image_opportunity_df['Priority']\n",
    "    \n",
    "    image_opportunity_df['SatID'] = image_opportunity_df['SatID'].astype(str)\n",
    "    image_opportunity_df['OpportunityStartOffset'] = image_opportunity_df['OpportunityStartOffset'].astype(int)\n",
    "    image_opportunity_df['OpportunityEndOffset'] = image_opportunity_df['OpportunityEndOffset'].astype(int)\n",
    "    image_opportunity_df_copy = image_opportunity_df.copy()\n",
    "    image_opportunity_df_copy['X'] = image_opportunity_df_copy[['OpportunityStartTime','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['OpportunityStartTime']) - pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)\n",
    "    image_opportunity_df_copy['Y'] = image_opportunity_df_copy[['OpportunityEndTime','OpportunityEndOffset']].apply(lambda a: pd.to_datetime(a['OpportunityEndTime']) - pd.DateOffset(seconds=a['OpportunityEndOffset']),axis=1)\n",
    "    base_time_stamp = image_opportunity_df_copy[\"X\"].to_list()[0]\n",
    "    config['base_time_stamp_downlink'] = base_time_stamp\n",
    "\n",
    "    #image Downlink\n",
    "    #image_downlink_df = pd.read_csv(config[\"csv_file_path\"][\"image_downlink_file\"])\n",
    "    image_downlink_df['assured_downlink_flag'] = [0,0] +[0]*(len(image_downlink_df)-2)\n",
    "    image_downlink_df['delivery_type'] = 'standard_delivery' # expedited_delivery,super_expedited_delivery\n",
    "    union_list_of_sat = list(set(image_opportunity_df['SatID']).union(set(GS_pass_df['SatID'])).union(set(image_downlink_df['SatID'])))\n",
    "    hrs = config['scheduled_Hrs']\n",
    "\n",
    "    # get dummy eclipse data close to reality\n",
    "    # satellite_list = eclipse_event_df['SatID'].unique()\n",
    "    # eclipse_df = pd.DataFrame()\n",
    "    # for sat in satellite_list:\n",
    "    #     this_eclipse_df = eclipse_event_df[eclipse_event_df['SatID']==sat]\n",
    "    #     that_eclipse_df = get_eclipse_data(this_eclipse_df,config)\n",
    "    #     eclipse_df = pd.concat([that_eclipse_df,eclipse_df])\n",
    "        \n",
    "    # min_time_index= min([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "    # max_time_index= max([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "\n",
    "    # hrs = (max_time_index - min_time_index)/3600\n",
    "    # hrs = math.ceil(hrs)\n",
    "    # while True:\n",
    "    #     hrs += 1\n",
    "    #     if hrs % 1.5==0:\n",
    "    #         break\n",
    "\n",
    "\n",
    "    # in_orbit_eclipse_event = [1 for i in range(int(1.5*3600*0.4))] + [0 for i in range(int(1.5*3600*0.6))] #\n",
    "    # eclipse_df  = pd.DataFrame({'time_index': [i for i in range(min_time_index,min_time_index+hrs*3600)] ,\"eclipse\" : in_orbit_eclipse_event*int(hrs/1.5)})\n",
    "    # eclipse_df['SatID']= [union_list_of_sat] *len(eclipse_df)\n",
    "    # eclipse_df = eclipse_df.explode('SatID')\n",
    "    # eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "    try :\n",
    "        eclipse_df = pd.DataFrame()\n",
    "        satellite_list = eclipse_event_df['SatID'].unique()\n",
    "        for sat in satellite_list:\n",
    "            this_eclipse_df = eclipse_event_df[eclipse_event_df['SatID']==sat]\n",
    "            that_eclipse_df = get_eclipse_data(this_eclipse_df,config)\n",
    "            eclipse_df = pd.concat([that_eclipse_df,eclipse_df])\n",
    "        eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "    except:\n",
    "        print(\"some_error_in_eclipse_data_So_hard_coded_eclipse_data\")\n",
    "        min_time_index= min([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "        max_time_index= max([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "\n",
    "        hrs = (max_time_index - min_time_index)/3600\n",
    "        hrs = math.ceil(hrs)\n",
    "        while True:\n",
    "            hrs += 1\n",
    "            if hrs % 1.5==0:\n",
    "                break\n",
    "\n",
    "\n",
    "        in_orbit_eclipse_event = [1 for i in range(int(1.5*3600*0.4))] + [0 for i in range(int(1.5*3600*0.6))] #\n",
    "        eclipse_df  = pd.DataFrame({'time_index': [i for i in range(min_time_index,min_time_index+hrs*3600)] ,\"eclipse\" : in_orbit_eclipse_event*int(hrs/1.5)})\n",
    "        eclipse_df['SatID']= [union_list_of_sat] *len(eclipse_df)\n",
    "        eclipse_df = eclipse_df.explode('SatID')\n",
    "        eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "\n",
    "\n",
    "    # get dummy data for assured tasking\n",
    "    image_opportunity_df['encoded_stripId'] =   image_opportunity_df['StripID'].astype(str)+ '_' + image_opportunity_df['AoiID'].astype(str)\n",
    "    total_capture_list = list(image_opportunity_df['encoded_stripId'].unique())\n",
    "    no_of_list = len(total_capture_list)\n",
    "    assured_capture_df = pd.DataFrame({'encoded_stripId':total_capture_list,'assured_task':[0,0]+[0]*(no_of_list-2)})\n",
    "    image_opportunity_df = pd.merge(image_opportunity_df,assured_capture_df,on='encoded_stripId',how='left')\n",
    "    image_opportunity_df = image_opportunity_df.drop(columns=['encoded_stripId'])\n",
    "\n",
    "    # further processing eclipse data to align with gs pass where entire gs pass is assumed to be in eclipse region\n",
    "    gsPassInput_df_copy = GS_pass_df_original\n",
    "    gsPassInput_df_copy['SatID'] = gsPassInput_df_copy['SatID'].astype(str)\n",
    "    gsPassInput_df_copy['AOSOffset'] = gsPassInput_df_copy['AOSOffset'].astype(int)\n",
    "    gsPassInput_df_copy['LOSOffset'] = gsPassInput_df_copy['LOSOffset'].astype(int)\n",
    "    gsPassInput_df_copy['list'] =  gsPassInput_df_copy[['AOSOffset','LOSOffset']].apply(lambda a : [i for i in range(a['AOSOffset'],a['LOSOffset']+1)],axis =1 )\n",
    "\n",
    "    gsPassInput_df_copy1 = gsPassInput_df_copy[['SatID','list']]\n",
    "    gsPassInput_df_copy1 = gsPassInput_df_copy1.explode('list')\n",
    "    gsPassInput_df_grouped_copy1 = gsPassInput_df_copy1.groupby('SatID').agg(time_index_list = ('list',list)).reset_index()\n",
    "    gsPasstimeIndexList__s = dict(zip(gsPassInput_df_grouped_copy1['SatID'],gsPassInput_df_grouped_copy1['time_index_list']))\n",
    "    for k,v in eclipse_df_dict.items():\n",
    "        if k in gsPasstimeIndexList__s.keys():\n",
    "            this_time_index_list = gsPasstimeIndexList__s[k]\n",
    "            v.loc[v[\"time_index\"].isin(this_time_index_list), \"eclipse\"] = 1\n",
    "            eclipse_df_dict[k] = v\n",
    "\n",
    "    return {\n",
    "            'GS_pass_df':GS_pass_df,\\\n",
    "            'image_opportunity_df':image_opportunity_df,\\\n",
    "            'image_downlink_df':image_downlink_df,\\\n",
    "            \"eclipse_df_dict\": eclipse_df_dict,\n",
    "            \"config\":config\n",
    "            }\n",
    "    \n",
    "def get_schedule(config,GS_pass_df,image_opportunity_df,image_downlink_df,eclipse_df):\n",
    "    ''' \n",
    "    to get imaging , readout schedule and stats for schedule.\n",
    "\n",
    "    Input-->\n",
    "            GS_pass_df-->df['GsID', 'AOS', 'LOS', 'Eclipse', 'AOSOffset', 'LOSOffset','SatID']\n",
    "            image_opportunity_df-->df['SatID', 'OpportunityStartTime',\n",
    "                'OpportunityEndTime', 'StripID', 'OffNadir', 'SunInView', 'EarthInView',\n",
    "                'MoonInView','OrderValidityStart', 'OrderValidityEnd', 'AoiID','CloudCoverLimit', 'CloudCover',\n",
    "                'OffNadirLimit', 'Priority','OpportunityStartOffset',\n",
    "                'OpportunityEndOffset']\n",
    "            image_downlink_df-->df['ImageID', 'SatID', 'DueDate', 'Priority', 'Tilestrips', 'Sensors',\n",
    "                                   'Bands', 'EmergencyFlag', 'CaptureDate',delivery_type,assured_downlink_flag]\n",
    "\n",
    "    Output-->dict{\"only_readout_result\":df['SatID','start_time','end_time','base_time'],\\\n",
    "        \"only_img_capture_result\":df['SatID','start_time','end_time','AoiID','StripID','base_time'],\\\n",
    "            \"only_gsPass_result\":df['SatID','start_time','end_time','gsID','base_time'],\\\n",
    "            \"combined_result\":df['SatID', 'start_time', 'end_time', 'encoded_strip_id', 'gsID','operation', 'camera_memory_value_endofTW',\n",
    "                                'delta_camera_memory_value_in_this_TW', 'SSD_memory_value_endofTW','delta_SSD_memory_value_in_this_TW', 'global_priority',\n",
    "                                'local_priority', 'mean_global_priority', 'mean_local_priority','StripID', 'AoiID', 'base_time']}\n",
    "\n",
    "            \"interpret_extracted_raw_file_df\":df['SatID', 'OpportunityStartTime', 'OpportunityEndTime', 'StripID','OffNadir', 'OrderValidityStart', 'OrderValidityEnd', 'AoiID','Priority', 'OpportunityStartOffset', 'OpportunityEndOffset',\n",
    "                                                'normalized_local_priority_due_date','normalized_local_priority_CC_based','normalized_local_priority_offNadir', 'normalized_GlobalPriority','normalized_Total_Priority', 'camera_memory_value_endofTW',\n",
    "                                                'delta_camera_memory_value_in_this_TW', 'flag', 'flag_gs_pass_conflict','conflicting_strip_oppr', 'concat_SatID_encodedStripId_TWindex','CloudCoverLimit', 'CloudCover', 'encoded_strip_id', 'base_time']\n",
    "            \"interpret_selected_oppr_conflict_comparision_df\"df['conflic_strip_flag_named', 'max_Norm_TP', 'this_flag_norm_TP','max_Norm_GP', 'this_flag_norm_GP', 'max_Norm_LPDD','this_flag_norm_LLDD', 'base_time']\n",
    "            \"interpret_KPI_df: df['criteria', 'before_APS', 'APS_result', 'remarks', 'percentage','base_time']\n",
    "            \n",
    "                                                   \n",
    "    '''\n",
    "    \n",
    "    # Open and read the JSON file\n",
    "    #APS_Python_core/src/APS_Python_core/1_input_data/config.json\n",
    "    #with open('APS_Python_core/src/APS_Python_core/1_input_data/config.json', 'r') as file:\n",
    "    #with open('../1_input_data/config.json', 'r') as file:\n",
    "        #config = json.load(file)\n",
    "    original_image_opportunity_df = image_opportunity_df.copy()\n",
    "    # if memory constraint False then thermal_constraint is also False\n",
    "    #config['constraints']['thermal_constraint_readout'] = config['constraints']['memory_constrant'] and config['constraints']['thermal_constraint_readout']\n",
    "    #config['constraints']['thermal_constraint_imaging'] = config['constraints']['memory_constrant'] and config['constraints']['thermal_constraint_imaging']\n",
    "\n",
    "    #======================================================================================================================================================================================================\n",
    "    # read_input\n",
    "    input_dict = get_input_files(config,GS_pass_df,image_opportunity_df,image_downlink_df,eclipse_df)\n",
    "    config = input_dict['config']\n",
    "    #======================================================================================================================================================================================================\n",
    "    #gs pass_selection\n",
    "    gs_pass_result_df = select_gs_pass_oppr(input_dict['GS_pass_df'],config)\n",
    "    gs_pass_result_df['Eclipse'] = 1 ## dummy\n",
    "    gs_pass_result_df['duration'] = gs_pass_result_df['end_time'] - gs_pass_result_df['start_time']\n",
    "    gs_pass_result_df = gs_pass_result_df[gs_pass_result_df['duration']> 0]\n",
    "    print(gs_pass_result_df['concat_sat_gs_k'].nunique())\n",
    "    interpret_gs_pass_result_df_copy = gs_pass_result_df.copy()# this not the gsPass result as it is to be get filtered after due to other factors in image capture plan.It is just to get require info in interpret result.\n",
    "\n",
    "    print(\"image_capture_plan_starting\")\n",
    "    #======================================================================================================================================================================================================\n",
    "    #image_selection\n",
    "    img_capture_result,capture_plan_data_input= select_img_opprtunity(input_dict['image_opportunity_df'],gs_pass_result_df,input_dict['eclipse_df_dict'],config)\n",
    "    img_capture_result['base_time'] = config['base_time_stamp_downlink']\n",
    "    #img_capture_result = img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "    #readout_result = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "    interpret_img_capture_resul_copy = img_capture_result.copy()\n",
    "    #======================================================================================================================================================================================================\n",
    "    # get APS success metrics \n",
    "    APS_success_metric_df = get_aps_success_metric(img_capture_result,capture_plan_data_input)\n",
    "    #======================================================================================================================================================================================================\n",
    "    print(\"Downlink_plan_starting\")\n",
    "    try:\n",
    "        downlink_result = get_downlink_schedule(input_dict['image_downlink_df'],img_capture_result,config)\n",
    "        downlink_result['base_time'] = config['base_time_stamp_downlink']\n",
    "    except:\n",
    "        print(\"downlink_schedule_error\")\n",
    "    #======================================================================================================================================================================================================\n",
    "    #img_capture_result[img_capture_result['download_from_']]\n",
    "    # gs_pass_result_df.to_csv(\"APS_Python_core/src/APS_Python_core/5_output_data/gs_pass_result_df.csv\",index=None)\n",
    "    # img_capture_result.to_csv(\"APS_Python_core/src/APS_Python_core/5_output_data/img_capture_schedule.csv\",index=None)\n",
    "    # APS_success_metric_df.to_csv(\"APS_Python_core/src/APS_Python_core/5_output_data/APS_success_metric.csv\",index = None)\n",
    "    # downlink_result.to_csv(\"APS_Python_core/src/APS_Python_core/5_output_data/downlink_result.csv\",index = None)\n",
    "\n",
    "    interpret_image_opportunity_df = original_image_opportunity_df\n",
    "    interpret_result_dict = interpret_result(interpret_image_opportunity_df,interpret_gs_pass_result_df_copy,interpret_img_capture_resul_copy,config)\n",
    "    for k,v in interpret_result_dict.items():\n",
    "        v['base_time'] = config['base_time_stamp_downlink']\n",
    "        #v.to_csv(\"APS_Python_core/src/APS_Python_core/5_output_data/\"+k+\".csv\",index = None)\n",
    "    \n",
    "    only_img_capture_result = img_capture_result[img_capture_result['operation']=='Imaging'][['SatID','start_time','end_time','AoiID','StripID','base_time']]\n",
    "    only_img_capture_result['start_time'] = only_img_capture_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "    only_img_capture_result['end_time'] = only_img_capture_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "    only_readout_result = img_capture_result[img_capture_result['operation']=='Readout'][['SatID','start_time','end_time','base_time']]\n",
    "    \n",
    "    if len(only_readout_result):\n",
    "        only_readout_result['start_time'] = only_readout_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "        only_readout_result['end_time'] = only_readout_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "    only_gsPass_result = img_capture_result[img_capture_result['operation']=='downlinking_from_Readout'][['SatID','start_time','end_time','gsID','base_time']]\n",
    "    only_gsPass_result['start_time'] = only_gsPass_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "    only_gsPass_result['end_time'] = only_gsPass_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "\n",
    "    result_dict = {\"only_readout_result\":only_readout_result,\\\n",
    "                  \"only_img_capture_result\":only_img_capture_result,\\\n",
    "                  \"only_gsPass_result\":only_gsPass_result,\\\n",
    "                  \"combined_result\":img_capture_result}\n",
    "    result_dict.update(interpret_result_dict)\n",
    "    #return result_dict\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/robin/Documents/Schedule_plan/git_APS_Python_core_develop/APS_Python_core/src/APS_Python_core'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some_error_in_eclipse_data_So_hard_coded_eclipse_data\n",
      "=====GA pASS THERMAL======\n",
      "optimization_model_starts\n",
      "start_solving\n",
      "Running HiGHS 1.8.1 (git hash: 4a7f24a): Copyright (c) 2024 HiGHS under MIT licence terms\n",
      "Coefficient ranges:\n",
      "  Matrix [1e+00, 1e+09]\n",
      "  Cost   [1e+00, 1e+00]\n",
      "  Bound  [1e+00, 1e+00]\n",
      "  RHS    [1e+00, 2e+09]\n",
      "Presolving model\n",
      "1598487 rows, 57850 cols, 4790687 nonzeros  0s\n",
      "116721 rows, 57847 cols, 1088253 nonzeros  1s\n",
      "99263 rows, 41698 cols, 799099 nonzeros  5s\n",
      "84423 rows, 35391 cols, 678696 nonzeros  6s\n",
      "71809 rows, 30030 cols, 575763 nonzeros  7s\n",
      "61087 rows, 25474 cols, 489390 nonzeros  7s\n",
      "51975 rows, 21601 cols, 412045 nonzeros  8s\n",
      "44229 rows, 18309 cols, 349726 nonzeros  8s\n",
      "37645 rows, 15511 cols, 296877 nonzeros  8s\n",
      "32049 rows, 13132 cols, 251605 nonzeros  8s\n",
      "27291 rows, 11110 cols, 213337 nonzeros  9s\n",
      "23247 rows, 9392 cols, 180705 nonzeros  9s\n",
      "19811 rows, 7931 cols, 150351 nonzeros  9s\n",
      "16889 rows, 6689 cols, 124451 nonzeros  9s\n",
      "14405 rows, 5634 cols, 105427 nonzeros  9s\n",
      "12295 rows, 4633 cols, 88915 nonzeros  9s\n",
      "10293 rows, 3667 cols, 72451 nonzeros  9s\n",
      "8196 rows, 3667 cols, 70190 nonzeros  9s\n",
      "\n",
      "Solving MIP model with:\n",
      "   8196 rows\n",
      "   3667 cols (3503 binary, 0 integer, 0 implied int., 164 continuous)\n",
      "   70190 nonzeros\n",
      "MIP-Timing:         9.6 - starting analytic centre calculation\n",
      "\n",
      "Src: B => Branching; C => Central rounding; F => Feasibility pump; H => Heuristic; L => Sub-MIP;\n",
      "     P => Empty MIP; R => Randomized rounding; S => Solve LP; T => Evaluate node; U => Unbounded;\n",
      "     z => Trivial zero; l => Trivial lower; u => Trivial upper; p => Trivial point\n",
      "\n",
      "        Nodes      |    B&B Tree     |            Objective Bounds              |  Dynamic Constraints |       Work      \n",
      "Src  Proc. InQueue |  Leaves   Expl. | BestBound       BestSol              Gap |   Cuts   InLp Confl. | LpIters     Time\n",
      "\n",
      "         0       0         0   0.00%   -45431          inf                  inf        0      0      0         0     9.6s\n",
      " T       0       0         0 100.00%   -45431          -45431             0.00%        0      0      0      2834     9.7s\n",
      "         1       0         1 100.00%   -45431          -45431             0.00%        0      0      0      2834     9.7s\n",
      "\n",
      "Solving report\n",
      "  Status            Optimal\n",
      "  Primal bound      -45431\n",
      "  Dual bound        -45431\n",
      "  Gap               0% (tolerance: 0.01%)\n",
      "  P-D integral      0\n",
      "  Solution status   feasible\n",
      "                    -45431 (objective)\n",
      "                    0 (bound viol.)\n",
      "                    0 (int. viol.)\n",
      "                    0 (row viol.)\n",
      "  Timing            9.69 (total)\n",
      "                    0.00 (presolve)\n",
      "                    0.00 (solve)\n",
      "                    0.00 (postsolve)\n",
      "  Max sub-MIP depth 0\n",
      "  Nodes             1\n",
      "  Repair LPs        0 (0 feasible; 0 iterations)\n",
      "  LP iterations     2834 (total)\n",
      "                    0 (strong br.)\n",
      "                    0 (separation)\n",
      "                    0 (heuristics)\n",
      "status= Optimal\n",
      "83\n",
      "image_capture_plan_starting\n",
      "=====IMAGING THEMAL======\n",
      "=====READOUT THERMAL======\n",
      "len_before_eclipse_transition_divide= 437\n",
      "len_after(after explode)_eclipse_transition_divide= 519\n",
      "Before_Ambiguous_event_transition_divide = 519\n",
      "Empty DataFrame\n",
      "Columns: [SatID, encoded_stripId, start_time, end_time, TW_index, gsID, till_now_max, prev_max, global_TW, Memory_global_TW_index, concat_sat_MGWI, EcStEnd_list, len_EcStEnd_list, new_eclipse, new_start_time, new_end_time]\n",
      "Index: []\n",
      "After_len_of_ambiguous_event_transition_divide = 519\n",
      "list of unique lenths of eclipse_transition_divide(bifurcation) =  [1 2 3]\n",
      "len_power_based_memory_based= 373 len_power_based_memory_based= 146\n",
      "final_len_power_based= 519\n",
      "GS_Pass_time_objective\n",
      "only gs check  FF01 1.0 [1.0]\n",
      "only gs check  FF02 1.0 [1.0]\n",
      "only gs check  FF03 1.0 [1.0]\n",
      "Running HiGHS 1.8.1 (git hash: 4a7f24a): Copyright (c) 2024 HiGHS under MIT licence terms\n",
      "Coefficient ranges:\n",
      "  Matrix [8e-01, 1e+06]\n",
      "  Cost   [1e+00, 7e+02]\n",
      "  Bound  [1e+00, 7e+08]\n",
      "  RHS    [1e+00, 2e+08]\n",
      "Presolving model\n",
      "15731 rows, 5003 cols, 44436 nonzeros  0s\n",
      "9539 rows, 4431 cols, 28143 nonzeros  0s\n",
      "7321 rows, 3030 cols, 18349 nonzeros  0s\n",
      "4519 rows, 1629 cols, 12745 nonzeros  0s\n",
      "4515 rows, 1629 cols, 12737 nonzeros  0s\n",
      "\n",
      "Solving MIP model with:\n",
      "   4515 rows\n",
      "   1629 cols (353 binary, 0 integer, 2 implied int., 1274 continuous)\n",
      "   12737 nonzeros\n",
      "MIP-Timing:       0.081 - starting analytic centre calculation\n",
      "\n",
      "Src: B => Branching; C => Central rounding; F => Feasibility pump; H => Heuristic; L => Sub-MIP;\n",
      "     P => Empty MIP; R => Randomized rounding; S => Solve LP; T => Evaluate node; U => Unbounded;\n",
      "     z => Trivial zero; l => Trivial lower; u => Trivial upper; p => Trivial point\n",
      "\n",
      "        Nodes      |    B&B Tree     |            Objective Bounds              |  Dynamic Constraints |       Work      \n",
      "Src  Proc. InQueue |  Leaves   Expl. | BestBound       BestSol              Gap |   Cuts   InLp Confl. | LpIters     Time\n",
      "\n",
      "         0       0         0   0.00%   -60380.263555   inf                  inf        0      0      0         0     0.1s\n",
      " R       0       0         0   0.00%   -56964.605569   -45107.304019     26.29%        0      0      0      1106     0.1s\n",
      " C       0       0         0   0.00%   -55289.705838   -45934.933365     20.37%      329     62      0      1363     0.2s\n",
      " L       0       0         0 100.00%   -48283.582431   -48283.582431      0.00%      554    140      0      1922     0.3s\n",
      "         1       0         1 100.00%   -48283.582431   -48283.582431      0.00%      554    140      0      2154     0.3s\n",
      "\n",
      "Solving report\n",
      "  Status            Optimal\n",
      "  Primal bound      -48283.5824309\n",
      "  Dual bound        -48283.5824309\n",
      "  Gap               0%\n",
      "  P-D integral      0.0295208288588\n",
      "  Solution status   feasible\n",
      "                    -48283.5824309 (objective)\n",
      "                    0 (bound viol.)\n",
      "                    6.10622663544e-15 (int. viol.)\n",
      "                    0 (row viol.)\n",
      "  Timing            0.30 (total)\n",
      "                    0.00 (presolve)\n",
      "                    0.00 (solve)\n",
      "                    0.00 (postsolve)\n",
      "  Max sub-MIP depth 1\n",
      "  Nodes             1\n",
      "  Repair LPs        0 (0 feasible; 0 iterations)\n",
      "  LP iterations     2154 (total)\n",
      "                    0 (strong br.)\n",
      "                    816 (separation)\n",
      "                    232 (heuristics)\n",
      "status= Optimal\n",
      "total_readout_memory_objective\n",
      "only gs check  FF01 1.0 [1.0]\n",
      "only gs check  FF02 1.0 [1.0]\n",
      "only gs check  FF03 1.0 [1.0]\n",
      "Running HiGHS 1.8.1 (git hash: 4a7f24a): Copyright (c) 2024 HiGHS under MIT licence terms\n",
      "Coefficient ranges:\n",
      "  Matrix [8e-01, 1e+06]\n",
      "  Cost   [6e-02, 1e+00]\n",
      "  Bound  [1e+00, 7e+08]\n",
      "  RHS    [1e+00, 2e+08]\n",
      "Presolving model\n",
      "15732 rows, 5003 cols, 44742 nonzeros  0s\n",
      "9540 rows, 4431 cols, 28449 nonzeros  0s\n",
      "7322 rows, 3030 cols, 18655 nonzeros  0s\n",
      "4520 rows, 1629 cols, 13051 nonzeros  0s\n",
      "4516 rows, 1629 cols, 13043 nonzeros  0s\n",
      "\n",
      "Solving MIP model with:\n",
      "   4516 rows\n",
      "   1629 cols (353 binary, 0 integer, 2 implied int., 1274 continuous)\n",
      "   13043 nonzeros\n",
      "MIP-Timing:       0.084 - starting analytic centre calculation\n",
      "\n",
      "Src: B => Branching; C => Central rounding; F => Feasibility pump; H => Heuristic; L => Sub-MIP;\n",
      "     P => Empty MIP; R => Randomized rounding; S => Solve LP; T => Evaluate node; U => Unbounded;\n",
      "     z => Trivial zero; l => Trivial lower; u => Trivial upper; p => Trivial point\n",
      "\n",
      "        Nodes      |    B&B Tree     |            Objective Bounds              |  Dynamic Constraints |       Work      \n",
      "Src  Proc. InQueue |  Leaves   Expl. | BestBound       BestSol              Gap |   Cuts   InLp Confl. | LpIters     Time\n",
      "\n",
      "         0       0         0   0.00%   -10915.740299   inf                  inf        0      0      0         0     0.1s\n",
      "         0       0         0   0.00%   -8954.28521     inf                  inf        0      0      2       982     0.1s\n",
      " L       0       0         0   0.00%   -8783.740299    -8783.740299       0.00%      649    184    105      2141     0.5s\n",
      "         1       0         1 100.00%   -8783.740299    -8783.740299       0.00%      649    184    105      2351     0.5s\n",
      "\n",
      "Solving report\n",
      "  Status            Optimal\n",
      "  Primal bound      -8783.74029892\n",
      "  Dual bound        -8783.74029892\n",
      "  Gap               0%\n",
      "  P-D integral      0\n",
      "  Solution status   feasible\n",
      "                    -8783.74029892 (objective)\n",
      "                    0 (bound viol.)\n",
      "                    0 (int. viol.)\n",
      "                    0 (row viol.)\n",
      "  Timing            0.46 (total)\n",
      "                    0.00 (presolve)\n",
      "                    0.00 (solve)\n",
      "                    0.00 (postsolve)\n",
      "  Max sub-MIP depth 1\n",
      "  Nodes             1\n",
      "  Repair LPs        0 (0 feasible; 0 iterations)\n",
      "  LP iterations     2351 (total)\n",
      "                    0 (strong br.)\n",
      "                    1159 (separation)\n",
      "                    210 (heuristics)\n",
      "status= Optimal\n",
      "Downlink_plan_starting\n"
     ]
    }
   ],
   "source": [
    "GS_pass_df = pd.read_csv(\"1_input_data/GS_Passes_new (1).csv\")\n",
    "image_opportunity_df = pd.read_csv(\"1_input_data/Imaging_new (1) copy.csv\")\n",
    "image_downlink_df = pd.read_csv(\"1_input_data/APS_imageTable_TV1.csv\")\n",
    "eclipse_df = pd.DataFrame()\n",
    "with open('1_input_data/config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "result_dict = get_schedule(config,GS_pass_df,image_opportunity_df,image_downlink_df,eclipse_df)\n",
    "for k,v in result_dict.items():\n",
    "    v.to_csv('5_output_data/'+k+'.csv',index=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SatID\n",
       "FF01    356.0\n",
       "FF02    358.0\n",
       "FF03    344.0\n",
       "Name: cool_time, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_pass_df = pd.read_csv(\"1_input_data/GS_Passes_new (1).csv\")\n",
    "GS_pass_df['d'] = GS_pass_df['LOSOffset'] - GS_pass_df['AOSOffset']\n",
    "GS_pass_df.sort_values(by=['SatID','AOSOffset'],ascending=True,inplace=True)\n",
    "GS_pass_df['los_shift'] = GS_pass_df.groupby('SatID')['LOSOffset'].shift(1)\n",
    "GS_pass_df['cool_time'] = GS_pass_df['AOSOffset']- GS_pass_df['los_shift']\n",
    "GS_pass_df.sort_values(by=['SatID','AOSOffset'],ascending=True,inplace=True)\n",
    "GS_pass_df.groupby(\"SatID\")['cool_time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'GsID', 'AOS', 'LOS', 'Eclipse', 'AOSOffset', 'LOSOffset',\n",
       "       'SatID', 'd', 'los_shift', 'cool_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_pass_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['criteria', 'before_APS', 'APS_result', 'remarks', 'percentage',\n",
       "       'base_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['interpret_KPI_df'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['only_readout_result', 'only_img_capture_result', 'only_gsPass_result', 'combined_result', 'interpret_extracted_raw_file_df', 'interpret_selected_oppr_conflict_comparision_df', 'interpret_KPI_df'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ImageID', 'SatID', 'DueDate', 'Priority', 'Tilestrips', 'Sensors',\n",
       "       'Bands', 'EmergencyFlag', 'CaptureDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_pass_df = GS_pass_df = pd.read_csv(\"1_input_data/GS_Passes_new (1).csv\")\n",
    "image_opportunity_df = pd.read_csv(\"1_input_data/Imaging_new (1) copy.csv\")\n",
    "image_downlink_df = pd.read_csv(\"1_input_data/APS_imageTable_TV1.csv\")\n",
    "image_downlink_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-48283.5824309=25 strips 83 gspasses,-48283.5824309=25 strips 83 gspasses,-48283.5824309=26 strips 83 gspasses ,  -48283.5824309= 24 strips 82 gspasses , -48283.5824309 25 strips 82 gs PASss,-48283.5824309 24 strips 83 gs PASss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GS_pass_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(image_opportunity_df['Priority'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['only_readout_result', 'only_img_capture_result', 'only_gsPass_result', 'combined_result', 'interpret_extracted_raw_file_df', 'interpret_selected_oppr_conflict_comparision_df', 'interpret_KPI_df'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 83)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['only_img_capture_result']['StripID'].nunique(),len(result_dict['only_gsPass_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SatID</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>gsID</th>\n",
       "      <th>base_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 12:36:49</td>\n",
       "      <td>2024-11-14 12:44:54</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 12:51:35</td>\n",
       "      <td>2024-11-14 13:02:18</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 13:07:41</td>\n",
       "      <td>2024-11-14 13:17:44</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 13:23:42</td>\n",
       "      <td>2024-11-14 13:34:21</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 13:39:21</td>\n",
       "      <td>2024-11-14 13:50:02</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 13:51:01</td>\n",
       "      <td>2024-11-14 13:54:32</td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 13:55:46</td>\n",
       "      <td>2024-11-14 14:06:22</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 14:11:39</td>\n",
       "      <td>2024-11-14 14:21:49</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 14:27:45</td>\n",
       "      <td>2024-11-14 14:38:18</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 14:44:54</td>\n",
       "      <td>2024-11-14 14:53:03</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 14:59:46</td>\n",
       "      <td>2024-11-14 15:10:18</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 15:31:47</td>\n",
       "      <td>2024-11-14 15:42:18</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 16:03:42</td>\n",
       "      <td>2024-11-14 16:14:14</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 16:35:42</td>\n",
       "      <td>2024-11-14 16:46:17</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 17:07:42</td>\n",
       "      <td>2024-11-14 17:18:20</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 17:39:40</td>\n",
       "      <td>2024-11-14 17:50:22</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 17:46:17</td>\n",
       "      <td>2024-11-14 17:50:22</td>\n",
       "      <td>MAU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 18:11:44</td>\n",
       "      <td>2024-11-14 18:22:28</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 18:17:06</td>\n",
       "      <td>2024-11-14 18:22:28</td>\n",
       "      <td>MAU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 18:43:51</td>\n",
       "      <td>2024-11-14 18:54:37</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 18:48:46</td>\n",
       "      <td>2024-11-14 18:54:37</td>\n",
       "      <td>MAU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 19:15:57</td>\n",
       "      <td>2024-11-14 19:26:43</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 19:21:08</td>\n",
       "      <td>2024-11-14 19:26:43</td>\n",
       "      <td>MAU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 19:48:13</td>\n",
       "      <td>2024-11-14 19:58:54</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 19:54:21</td>\n",
       "      <td>2024-11-14 19:58:54</td>\n",
       "      <td>MAU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 20:20:33</td>\n",
       "      <td>2024-11-14 20:31:07</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 20:35:38</td>\n",
       "      <td>2024-11-14 20:36:36</td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 20:52:55</td>\n",
       "      <td>2024-11-14 21:03:17</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 21:04:14</td>\n",
       "      <td>2024-11-14 21:11:06</td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 21:25:28</td>\n",
       "      <td>2024-11-14 21:35:32</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 21:34:45</td>\n",
       "      <td>2024-11-14 21:35:32</td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 21:58:07</td>\n",
       "      <td>2024-11-14 22:07:47</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 22:06:00</td>\n",
       "      <td>2024-11-14 22:07:47</td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 22:30:48</td>\n",
       "      <td>2024-11-14 22:40:00</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 22:37:48</td>\n",
       "      <td>2024-11-14 22:40:00</td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 23:03:41</td>\n",
       "      <td>2024-11-14 23:12:17</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-14 23:10:02</td>\n",
       "      <td>2024-11-14 23:12:17</td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-14 23:36:41</td>\n",
       "      <td>2024-11-14 23:44:35</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-14 23:42:56</td>\n",
       "      <td>2024-11-14 23:44:35</td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-15 00:09:42</td>\n",
       "      <td>2024-11-15 00:16:50</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-15 00:16:47</td>\n",
       "      <td>2024-11-15 00:16:50</td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-15 00:42:54</td>\n",
       "      <td>2024-11-15 00:49:10</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-15 01:01:18</td>\n",
       "      <td>2024-11-15 01:06:43</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-15 01:16:11</td>\n",
       "      <td>2024-11-15 01:21:31</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-15 01:31:46</td>\n",
       "      <td>2024-11-15 01:40:54</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-15 01:49:27</td>\n",
       "      <td>2024-11-15 01:53:50</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-15 02:03:14</td>\n",
       "      <td>2024-11-15 02:13:41</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-15 02:22:48</td>\n",
       "      <td>2024-11-15 02:26:17</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-15 02:35:16</td>\n",
       "      <td>2024-11-15 02:45:46</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-15 02:56:05</td>\n",
       "      <td>2024-11-15 02:58:51</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-15 03:07:46</td>\n",
       "      <td>2024-11-15 03:17:08</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-15 03:29:06</td>\n",
       "      <td>2024-11-15 03:31:34</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-15 03:40:52</td>\n",
       "      <td>2024-11-15 03:47:27</td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-15 04:01:53</td>\n",
       "      <td>2024-11-15 04:04:39</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-15 04:34:26</td>\n",
       "      <td>2024-11-15 04:37:56</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>FF03</td>\n",
       "      <td>2024-11-15 05:04:56</td>\n",
       "      <td>2024-11-15 05:08:08</td>\n",
       "      <td>MAU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-15 05:06:49</td>\n",
       "      <td>2024-11-15 05:08:08</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>FF01</td>\n",
       "      <td>2024-11-15 05:33:57</td>\n",
       "      <td>2024-11-15 05:42:33</td>\n",
       "      <td>MAU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-15 05:39:12</td>\n",
       "      <td>2024-11-15 05:42:33</td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>FF02</td>\n",
       "      <td>2024-11-15 06:04:59</td>\n",
       "      <td>2024-11-15 06:15:21</td>\n",
       "      <td>MAU01</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SatID          start_time            end_time        gsID  \\\n",
       "30  FF01 2024-11-14 12:36:49 2024-11-14 12:44:54      JEJU01   \n",
       "31  FF01 2024-11-14 12:51:35 2024-11-14 13:02:18  SVALBARD01   \n",
       "32  FF02 2024-11-14 13:07:41 2024-11-14 13:17:44      JEJU01   \n",
       "33  FF02 2024-11-14 13:23:42 2024-11-14 13:34:21  SVALBARD01   \n",
       "34  FF03 2024-11-14 13:39:21 2024-11-14 13:50:02      JEJU01   \n",
       "35  FF01 2024-11-14 13:51:01 2024-11-14 13:54:32    AWARUA01   \n",
       "36  FF03 2024-11-14 13:55:46 2024-11-14 14:06:22  SVALBARD01   \n",
       "37  FF01 2024-11-14 14:11:39 2024-11-14 14:21:49      JEJU01   \n",
       "38  FF01 2024-11-14 14:27:45 2024-11-14 14:38:18  SVALBARD01   \n",
       "39  FF02 2024-11-14 14:44:54 2024-11-14 14:53:03      JEJU01   \n",
       "40  FF02 2024-11-14 14:59:46 2024-11-14 15:10:18  SVALBARD01   \n",
       "41  FF03 2024-11-14 15:31:47 2024-11-14 15:42:18  SVALBARD01   \n",
       "42  FF01 2024-11-14 16:03:42 2024-11-14 16:14:14  SVALBARD01   \n",
       "43  FF02 2024-11-14 16:35:42 2024-11-14 16:46:17  SVALBARD01   \n",
       "44  FF03 2024-11-14 17:07:42 2024-11-14 17:18:20  SVALBARD01   \n",
       "45  FF01 2024-11-14 17:39:40 2024-11-14 17:50:22  SVALBARD01   \n",
       "46  FF02 2024-11-14 17:46:17 2024-11-14 17:50:22       MAU01   \n",
       "47  FF02 2024-11-14 18:11:44 2024-11-14 18:22:28  SVALBARD01   \n",
       "48  FF03 2024-11-14 18:17:06 2024-11-14 18:22:28       MAU01   \n",
       "49  FF03 2024-11-14 18:43:51 2024-11-14 18:54:37  SVALBARD01   \n",
       "50  FF01 2024-11-14 18:48:46 2024-11-14 18:54:37       MAU01   \n",
       "51  FF01 2024-11-14 19:15:57 2024-11-14 19:26:43  SVALBARD01   \n",
       "52  FF02 2024-11-14 19:21:08 2024-11-14 19:26:43       MAU01   \n",
       "53  FF02 2024-11-14 19:48:13 2024-11-14 19:58:54  SVALBARD01   \n",
       "54  FF03 2024-11-14 19:54:21 2024-11-14 19:58:54       MAU01   \n",
       "55  FF03 2024-11-14 20:20:33 2024-11-14 20:31:07  SVALBARD01   \n",
       "56  FF02 2024-11-14 20:35:38 2024-11-14 20:36:36    AWARUA01   \n",
       "57  FF01 2024-11-14 20:52:55 2024-11-14 21:03:17  SVALBARD01   \n",
       "58  FF03 2024-11-14 21:04:14 2024-11-14 21:11:06    AWARUA01   \n",
       "59  FF02 2024-11-14 21:25:28 2024-11-14 21:35:32  SVALBARD01   \n",
       "60  FF01 2024-11-14 21:34:45 2024-11-14 21:35:32    AWARUA01   \n",
       "61  FF03 2024-11-14 21:58:07 2024-11-14 22:07:47  SVALBARD01   \n",
       "62  FF02 2024-11-14 22:06:00 2024-11-14 22:07:47    AWARUA01   \n",
       "63  FF01 2024-11-14 22:30:48 2024-11-14 22:40:00  SVALBARD01   \n",
       "64  FF03 2024-11-14 22:37:48 2024-11-14 22:40:00    AWARUA01   \n",
       "65  FF02 2024-11-14 23:03:41 2024-11-14 23:12:17  SVALBARD01   \n",
       "66  FF01 2024-11-14 23:10:02 2024-11-14 23:12:17    AWARUA01   \n",
       "67  FF03 2024-11-14 23:36:41 2024-11-14 23:44:35  SVALBARD01   \n",
       "68  FF02 2024-11-14 23:42:56 2024-11-14 23:44:35    AWARUA01   \n",
       "69  FF01 2024-11-15 00:09:42 2024-11-15 00:16:50  SVALBARD01   \n",
       "70  FF03 2024-11-15 00:16:47 2024-11-15 00:16:50    AWARUA01   \n",
       "71  FF02 2024-11-15 00:42:54 2024-11-15 00:49:10  SVALBARD01   \n",
       "72  FF02 2024-11-15 01:01:18 2024-11-15 01:06:43      JEJU01   \n",
       "73  FF03 2024-11-15 01:16:11 2024-11-15 01:21:31  SVALBARD01   \n",
       "74  FF03 2024-11-15 01:31:46 2024-11-15 01:40:54      JEJU01   \n",
       "75  FF01 2024-11-15 01:49:27 2024-11-15 01:53:50  SVALBARD01   \n",
       "76  FF01 2024-11-15 02:03:14 2024-11-15 02:13:41      JEJU01   \n",
       "77  FF02 2024-11-15 02:22:48 2024-11-15 02:26:17  SVALBARD01   \n",
       "78  FF02 2024-11-15 02:35:16 2024-11-15 02:45:46      JEJU01   \n",
       "79  FF03 2024-11-15 02:56:05 2024-11-15 02:58:51  SVALBARD01   \n",
       "80  FF03 2024-11-15 03:07:46 2024-11-15 03:17:08      JEJU01   \n",
       "81  FF01 2024-11-15 03:29:06 2024-11-15 03:31:34  SVALBARD01   \n",
       "82  FF01 2024-11-15 03:40:52 2024-11-15 03:47:27      JEJU01   \n",
       "83  FF02 2024-11-15 04:01:53 2024-11-15 04:04:39  SVALBARD01   \n",
       "84  FF03 2024-11-15 04:34:26 2024-11-15 04:37:56  SVALBARD01   \n",
       "85  FF03 2024-11-15 05:04:56 2024-11-15 05:08:08       MAU01   \n",
       "86  FF01 2024-11-15 05:06:49 2024-11-15 05:08:08  SVALBARD01   \n",
       "87  FF01 2024-11-15 05:33:57 2024-11-15 05:42:33       MAU01   \n",
       "88  FF02 2024-11-15 05:39:12 2024-11-15 05:42:33  SVALBARD01   \n",
       "89  FF02 2024-11-15 06:04:59 2024-11-15 06:15:21       MAU01   \n",
       "\n",
       "             base_time  \n",
       "30 2024-11-13 12:30:44  \n",
       "31 2024-11-13 12:30:44  \n",
       "32 2024-11-13 12:30:44  \n",
       "33 2024-11-13 12:30:44  \n",
       "34 2024-11-13 12:30:44  \n",
       "35 2024-11-13 12:30:44  \n",
       "36 2024-11-13 12:30:44  \n",
       "37 2024-11-13 12:30:44  \n",
       "38 2024-11-13 12:30:44  \n",
       "39 2024-11-13 12:30:44  \n",
       "40 2024-11-13 12:30:44  \n",
       "41 2024-11-13 12:30:44  \n",
       "42 2024-11-13 12:30:44  \n",
       "43 2024-11-13 12:30:44  \n",
       "44 2024-11-13 12:30:44  \n",
       "45 2024-11-13 12:30:44  \n",
       "46 2024-11-13 12:30:44  \n",
       "47 2024-11-13 12:30:44  \n",
       "48 2024-11-13 12:30:44  \n",
       "49 2024-11-13 12:30:44  \n",
       "50 2024-11-13 12:30:44  \n",
       "51 2024-11-13 12:30:44  \n",
       "52 2024-11-13 12:30:44  \n",
       "53 2024-11-13 12:30:44  \n",
       "54 2024-11-13 12:30:44  \n",
       "55 2024-11-13 12:30:44  \n",
       "56 2024-11-13 12:30:44  \n",
       "57 2024-11-13 12:30:44  \n",
       "58 2024-11-13 12:30:44  \n",
       "59 2024-11-13 12:30:44  \n",
       "60 2024-11-13 12:30:44  \n",
       "61 2024-11-13 12:30:44  \n",
       "62 2024-11-13 12:30:44  \n",
       "63 2024-11-13 12:30:44  \n",
       "64 2024-11-13 12:30:44  \n",
       "65 2024-11-13 12:30:44  \n",
       "66 2024-11-13 12:30:44  \n",
       "67 2024-11-13 12:30:44  \n",
       "68 2024-11-13 12:30:44  \n",
       "69 2024-11-13 12:30:44  \n",
       "70 2024-11-13 12:30:44  \n",
       "71 2024-11-13 12:30:44  \n",
       "72 2024-11-13 12:30:44  \n",
       "73 2024-11-13 12:30:44  \n",
       "74 2024-11-13 12:30:44  \n",
       "75 2024-11-13 12:30:44  \n",
       "76 2024-11-13 12:30:44  \n",
       "77 2024-11-13 12:30:44  \n",
       "78 2024-11-13 12:30:44  \n",
       "79 2024-11-13 12:30:44  \n",
       "80 2024-11-13 12:30:44  \n",
       "81 2024-11-13 12:30:44  \n",
       "82 2024-11-13 12:30:44  \n",
       "83 2024-11-13 12:30:44  \n",
       "84 2024-11-13 12:30:44  \n",
       "85 2024-11-13 12:30:44  \n",
       "86 2024-11-13 12:30:44  \n",
       "87 2024-11-13 12:30:44  \n",
       "88 2024-11-13 12:30:44  \n",
       "89 2024-11-13 12:30:44  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['only_gsPass_result'].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SatID</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>encoded_strip_id</th>\n",
       "      <th>gsID</th>\n",
       "      <th>operation</th>\n",
       "      <th>camera_memory_value_endofTW</th>\n",
       "      <th>delta_camera_memory_value_in_this_TW</th>\n",
       "      <th>SSD_memory_value_endofTW</th>\n",
       "      <th>delta_SSD_memory_value_in_this_TW</th>\n",
       "      <th>global_priority</th>\n",
       "      <th>local_priority</th>\n",
       "      <th>mean_global_priority</th>\n",
       "      <th>mean_local_priority</th>\n",
       "      <th>StripID</th>\n",
       "      <th>AoiID</th>\n",
       "      <th>base_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>FF02</td>\n",
       "      <td>88617.0</td>\n",
       "      <td>89220.0</td>\n",
       "      <td></td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FF02</td>\n",
       "      <td>89578.0</td>\n",
       "      <td>90217.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FF02</td>\n",
       "      <td>91482.0</td>\n",
       "      <td>91498.0</td>\n",
       "      <td>Order 53 - Strip 3_Area 36</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>132.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1029.347967</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1029.347967</td>\n",
       "      <td>Order 53 - Strip 3</td>\n",
       "      <td>Area 36</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FF02</td>\n",
       "      <td>91539.0</td>\n",
       "      <td>92164.0</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-500.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FF02</td>\n",
       "      <td>94450.0</td>\n",
       "      <td>94939.0</td>\n",
       "      <td></td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FF02</td>\n",
       "      <td>95342.0</td>\n",
       "      <td>95974.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FF02</td>\n",
       "      <td>95975.0</td>\n",
       "      <td>96137.5</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FF02</td>\n",
       "      <td>101098.0</td>\n",
       "      <td>101733.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FF02</td>\n",
       "      <td>102364.0</td>\n",
       "      <td>102380.0</td>\n",
       "      <td>Order 14 - Strip 3_Area 18</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>112.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>766.940092</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>766.940092</td>\n",
       "      <td>Order 14 - Strip 3</td>\n",
       "      <td>Area 18</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FF02</td>\n",
       "      <td>105333.0</td>\n",
       "      <td>105578.0</td>\n",
       "      <td></td>\n",
       "      <td>MAU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FF02</td>\n",
       "      <td>106860.0</td>\n",
       "      <td>107504.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FF02</td>\n",
       "      <td>107731.0</td>\n",
       "      <td>107756.0</td>\n",
       "      <td>Order 44 - Strip 3_Area 35</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>175.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>750.0</td>\n",
       "      <td>962.882406</td>\n",
       "      <td>750.0</td>\n",
       "      <td>939.647829</td>\n",
       "      <td>Order 44 - Strip 3</td>\n",
       "      <td>Area 35</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FF02</td>\n",
       "      <td>107955.0</td>\n",
       "      <td>107971.0</td>\n",
       "      <td>Order 4 - Strip 3_Area 0</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>287.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1057.444263</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1057.444263</td>\n",
       "      <td>Order 4 - Strip 3</td>\n",
       "      <td>Area 0</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FF02</td>\n",
       "      <td>111024.0</td>\n",
       "      <td>111359.0</td>\n",
       "      <td></td>\n",
       "      <td>MAU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>FF02</td>\n",
       "      <td>112649.0</td>\n",
       "      <td>113290.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FF02</td>\n",
       "      <td>113500.0</td>\n",
       "      <td>113535.0</td>\n",
       "      <td>Order 46 - Strip 3_Area 35</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1113.287849</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1113.287849</td>\n",
       "      <td>Order 46 - Strip 3</td>\n",
       "      <td>Area 35</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>FF02</td>\n",
       "      <td>115494.0</td>\n",
       "      <td>115552.0</td>\n",
       "      <td></td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>FF02</td>\n",
       "      <td>118484.0</td>\n",
       "      <td>119088.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>FF02</td>\n",
       "      <td>120916.0</td>\n",
       "      <td>121023.0</td>\n",
       "      <td></td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>FF02</td>\n",
       "      <td>124377.0</td>\n",
       "      <td>124893.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>FF02</td>\n",
       "      <td>126732.0</td>\n",
       "      <td>126831.0</td>\n",
       "      <td></td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>FF02</td>\n",
       "      <td>130330.0</td>\n",
       "      <td>130706.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>FF02</td>\n",
       "      <td>131434.0</td>\n",
       "      <td>131759.0</td>\n",
       "      <td></td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>FF02</td>\n",
       "      <td>136324.0</td>\n",
       "      <td>136533.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>FF02</td>\n",
       "      <td>137072.0</td>\n",
       "      <td>137702.0</td>\n",
       "      <td></td>\n",
       "      <td>JEJU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>FF02</td>\n",
       "      <td>142269.0</td>\n",
       "      <td>142435.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>FF02</td>\n",
       "      <td>148108.0</td>\n",
       "      <td>148309.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>FF02</td>\n",
       "      <td>149655.0</td>\n",
       "      <td>150277.0</td>\n",
       "      <td></td>\n",
       "      <td>MAU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>FF02</td>\n",
       "      <td>153924.0</td>\n",
       "      <td>154085.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>FF02</td>\n",
       "      <td>155596.0</td>\n",
       "      <td>155884.0</td>\n",
       "      <td></td>\n",
       "      <td>MAU01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>FF02</td>\n",
       "      <td>159732.0</td>\n",
       "      <td>160312.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FF02</td>\n",
       "      <td>160664.0</td>\n",
       "      <td>160674.0</td>\n",
       "      <td>Order 29 - Strip 0_Area 26</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1034.990488</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1034.990488</td>\n",
       "      <td>Order 29 - Strip 0</td>\n",
       "      <td>Area 26</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>FF02</td>\n",
       "      <td>163400.0</td>\n",
       "      <td>163525.0</td>\n",
       "      <td></td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>FF02</td>\n",
       "      <td>165532.0</td>\n",
       "      <td>165651.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FF02</td>\n",
       "      <td>166424.0</td>\n",
       "      <td>166440.0</td>\n",
       "      <td>Order 28 - Strip 3_Area 24</td>\n",
       "      <td></td>\n",
       "      <td>Imaging</td>\n",
       "      <td>112.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1008.886351</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1008.886351</td>\n",
       "      <td>Order 28 - Strip 3</td>\n",
       "      <td>Area 24</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>FF02</td>\n",
       "      <td>168967.0</td>\n",
       "      <td>169611.0</td>\n",
       "      <td></td>\n",
       "      <td>AWARUA01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>FF02</td>\n",
       "      <td>171322.0</td>\n",
       "      <td>171537.0</td>\n",
       "      <td></td>\n",
       "      <td>SVALBARD01</td>\n",
       "      <td>downlinking_from_Readout</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>no_i_no_g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SatID  start_time  end_time            encoded_strip_id        gsID  \\\n",
       "32   FF02     88617.0   89220.0                                  JEJU01   \n",
       "33   FF02     89578.0   90217.0                              SVALBARD01   \n",
       "5    FF02     91482.0   91498.0  Order 53 - Strip 3_Area 36               \n",
       "1    FF02     91539.0   92164.0                   no_i_no_g   no_i_no_g   \n",
       "39   FF02     94450.0   94939.0                                  JEJU01   \n",
       "40   FF02     95342.0   95974.0                              SVALBARD01   \n",
       "3    FF02     95975.0   96137.5                   no_i_no_g   no_i_no_g   \n",
       "43   FF02    101098.0  101733.0                              SVALBARD01   \n",
       "7    FF02    102364.0  102380.0  Order 14 - Strip 3_Area 18               \n",
       "46   FF02    105333.0  105578.0                                   MAU01   \n",
       "47   FF02    106860.0  107504.0                              SVALBARD01   \n",
       "9    FF02    107731.0  107756.0  Order 44 - Strip 3_Area 35               \n",
       "10   FF02    107955.0  107971.0    Order 4 - Strip 3_Area 0               \n",
       "52   FF02    111024.0  111359.0                                   MAU01   \n",
       "53   FF02    112649.0  113290.0                              SVALBARD01   \n",
       "15   FF02    113500.0  113535.0  Order 46 - Strip 3_Area 35               \n",
       "56   FF02    115494.0  115552.0                                AWARUA01   \n",
       "59   FF02    118484.0  119088.0                              SVALBARD01   \n",
       "62   FF02    120916.0  121023.0                                AWARUA01   \n",
       "65   FF02    124377.0  124893.0                              SVALBARD01   \n",
       "68   FF02    126732.0  126831.0                                AWARUA01   \n",
       "71   FF02    130330.0  130706.0                              SVALBARD01   \n",
       "72   FF02    131434.0  131759.0                                  JEJU01   \n",
       "77   FF02    136324.0  136533.0                              SVALBARD01   \n",
       "78   FF02    137072.0  137702.0                                  JEJU01   \n",
       "83   FF02    142269.0  142435.0                              SVALBARD01   \n",
       "88   FF02    148108.0  148309.0                              SVALBARD01   \n",
       "89   FF02    149655.0  150277.0                                   MAU01   \n",
       "94   FF02    153924.0  154085.0                              SVALBARD01   \n",
       "95   FF02    155596.0  155884.0                                   MAU01   \n",
       "98   FF02    159732.0  160312.0                              SVALBARD01   \n",
       "26   FF02    160664.0  160674.0  Order 29 - Strip 0_Area 26               \n",
       "100  FF02    163400.0  163525.0                                AWARUA01   \n",
       "103  FF02    165532.0  165651.0                              SVALBARD01   \n",
       "27   FF02    166424.0  166440.0  Order 28 - Strip 3_Area 24               \n",
       "106  FF02    168967.0  169611.0                                AWARUA01   \n",
       "109  FF02    171322.0  171537.0                              SVALBARD01   \n",
       "\n",
       "                    operation  camera_memory_value_endofTW  \\\n",
       "32   downlinking_from_Readout                         20.0   \n",
       "33   downlinking_from_Readout                         20.0   \n",
       "5                     Imaging                        132.0   \n",
       "1                     Readout                          0.0   \n",
       "39   downlinking_from_Readout                          0.0   \n",
       "40   downlinking_from_Readout                          0.0   \n",
       "3                     Readout                          0.0   \n",
       "43   downlinking_from_Readout                          0.0   \n",
       "7                     Imaging                        112.0   \n",
       "46   downlinking_from_Readout                          0.0   \n",
       "47   downlinking_from_Readout                          0.0   \n",
       "9                     Imaging                        175.0   \n",
       "10                    Imaging                        287.0   \n",
       "52   downlinking_from_Readout                        755.0   \n",
       "53   downlinking_from_Readout                        755.0   \n",
       "15                    Imaging                       1000.0   \n",
       "56   downlinking_from_Readout                          0.0   \n",
       "59   downlinking_from_Readout                          0.0   \n",
       "62   downlinking_from_Readout                          0.0   \n",
       "65   downlinking_from_Readout                          0.0   \n",
       "68   downlinking_from_Readout                          0.0   \n",
       "71   downlinking_from_Readout                          0.0   \n",
       "72   downlinking_from_Readout                          0.0   \n",
       "77   downlinking_from_Readout                          0.0   \n",
       "78   downlinking_from_Readout                          0.0   \n",
       "83   downlinking_from_Readout                          0.0   \n",
       "88   downlinking_from_Readout                          0.0   \n",
       "89   downlinking_from_Readout                          0.0   \n",
       "94   downlinking_from_Readout                          0.0   \n",
       "95   downlinking_from_Readout                          0.0   \n",
       "98   downlinking_from_Readout                          0.0   \n",
       "26                    Imaging                         70.0   \n",
       "100  downlinking_from_Readout                          0.0   \n",
       "103  downlinking_from_Readout                          0.0   \n",
       "27                    Imaging                        112.0   \n",
       "106  downlinking_from_Readout                          0.0   \n",
       "109  downlinking_from_Readout                          0.0   \n",
       "\n",
       "     delta_camera_memory_value_in_this_TW SSD_memory_value_endofTW  \\\n",
       "32                                    0.0                       NA   \n",
       "33                                    0.0                       NA   \n",
       "5                                   112.0                       NA   \n",
       "1                                  -500.0                    850.0   \n",
       "39                                    0.0                       NA   \n",
       "40                                    0.0                       NA   \n",
       "3                                  -130.0                    980.0   \n",
       "43                                    0.0                       NA   \n",
       "7                                   112.0                       NA   \n",
       "46                                    0.0                       NA   \n",
       "47                                    0.0                       NA   \n",
       "9                                   175.0                       NA   \n",
       "10                                  112.0                       NA   \n",
       "52                                    0.0                       NA   \n",
       "53                                    0.0                       NA   \n",
       "15                                  245.0                       NA   \n",
       "56                                    0.0                       NA   \n",
       "59                                    0.0                       NA   \n",
       "62                                    0.0                       NA   \n",
       "65                                    0.0                       NA   \n",
       "68                                    0.0                       NA   \n",
       "71                                    0.0                       NA   \n",
       "72                                    0.0                       NA   \n",
       "77                                    0.0                       NA   \n",
       "78                                    0.0                       NA   \n",
       "83                                    0.0                       NA   \n",
       "88                                    0.0                       NA   \n",
       "89                                    0.0                       NA   \n",
       "94                                    0.0                       NA   \n",
       "95                                    0.0                       NA   \n",
       "98                                    0.0                       NA   \n",
       "26                                   70.0                       NA   \n",
       "100                                   0.0                       NA   \n",
       "103                                   0.0                       NA   \n",
       "27                                  112.0                       NA   \n",
       "106                                   0.0                       NA   \n",
       "109                                   0.0                       NA   \n",
       "\n",
       "    delta_SSD_memory_value_in_this_TW global_priority local_priority  \\\n",
       "32                                 NA       no_i_no_g      no_i_no_g   \n",
       "33                                 NA       no_i_no_g      no_i_no_g   \n",
       "5                                  NA          1000.0    1029.347967   \n",
       "1                               500.0       no_i_no_g      no_i_no_g   \n",
       "39                                 NA       no_i_no_g      no_i_no_g   \n",
       "40                                 NA       no_i_no_g      no_i_no_g   \n",
       "3                               130.0       no_i_no_g      no_i_no_g   \n",
       "43                                 NA       no_i_no_g      no_i_no_g   \n",
       "7                                  NA          1000.0     766.940092   \n",
       "46                                 NA       no_i_no_g      no_i_no_g   \n",
       "47                                 NA       no_i_no_g      no_i_no_g   \n",
       "9                                  NA           750.0     962.882406   \n",
       "10                                 NA           750.0    1057.444263   \n",
       "52                                 NA       no_i_no_g      no_i_no_g   \n",
       "53                                 NA       no_i_no_g      no_i_no_g   \n",
       "15                                 NA           750.0    1113.287849   \n",
       "56                                 NA       no_i_no_g      no_i_no_g   \n",
       "59                                 NA       no_i_no_g      no_i_no_g   \n",
       "62                                 NA       no_i_no_g      no_i_no_g   \n",
       "65                                 NA       no_i_no_g      no_i_no_g   \n",
       "68                                 NA       no_i_no_g      no_i_no_g   \n",
       "71                                 NA       no_i_no_g      no_i_no_g   \n",
       "72                                 NA       no_i_no_g      no_i_no_g   \n",
       "77                                 NA       no_i_no_g      no_i_no_g   \n",
       "78                                 NA       no_i_no_g      no_i_no_g   \n",
       "83                                 NA       no_i_no_g      no_i_no_g   \n",
       "88                                 NA       no_i_no_g      no_i_no_g   \n",
       "89                                 NA       no_i_no_g      no_i_no_g   \n",
       "94                                 NA       no_i_no_g      no_i_no_g   \n",
       "95                                 NA       no_i_no_g      no_i_no_g   \n",
       "98                                 NA       no_i_no_g      no_i_no_g   \n",
       "26                                 NA           500.0    1034.990488   \n",
       "100                                NA       no_i_no_g      no_i_no_g   \n",
       "103                                NA       no_i_no_g      no_i_no_g   \n",
       "27                                 NA           500.0    1008.886351   \n",
       "106                                NA       no_i_no_g      no_i_no_g   \n",
       "109                                NA       no_i_no_g      no_i_no_g   \n",
       "\n",
       "    mean_global_priority mean_local_priority             StripID    AoiID  \\\n",
       "32             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "33             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "5                 1000.0         1029.347967  Order 53 - Strip 3  Area 36   \n",
       "1              no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "39             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "40             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "3              no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "43             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "7                 1000.0          766.940092  Order 14 - Strip 3  Area 18   \n",
       "46             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "47             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "9                  750.0          939.647829  Order 44 - Strip 3  Area 35   \n",
       "10                 750.0         1057.444263   Order 4 - Strip 3   Area 0   \n",
       "52             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "53             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "15                 750.0         1113.287849  Order 46 - Strip 3  Area 35   \n",
       "56             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "59             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "62             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "65             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "68             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "71             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "72             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "77             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "78             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "83             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "88             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "89             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "94             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "95             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "98             no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "26                 500.0         1034.990488  Order 29 - Strip 0  Area 26   \n",
       "100            no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "103            no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "27                 500.0         1008.886351  Order 28 - Strip 3  Area 24   \n",
       "106            no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "109            no_i_no_g           no_i_no_g                 NaN      NaN   \n",
       "\n",
       "              base_time  \n",
       "32  2024-11-13 12:30:44  \n",
       "33  2024-11-13 12:30:44  \n",
       "5   2024-11-13 12:30:44  \n",
       "1   2024-11-13 12:30:44  \n",
       "39  2024-11-13 12:30:44  \n",
       "40  2024-11-13 12:30:44  \n",
       "3   2024-11-13 12:30:44  \n",
       "43  2024-11-13 12:30:44  \n",
       "7   2024-11-13 12:30:44  \n",
       "46  2024-11-13 12:30:44  \n",
       "47  2024-11-13 12:30:44  \n",
       "9   2024-11-13 12:30:44  \n",
       "10  2024-11-13 12:30:44  \n",
       "52  2024-11-13 12:30:44  \n",
       "53  2024-11-13 12:30:44  \n",
       "15  2024-11-13 12:30:44  \n",
       "56  2024-11-13 12:30:44  \n",
       "59  2024-11-13 12:30:44  \n",
       "62  2024-11-13 12:30:44  \n",
       "65  2024-11-13 12:30:44  \n",
       "68  2024-11-13 12:30:44  \n",
       "71  2024-11-13 12:30:44  \n",
       "72  2024-11-13 12:30:44  \n",
       "77  2024-11-13 12:30:44  \n",
       "78  2024-11-13 12:30:44  \n",
       "83  2024-11-13 12:30:44  \n",
       "88  2024-11-13 12:30:44  \n",
       "89  2024-11-13 12:30:44  \n",
       "94  2024-11-13 12:30:44  \n",
       "95  2024-11-13 12:30:44  \n",
       "98  2024-11-13 12:30:44  \n",
       "26  2024-11-13 12:30:44  \n",
       "100 2024-11-13 12:30:44  \n",
       "103 2024-11-13 12:30:44  \n",
       "27  2024-11-13 12:30:44  \n",
       "106 2024-11-13 12:30:44  \n",
       "109 2024-11-13 12:30:44  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = result_dict['combined_result']\n",
    "A[A['SatID']=='FF02'].sort_values(by='start_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#capture_plan_data_input['']\n",
    "#-48283.5824309\n",
    "#-48271\n",
    "len(result_dict['interpret_selected_oppr_conflict_comparision_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conflic_strip_flag_named</th>\n",
       "      <th>max_Norm_TP</th>\n",
       "      <th>this_flag_norm_TP</th>\n",
       "      <th>max_Norm_GP</th>\n",
       "      <th>this_flag_norm_GP</th>\n",
       "      <th>max_Norm_LPDD</th>\n",
       "      <th>this_flag_norm_LLDD</th>\n",
       "      <th>base_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FF01_Order 11 - Strip 1_Area 13_1.0</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FF01_Order 22 - Strip 3_Area 21_1.0</td>\n",
       "      <td>568</td>\n",
       "      <td>568</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FF01_Order 30 - Strip 0_Area 27_1.0</td>\n",
       "      <td>555</td>\n",
       "      <td>555</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FF01_Order 47 - Strip 5_Area 35_1.0</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FF01_Order 57 - Strip 0_Area 36_1.0</td>\n",
       "      <td>725</td>\n",
       "      <td>725</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>FF01_Order 64 - Strip 3_Area 37_1.0</td>\n",
       "      <td>555</td>\n",
       "      <td>555</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>FF01_Order 67 - Strip 0_Area 6_1.0</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>FF01_Order 71 - Strip 1_Area 8_1.0</td>\n",
       "      <td>420</td>\n",
       "      <td>420</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>FF02_Order 4 - Strip 3_Area 0_1.0</td>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>FF02_Order 14 - Strip 3_Area 18_1.0</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>FF02_Order 28 - Strip 3_Area 24_1.0</td>\n",
       "      <td>401</td>\n",
       "      <td>401</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>FF02_Order 29 - Strip 0_Area 26_1.0</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>FF02_Order 44 - Strip 3_Area 35_1.0</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>FF02_Order 46 - Strip 3_Area 35_1.0</td>\n",
       "      <td>542</td>\n",
       "      <td>542</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>FF02_Order 53 - Strip 3_Area 36_1.0</td>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>FF03_Order 0 - Strip 4_Area 0_1.0</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>FF03_Order 9 - Strip 3_Area 13_1.0</td>\n",
       "      <td>404</td>\n",
       "      <td>404</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>FF03_Order 18 - Strip 1_Area 18_1.0</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>FF03_Order 20 - Strip 3_Area 20_1.0</td>\n",
       "      <td>552</td>\n",
       "      <td>552</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>FF03_Order 23 - Strip 1_Area 23_1.0</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>FF03_Order 41 - Strip 1_Area 34_1.0</td>\n",
       "      <td>701</td>\n",
       "      <td>701</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>FF03_Order 45 - Strip 0_Area 35_1.0</td>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>FF03_Order 48 - Strip 1_Area 35_1.0</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>908.001084</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>FF03_Order 59 - Strip 3_Area 36_1.0</td>\n",
       "      <td>570</td>\n",
       "      <td>570</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>FF03_Order 65 - Strip 2_Area 37_1.0</td>\n",
       "      <td>587</td>\n",
       "      <td>587</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>752.280794</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>FF03_Order 72 - Strip 3_Area 8_1.0</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2024-11-13 12:30:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                conflic_strip_flag_named  max_Norm_TP  this_flag_norm_TP  \\\n",
       "0    FF01_Order 11 - Strip 1_Area 13_1.0          403                403   \n",
       "6    FF01_Order 22 - Strip 3_Area 21_1.0          568                568   \n",
       "11   FF01_Order 30 - Strip 0_Area 27_1.0          555                555   \n",
       "16   FF01_Order 47 - Strip 5_Area 35_1.0          506                506   \n",
       "28   FF01_Order 57 - Strip 0_Area 36_1.0          725                725   \n",
       "49   FF01_Order 64 - Strip 3_Area 37_1.0          555                555   \n",
       "56    FF01_Order 67 - Strip 0_Area 6_1.0          700                700   \n",
       "72    FF01_Order 71 - Strip 1_Area 8_1.0          420                420   \n",
       "80     FF02_Order 4 - Strip 3_Area 0_1.0          525                525   \n",
       "91   FF02_Order 14 - Strip 3_Area 18_1.0          554                554   \n",
       "95   FF02_Order 28 - Strip 3_Area 24_1.0          401                401   \n",
       "96   FF02_Order 29 - Strip 0_Area 26_1.0          409                409   \n",
       "98   FF02_Order 44 - Strip 3_Area 35_1.0          488                488   \n",
       "105  FF02_Order 46 - Strip 3_Area 35_1.0          542                542   \n",
       "118  FF02_Order 53 - Strip 3_Area 36_1.0          591                591   \n",
       "131    FF03_Order 0 - Strip 4_Area 0_1.0          504                504   \n",
       "151   FF03_Order 9 - Strip 3_Area 13_1.0          404                404   \n",
       "156  FF03_Order 18 - Strip 1_Area 18_1.0          612                612   \n",
       "170  FF03_Order 20 - Strip 3_Area 20_1.0          552                552   \n",
       "171  FF03_Order 23 - Strip 1_Area 23_1.0          491                491   \n",
       "181  FF03_Order 41 - Strip 1_Area 34_1.0          701                701   \n",
       "196  FF03_Order 45 - Strip 0_Area 35_1.0          485                485   \n",
       "200  FF03_Order 48 - Strip 1_Area 35_1.0          498                498   \n",
       "209  FF03_Order 59 - Strip 3_Area 36_1.0          570                570   \n",
       "226  FF03_Order 65 - Strip 2_Area 37_1.0          587                587   \n",
       "233   FF03_Order 72 - Strip 3_Area 8_1.0          403                403   \n",
       "\n",
       "     max_Norm_GP  this_flag_norm_GP  max_Norm_LPDD  this_flag_norm_LLDD  \\\n",
       "0          500.0              500.0    1000.000000          1000.000000   \n",
       "6         1000.0             1000.0     752.280794           752.280794   \n",
       "11        1000.0             1000.0     752.280794           752.280794   \n",
       "16         750.0              750.0     908.001084           908.001084   \n",
       "28        1000.0             1000.0     752.280794           752.280794   \n",
       "49        1000.0             1000.0     752.280794           752.280794   \n",
       "56        1000.0             1000.0     908.001084           752.280794   \n",
       "72         500.0              500.0    1000.000000          1000.000000   \n",
       "80         750.0              750.0     908.001084           908.001084   \n",
       "91        1000.0             1000.0     752.280794           752.280794   \n",
       "95         500.0              500.0    1000.000000          1000.000000   \n",
       "96         500.0              500.0    1000.000000          1000.000000   \n",
       "98         750.0              750.0     908.001084           908.001084   \n",
       "105        750.0              750.0     908.001084           908.001084   \n",
       "118       1000.0             1000.0     752.280794           752.280794   \n",
       "131        750.0              750.0     908.001084           908.001084   \n",
       "151        500.0              500.0    1000.000000          1000.000000   \n",
       "156       1000.0             1000.0     752.280794           752.280794   \n",
       "170       1000.0             1000.0     752.280794           752.280794   \n",
       "171        750.0              750.0     908.001084           908.001084   \n",
       "181        500.0              500.0    1000.000000          1000.000000   \n",
       "196        750.0              750.0     908.001084           908.001084   \n",
       "200        750.0              750.0     908.001084           908.001084   \n",
       "209       1000.0             1000.0     752.280794           752.280794   \n",
       "226       1000.0             1000.0     752.280794           752.280794   \n",
       "233        500.0              500.0    1000.000000          1000.000000   \n",
       "\n",
       "              base_time  \n",
       "0   2024-11-13 12:30:44  \n",
       "6   2024-11-13 12:30:44  \n",
       "11  2024-11-13 12:30:44  \n",
       "16  2024-11-13 12:30:44  \n",
       "28  2024-11-13 12:30:44  \n",
       "49  2024-11-13 12:30:44  \n",
       "56  2024-11-13 12:30:44  \n",
       "72  2024-11-13 12:30:44  \n",
       "80  2024-11-13 12:30:44  \n",
       "91  2024-11-13 12:30:44  \n",
       "95  2024-11-13 12:30:44  \n",
       "96  2024-11-13 12:30:44  \n",
       "98  2024-11-13 12:30:44  \n",
       "105 2024-11-13 12:30:44  \n",
       "118 2024-11-13 12:30:44  \n",
       "131 2024-11-13 12:30:44  \n",
       "151 2024-11-13 12:30:44  \n",
       "156 2024-11-13 12:30:44  \n",
       "170 2024-11-13 12:30:44  \n",
       "171 2024-11-13 12:30:44  \n",
       "181 2024-11-13 12:30:44  \n",
       "196 2024-11-13 12:30:44  \n",
       "200 2024-11-13 12:30:44  \n",
       "209 2024-11-13 12:30:44  \n",
       "226 2024-11-13 12:30:44  \n",
       "233 2024-11-13 12:30:44  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['interpret_selected_oppr_conflict_comparision_df']#['conflic_strip_flag_named'].nunique()##['interpret_selected_oppr_conflict_comparision_df']#['interpret_extracted_raw_file_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downlink_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'extracted_raw_file_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m l1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_raw_file_df\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected_oppr_conflict_comparision_df\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKPI_df\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df111 \u001b[38;5;241m=\u001b[39m result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_raw_file_df\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'extracted_raw_file_df'"
     ]
    }
   ],
   "source": [
    "l1 = 'extracted_raw_file_df', 'selected_oppr_conflict_comparision_df', 'KPI_df'\n",
    "df111 = result_dict['extracted_raw_file_df']#.columns\n",
    "#interpret_result_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = img_capture_result[img_capture_result['operation']=='Imaging']#['StripID']#.nunique()\n",
    "Z = img_capture_result[img_capture_result['operation']=='downlinking_from_Readout']\n",
    "Z['duration'] = Z['end_time']- Z['start_time']\n",
    "#Y[Y['StripID']=='']\n",
    "\n",
    "#Y[Y['encoded_strip_id']=='Order 1 - Strip 0_Area 0']\n",
    "Y['StripID'].nunique(),len(Y),len(Z),Z['duration'].sum(),gs_pass_result_df['duration'].sum(),len(gs_pass_result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['SatID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI = Y[Y['SatID']=='FF03']\n",
    "RZO = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "CR = RZO[RZO['SatID']=='FF03']\n",
    "pd.concat([CI,CR]).sort_values(by='start_time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Order 1 - Strip 0_Area 0'\n",
    "RZO = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "RZO[RZO['SatID']=='FF01']\n",
    "RZO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RZ = capture_plan_data_input['dedicated_readout_df']\n",
    "len(RZ[RZ['SatID']=='FF01'].sort_values(by='start_time')),len(RZ[RZ['SatID']=='FF02'].sort_values(by='start_time')),len(RZ[RZ['SatID']=='FF03'].sort_values(by='start_time'))\n",
    "RZ[RZ['SatID']=='FF01'].sort_values(by='start_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_capture_result['operation'].unique()\n",
    "\n",
    "[ item for item in capture_plan_data_input['Memory_NoimageGs_TW_list'] if item[2]=='FF01']\n",
    "#capture_plan_data_input['dedicatedReadoutTWlist__concat_sat_memoryTWindex']['FF01_136.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['active_assured_strip_id_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_eclipse_data.csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eclipse_df[eclipse_df['eclipse']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse_df.sort_values(by='time_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SatID,start_time,end_time,eclipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['GS_pass_df', 'image_opportunity_df', 'image_downlink_df', 'eclipse_df_dict', 'config']\n",
    "#input_dict['eclipse_df_dict']['FF02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['readout_memory_capacity__s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['imgery_sat_id_list']#.keys()\n",
    "[s+'_'+str(n) for s in capture_plan_data_input['imgery_sat_id_list']+capture_plan_data_input['only_gs_sat_id_list'] \\\n",
    " if s in capture_plan_data_input['dedicatedReadoutTWIndex__sat'].keys() for n in capture_plan_data_input['dedicatedReadoutTWIndex__sat'][s]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "\n",
    "#eclipse_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['active_assured_strip_id_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['assured_tasking_based_on_input_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['cs1j2k2Domainlist__cs1j1k1']['FF01_Order 1 - Strip 0_Area 0_1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input['GS_Pass_time_objective'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(img_capture_result[img_capture_result['operation']=='Imaging'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_plan_data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run till here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "memory_plot_df = result_dict['combined_result']\n",
    "\n",
    "#memory_plot_df.columns\n",
    "#memory_plot_df[['SatID','camera_memory_value_endofTW','delta_camera_memory_value_in_this_TW','base_time','OpportunityStartOffset','OpportunityEndOffset#']]\n",
    "memory_plot_df = memory_plot_df[['SatID','start_time','end_time','operation','camera_memory_value_endofTW','delta_camera_memory_value_in_this_TW','base_time']]\n",
    "memory_plot_df.sort_values(by=['SatID','start_time'],inplace=True)\n",
    "\n",
    "memory_plot_df['till_now_max'] = memory_plot_df.groupby('SatID')['end_time'].cummax()\n",
    "memory_plot_df['prev_max'] = memory_plot_df.groupby('SatID')['till_now_max'].shift(1)\n",
    "\n",
    "memory_plot_df1 = memory_plot_df[memory_plot_df['start_time'] > memory_plot_df['prev_max'] + 1] \n",
    "memory_plot_df1['start_time1'] = memory_plot_df1['prev_max'] + 1 #TODO1 +1 is okay ?\n",
    "memory_plot_df1['end_time1'] = memory_plot_df1['start_time'] - 1\n",
    "memory_plot_df1['operation'] = 'idle'\n",
    "\n",
    "memory_plot_df1 = memory_plot_df1[['SatID','start_time1','end_time1','operation','base_time']]\n",
    "\n",
    "#memory_plot_df1 = memory_plot_df1.drop(['start_time', 'end_time','till_now_max','prev_max'], axis=1)\n",
    "memory_plot_df1.rename(columns={'start_time1':'start_time','end_time1':'end_time'},inplace=True)\n",
    "#imgGS_union_df1 ==> contains TW without img and without gs pass  table without eclipse divide\n",
    "final_memory_plot_df = pd.concat([memory_plot_df,memory_plot_df1])\n",
    "final_memory_plot_df.sort_values(by=['SatID','start_time'],inplace=True)\n",
    "\n",
    "final_memory_plot_df['camera_memory_value_endofTW'] = final_memory_plot_df['camera_memory_value_endofTW'].ffill()\n",
    "final_memory_plot_df['delta_camera_memory_value_in_this_TW'] = final_memory_plot_df['delta_camera_memory_value_in_this_TW'].fillna(0)\n",
    "final_memory_plot_df['start_time'] = final_memory_plot_df[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "final_memory_plot_df['end_time'] = final_memory_plot_df[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "final_memory_plot_df = final_memory_plot_df[['SatID','start_time','end_time','camera_memory_value_endofTW','delta_camera_memory_value_in_this_TW','operation','base_time']]\n",
    "sat_list = final_memory_plot_df['SatID'].unique()\n",
    "#sat_list = ['FF01']\n",
    "\n",
    "\n",
    "colors = {\n",
    "        \"Imaging\": \"blue\",\n",
    "        \"downlinking_from_Readout\": \"green\",\n",
    "        \"Readout\": \"red\",\n",
    "        \"idle\": \"gray\"\n",
    "    }\n",
    "\n",
    "\n",
    "for s in sat_list:\n",
    "    this_plot_df = final_memory_plot_df[final_memory_plot_df['SatID']==s]\n",
    "    start_time_list = this_plot_df['start_time'].to_list()\n",
    "    end_time_list = this_plot_df['end_time'].to_list()\n",
    "    operation_list = this_plot_df['operation'].to_list()\n",
    "\n",
    "    camera_memory_value_endofTW_list = this_plot_df['camera_memory_value_endofTW'].to_list()\n",
    "    this_plot_df['camera_memory_value_startofTW_list'] = this_plot_df['camera_memory_value_endofTW'].shift(1)\n",
    "\n",
    "    first_row_list = this_plot_df.values.tolist()[0]\n",
    "    first_row_operation = first_row_list[5]\n",
    "    first_row_memory_val = first_row_list[3]\n",
    "    ortherwise_memory_val =  first_row_list[3] - first_row_list[4]\n",
    "    if first_row_operation not in['Imaging','Readout']:\n",
    "        this_plot_df['camera_memory_value_startofTW_list'] = this_plot_df['camera_memory_value_startofTW_list'].fillna(first_row_memory_val)\n",
    "    else:\n",
    "        this_plot_df['camera_memory_value_startofTW_list'] = this_plot_df['camera_memory_value_startofTW_list'].fillna(ortherwise_memory_val)\n",
    "\n",
    "    camera_memory_value_StartofTW_list = this_plot_df['camera_memory_value_startofTW_list'].to_list()\n",
    "    \n",
    "    time_list = list(itertools.chain.from_iterable(zip(start_time_list,end_time_list )))\n",
    "    operation_list = list(itertools.chain.from_iterable(zip(operation_list,operation_list )))\n",
    "    camera_memory_value_list = list(itertools.chain.from_iterable(zip(camera_memory_value_StartofTW_list,camera_memory_value_endofTW_list )))\n",
    "    df = pd.DataFrame({'time':time_list,'operation':operation_list,'memory':camera_memory_value_list})\n",
    "\n",
    "    this_list = this_plot_df.values.tolist()\n",
    "    # Plot using Plotly Express\n",
    "    # fig = px.line(this_plot_df, x='start_time', y='camera_memory_value_endofTW', color='operation', line_group='operation',\n",
    "    #             title=\"Memory Usage of Different Operations\")\n",
    "    \n",
    "    # fig.add_trace(go.Scatter(\n",
    "    #                         x=time_list,\n",
    "    #                         y=camera_memory_value_list,\n",
    "    #                         mode='lines+markers+text',\n",
    "    #                         #name=operation_list,\n",
    "    #                         #line=dict(color=colors.get(operation, 'black'), width=2),\n",
    "    #                         #text=[f\"({start_time}, {current_memory:.2f})\", f\"({end_time}, {end_memory:.2f})\"],\n",
    "    #                         #textposition=text_position\n",
    "    #                     ))\n",
    "    \n",
    "    # fig.show()\n",
    "    \n",
    "    for item in this_list:\n",
    "            start_time = item[1]\n",
    "            end_time = item[2]\n",
    "            current_memory = item[6]\n",
    "            end_memory = item[3]\n",
    "            operation = item[5]\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                            x=[start_time, end_time],\n",
    "                            y=[current_memory, end_memory],\n",
    "                            mode='lines+markers+text',\n",
    "                            name=operation+'_'+s,\n",
    "                            line=dict(color=colors.get(operation, 'black'), width=2),\n",
    "                            #text=[f\"({start_time}, {current_memory:.2f})\", f\"({end_time}, {end_memory:.2f})\"],\n",
    "                            #textposition=text_position\n",
    "                        ))\n",
    "\n",
    "    #     # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"Memory Profile Over Time\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Memory\",\n",
    "        legend_title=\"Operations\",\n",
    "          )\n",
    "    # names = set()\n",
    "    # fig.for_each_trace(\n",
    "    #     lambda trace:\n",
    "    #         trace.update(showlegend=False)\n",
    "    #         if (trace.name in names) else names.add(trace.name))\n",
    "\n",
    "    # Save figure as HTML\n",
    "    html_filename = \"memory_profile_.html\"\n",
    "    fig.write_html('5_output_data'+'/'+html_filename)\n",
    "\n",
    "# final_memory_plot_df[final_memory_plot_df['SatID']=='FF01'].sort_values(by='start_time')\n",
    "\n",
    "import pygwalker as pyg\n",
    "pyg.walk(final_memory_plot_df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import os\n",
    "from preprocess_1.preprocess_GSpassSelecion import GSPassPreprocess\n",
    "from model_3.MILP_GSpassSelection_v3 import GSpassSelection\n",
    "from postprocess_4.postprocess_GSpassSelection import GSpasspostprocess\n",
    "\n",
    "from preprocess_1.preprocess_imageAqusuition_test import ImageAquisitionProcess #preprocess_imageAqusuition_test,preprocess_imageAquisition_v3_18112024\n",
    "from model_3.MILP_imageCapture_v3_17112024 import ImageCapturePlan # MILP_imageCapture_v2_16102024,MILP_imageCapture_v2_25102024 # MILP_imageCapture_v2_07112024 #MILP_imageCapture_v3_17112024\n",
    "from postprocess_4.image_capture_postprocess_V3_17112024 import ImagecapturePostProcess # image_capture_postprocess_V3_17112024# image_capture_postprocess_v2_18102024\n",
    "\n",
    "from preprocess_1.preprocess_downlink_WIP import DownlinkingPreProcess\n",
    "from model_3.MILP_downlink import ImageDownlinkPlan\n",
    "from postprocess_4.postprocess_downlink import ImageDownlinkPostProcess\n",
    "\n",
    "from result_interpret import interpret_result\n",
    "from utils import *\n",
    "\n",
    "# script_dir = os.path.abspath( os.path.dirname( __file__ ) )\n",
    "# print(\"script directory: \",script_dir)\n",
    "'''\n",
    "readout is happening after the last image and before entering the eclipse region.\n",
    "Any heating operation will start if the temp reaches around intial tempertaure.\n",
    "Higher number of Global priority is assumed to be Higher prior Important image.\n",
    "if end date of due date is less than 24 hrs from the reference time offset then it is going to assured tasking.\n",
    "Need offset from when scheduling is started. Example if scheduling is  needed from 10:00AM to 11 PM . Then offset is needed from 10:00 AM or 09:59 AM. Due date based assured tasking is the reason.\n",
    "Iniial Camera Memory is needed at the start of the any oppr imaging/gsPass whichever is first. \n",
    "Iniial Readout Memory is needed at the start of the readout oppr.\n",
    "Initial power is needed at start of the opportunity(imaging/gspass).For Now (since power constraint is not there for readout)\n",
    "Iniial thermal value is needed before the start of the oppr imaging/gsPass/readout according to device (for NCCms:readout , for camera detector: Imaging ,For XBT : gs Pass oppr).\n",
    "Eclipse Event should be starting from first oppr either gsPass/Imaging. Readout is happening after the first imaging so i guess not needed at readout.\n",
    "'''\n",
    "'''\n",
    "Need offset from when scheduling is started. Example if scheduling is  needed from 10:00AM to 11 PM . Then offset is needed from 10:00 AM or 09:59 AM.\n",
    "Iniial Memory,power and thermal value is needed at 10:00 AM\n",
    "'''\n",
    "def select_gs_pass_oppr(GS_pass_df,config):\n",
    "\n",
    "    obj_preprocess = GSPassPreprocess(GS_pass_df)\n",
    "    data = obj_preprocess.preprocess()\n",
    "\n",
    "    obj_model = GSpassSelection(data,config)\n",
    "    result,thermal_profile_gsPass = GSpasspostprocess(obj_model,data,config).get_gsPasses()# 21 seconds\n",
    "\n",
    "    try :\n",
    "        result['duration'] = result['end_time'] - result['start_time']\n",
    "        result = result[result['duration']> 0]\n",
    "    except:\n",
    "        print(\"model is not converged or infeasible or not solved\")\n",
    "\n",
    "    return result\n",
    "    \n",
    "\n",
    "def select_img_opprtunity(image_opportunity_df,gs_pass_result_df,eclipse_df_dict,config):\n",
    "\n",
    "    #basic flters\n",
    "    #image_opportunity_df = image_opportunity_df[image_opportunity_df['OpportunityEndOffset']<config['scheduled_Hrs']*3600]\n",
    "    image_opportunity_df = image_opportunity_df[image_opportunity_df['CloudCoverLimit']>image_opportunity_df['CloudCover']]\n",
    "    image_opportunity_df = image_opportunity_df[image_opportunity_df['OffNadirLimit']>image_opportunity_df['OffNadir']]\n",
    "\n",
    "    obj_preprocess = ImageAquisitionProcess(image_opportunity_df,gs_pass_result_df,eclipse_df_dict,config)\n",
    "    data = obj_preprocess.preprocess()\n",
    "    #print(data['cs1j2k2Domainlist__cs1j1k1'])\n",
    "\n",
    "    #++++++++++++++++++++++++++  STEP 0  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    '''\n",
    "    hard code some data\n",
    "    '''\n",
    "    data['camera_memory_capacity__s'] = {s:v for s,v in data['camera_memory_capacity__s'].items() }\n",
    "    data['readout_memory_capacity__s'] = {s:v for s,v in data['readout_memory_capacity__s'].items() }\n",
    "    data['power_capacity__s']  = {s:720000000 for s,v in data['power_capacity__s'].items() }\n",
    "    data['initial_power_value__s']  = {s:v*0.3 for s,v in data['power_capacity__s'].items() }\n",
    "    #++++++++++++++++++++++++++  STEP 1  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    config['objective']['GS_Pass_time'] = True\n",
    "    config['objective']['total_priority'] = False\n",
    "    config['objective']['total_readout_memory'] = False\n",
    "    obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    #Readout Schedule \n",
    "    # data['GS_Pass_time_objective'] = obj_model.prob.objective.value()\n",
    "    # config['objective']['GS_Pass_time'] = False\n",
    "    # config['objective']['total_priority'] = False\n",
    "    # config['objective']['total_readout_memory'] = True\n",
    "    # obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    #++++++++++++++++++++++++++  STEP 2  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    # config['objective']['GS_Pass_time'] = False\n",
    "    # config['objective']['total_priority'] = True\n",
    "    # #config['objective']['total_readout_memory'] = False\n",
    "\n",
    "    # obj_model = ImageCapturePlan(data,config)\n",
    "\n",
    "    # data['total_priority_objective'] = obj_model.prob.objective.value()\n",
    "    #++++++++++++++++++++++++++  STEP 3  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    # config['objective']['total_priority'] = False\n",
    "    # config['objective']['total_readout_memory'] = True\n",
    "\n",
    "    # obj_model = ImageCapturePlan(data,config)\n",
    "    #++++++++++++++++++++++++++  PostProcess  +++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    post_obj = ImagecapturePostProcess(obj_model,data)\n",
    "    img_capture_result= post_obj.get_schedule()\n",
    "    #.isnull().sum()\n",
    "    return img_capture_result,data\n",
    "    \n",
    "\n",
    "    #======================================================================================================================================================================================================\n",
    "\n",
    "    pass\n",
    "\n",
    "def get_aps_success_metric(img_capture_result,data):\n",
    "    after_aps_plan_df = img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "    criteria_list = ['total_opprtunities_ratio','GP_ratio','LP_ratio','conflictImg_gsPass']\n",
    "\n",
    "    total_conflict_images_list= [data['success_metric_before']['conflict_images']]\n",
    "    GP_before = data['success_metric_before']['original_Total_GP']\n",
    "    LP_before = data['success_metric_before']['original_Total_LP']\n",
    "    TOppr_before = data['success_metric_before']['total_opportunities'] \n",
    "    before_list = [TOppr_before,GP_before,LP_before,total_conflict_images_list]\n",
    "\n",
    "    GP_after= after_aps_plan_df['mean_global_priority'].sum()\n",
    "    LP_after = after_aps_plan_df['mean_local_priority'].sum()\n",
    "    TOppr_after= after_aps_plan_df['encoded_strip_id'].nunique()\n",
    "    fraction_conflict_images_list = [list(after_aps_plan_df[after_aps_plan_df['encoded_strip_id'].isin(total_conflict_images_list)]['encoded_strip_id'].unique())]\n",
    "    after_list = [TOppr_after,GP_after,LP_after,fraction_conflict_images_list]\n",
    "\n",
    "    APS_success_metric_df = pd.DataFrame({'criteria':criteria_list,'potential_input':before_list,'APS_selected':after_list})\n",
    "    #APS_success_metric_df['percentage'] = APS_success_metric_df['APS_selected'] / APS_success_metric_df['potential_input']\n",
    "    APS_success_metric_df1 = APS_success_metric_df[:-1]\n",
    "    APS_success_metric_df1['percentage'] = APS_success_metric_df1['APS_selected'] / APS_success_metric_df1['potential_input'] * 100\n",
    "    APS_success_metric_df2 = APS_success_metric_df[-1:]\n",
    "\n",
    "    APS_success_metric_df = pd.concat([APS_success_metric_df1,APS_success_metric_df2])\n",
    "\n",
    "    return APS_success_metric_df\n",
    "    \n",
    "\n",
    "def get_downlink_schedule(image_downlink_df,img_capture_result,config):\n",
    "\n",
    "    downlink_operation_list  = ['downlinking_from_camera','downlinking_from_Readout']\n",
    "    img_capture_result_downlink = img_capture_result[img_capture_result['operation'].isin(downlink_operation_list)]\n",
    "    DownlinkingPreProcessObj = DownlinkingPreProcess(image_downlink_df,img_capture_result_downlink,config)\n",
    "    data_downlink = DownlinkingPreProcessObj.preprocess()\n",
    "    \n",
    "    if config['downlink_schedule_OnlyJustsortImgID']:\n",
    "        downlink_result = pd.DataFrame(data_downlink['LP_DD_Priority_imgID'].items(),columns=['ImageID','computed_priority']).\\\n",
    "            sort_values(by='computed_priority',ascending=False)\n",
    "    else:\n",
    "        obj_downlink_model = ImageDownlinkPlan(data_downlink,config)\n",
    "        downlink_result = ImageDownlinkPostProcess(obj_downlink_model,data_downlink).get_schedule()\n",
    "        downlink_result = downlink_result[downlink_result['TileStripNo_downLoad']!=0]\n",
    "\n",
    "    return downlink_result\n",
    "    \n",
    "def schedule():\n",
    "\n",
    "    pass\n",
    "\n",
    "def get_input_files(config):\n",
    "    # GS PASS\n",
    "    #GS_pass_df = pd.read_csv(config[\"csv_file_path\"][\"gs_pass_opportunity\"])#APS_gsPasses_TV1#GS_Passes_mock1#GS_Passes_live1#GS_Passes_new (1)\n",
    "    \n",
    "    GS_pass_df = pd.read_csv(\"1_input_data/GS_Passes_new (1).csv\")\n",
    "    GS_pass_df['SatID'] = GS_pass_df['SatID'].astype(str)\n",
    "    GS_pass_df['AOSOffset'] = GS_pass_df['AOSOffset'].astype(int)\n",
    "    GS_pass_df['LOSOffset'] = GS_pass_df['LOSOffset'].astype(int)\n",
    "\n",
    "    # image Opprtunity\n",
    "    image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])#Imaging_mock1#APS_imagingOpportunities_TV1#Imaging_live#Imaging_new (1)\n",
    "    # change made priority ulta\n",
    "    #image_opportunity_df['Priority'] = 1/image_opportunity_df['Priority']\n",
    "    \n",
    "    image_opportunity_df['SatID'] = image_opportunity_df['SatID'].astype(str)\n",
    "    image_opportunity_df['OpportunityStartOffset'] = image_opportunity_df['OpportunityStartOffset'].astype(int)\n",
    "    image_opportunity_df['OpportunityEndOffset'] = image_opportunity_df['OpportunityEndOffset'].astype(int)\n",
    "    image_opportunity_df_copy = image_opportunity_df.copy()\n",
    "    image_opportunity_df_copy['X'] = image_opportunity_df_copy[['OpportunityStartTime','OpportunityStartOffset']].apply(lambda a: pd.to_datetime(a['OpportunityStartTime']) - pd.DateOffset(seconds=a['OpportunityStartOffset']),axis=1)\n",
    "    image_opportunity_df_copy['Y'] = image_opportunity_df_copy[['OpportunityEndTime','OpportunityEndOffset']].apply(lambda a: pd.to_datetime(a['OpportunityEndTime']) - pd.DateOffset(seconds=a['OpportunityEndOffset']),axis=1)\n",
    "    base_time_stamp = image_opportunity_df_copy[\"X\"].to_list()[0]\n",
    "    config['base_time_stamp_downlink'] = base_time_stamp\n",
    "\n",
    "    #image Downlink\n",
    "    image_downlink_df = pd.read_csv(config[\"csv_file_path\"][\"image_downlink_file\"])\n",
    "    image_downlink_df['assured_downlink_flag'] = [0,0] +[0]*(len(image_downlink_df)-2)\n",
    "    image_downlink_df['delivery_type'] = 'standard_delivery' # expedited_delivery,super_expedited_delivery\n",
    "    union_list_of_sat = list(set(image_opportunity_df['SatID']).union(set(GS_pass_df['SatID'])).union(set(image_downlink_df['SatID'])))\n",
    "    hrs = config['scheduled_Hrs']\n",
    "\n",
    "    # get dummy eclipse data close to reality\n",
    "    #eclipse_df = pd.DataFrame()\n",
    "    #for sat in satellite_list:\n",
    "        #this_eclipse_df = eclipse_event_df[eclipse_event_df['SatID']==sat]\n",
    "        #that_eclipse_df = get_eclipse_data(this_eclipse_df,config)\n",
    "        #eclipse_df = pd.concat([that_eclipse_df,eclipse_df])\n",
    "        \n",
    "    min_time_index= min([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "    max_time_index= max([image_opportunity_df['OpportunityStartOffset'].min(),image_opportunity_df['OpportunityEndOffset'].max(),GS_pass_df['AOSOffset'].min(),GS_pass_df['LOSOffset'].max()])\n",
    "\n",
    "    hrs = (max_time_index - min_time_index)/3600\n",
    "    hrs = math.ceil(hrs)\n",
    "    while True:\n",
    "        hrs += 1\n",
    "        if hrs % 1.5==0:\n",
    "            break\n",
    "\n",
    "\n",
    "    in_orbit_eclipse_event = [1 for i in range(int(1.5*3600*0.6))] + [0 for i in range(int(1.5*3600*0.4))] #\n",
    "    eclipse_df  = pd.DataFrame({'time_index': [i for i in range(min_time_index,min_time_index+hrs*3600)] ,\"eclipse\" : in_orbit_eclipse_event*int(hrs/1.5)})\n",
    "    eclipse_df['SatID']= [union_list_of_sat] *len(eclipse_df)\n",
    "    eclipse_df = eclipse_df.explode('SatID')\n",
    "    eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "\n",
    "    #eclipse_df = pd.DataFrame()\n",
    "    #for sat in satellite_list:\n",
    "        #this_eclipse_df = eclipse_event_df[eclipse_event_df['SatID']==sat]\n",
    "        #that_eclipse_df = get_eclipse_data(this_eclipse_df,config)\n",
    "        #eclipse_df = pd.concat([that_eclipse_df,eclipse_df])\n",
    "   #eclipse_df_dict = {s: eclipse_df[eclipse_df['SatID']==s] for s in eclipse_df['SatID'].unique()}\n",
    "\n",
    "    \n",
    "    # get dummy data for assured tasking\n",
    "    image_opportunity_df['encoded_stripId'] =   image_opportunity_df['StripID'].astype(str)+ '_' + image_opportunity_df['AoiID'].astype(str)\n",
    "    total_capture_list = list(image_opportunity_df['encoded_stripId'].unique())\n",
    "    no_of_list = len(total_capture_list)\n",
    "    assured_capture_df = pd.DataFrame({'encoded_stripId':total_capture_list,'assured_task':[0,0]+[0]*(no_of_list-2)})\n",
    "    image_opportunity_df = pd.merge(image_opportunity_df,assured_capture_df,on='encoded_stripId',how='left')\n",
    "    image_opportunity_df = image_opportunity_df.drop(columns=['encoded_stripId'])\n",
    "\n",
    "    # further processing eclipse data to align with gs pass where entire gs pass is assumed to be in eclipse region\n",
    "    gsPassInput_df_copy = pd.read_csv(config[\"csv_file_path\"][\"gs_pass_opportunity\"])\n",
    "    gsPassInput_df_copy['SatID'] = gsPassInput_df_copy['SatID'].astype(str)\n",
    "    gsPassInput_df_copy['AOSOffset'] = gsPassInput_df_copy['AOSOffset'].astype(int)\n",
    "    gsPassInput_df_copy['LOSOffset'] = gsPassInput_df_copy['LOSOffset'].astype(int)\n",
    "    gsPassInput_df_copy['list'] =  gsPassInput_df_copy[['AOSOffset','LOSOffset']].apply(lambda a : [i for i in range(a['AOSOffset'],a['LOSOffset']+1)],axis =1 )\n",
    "\n",
    "    gsPassInput_df_copy1 = gsPassInput_df_copy[['SatID','list']]\n",
    "    gsPassInput_df_copy1 = gsPassInput_df_copy1.explode('list')\n",
    "    gsPassInput_df_grouped_copy1 = gsPassInput_df_copy1.groupby('SatID').agg(time_index_list = ('list',list)).reset_index()\n",
    "    gsPasstimeIndexList__s = dict(zip(gsPassInput_df_grouped_copy1['SatID'],gsPassInput_df_grouped_copy1['time_index_list']))\n",
    "    for k,v in eclipse_df_dict.items():\n",
    "        if k in gsPasstimeIndexList__s.keys():\n",
    "            this_time_index_list = gsPasstimeIndexList__s[k]\n",
    "            v.loc[v[\"time_index\"].isin(this_time_index_list), \"eclipse\"] = 1\n",
    "            eclipse_df_dict[k] = v\n",
    "\n",
    "    return {\n",
    "            'GS_pass_df':GS_pass_df,\\\n",
    "            'image_opportunity_df':image_opportunity_df,\\\n",
    "            'image_downlink_df':image_downlink_df,\\\n",
    "            \"eclipse_df_dict\": eclipse_df_dict,\n",
    "            \"config\":config\n",
    "            }\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Open and read the JSON file\n",
    "    with open('1_input_data/config.json', 'r') as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "    # if memory constraint False then thermal_constraint is also False\n",
    "        config['constraints']['thermal_constraint_readout'] = config['constraints']['memory_constrant'] and config['constraints']['thermal_constraint_readout']\n",
    "        config['constraints']['thermal_constraint_imaging'] = config['constraints']['memory_constrant'] and config['constraints']['thermal_constraint_imaging']\n",
    "\n",
    "    #======================================================================================================================================================================================================\n",
    "    # read_input\n",
    "    input_dict = get_input_files(config)\n",
    "    config = input_dict['config']\n",
    "    #======================================================================================================================================================================================================\n",
    "    #gs pass_selection\n",
    "    gs_pass_result_df = select_gs_pass_oppr(input_dict['GS_pass_df'],config)\n",
    "    gs_pass_result_df['Eclipse'] = 1 ## dummy\n",
    "    gs_pass_result_df['duration'] = gs_pass_result_df['end_time'] - gs_pass_result_df['start_time']\n",
    "    gs_pass_result_df = gs_pass_result_df[gs_pass_result_df['duration']> 0]\n",
    "    interpret_gs_pass_result_df_copy = gs_pass_result_df.copy()# this not the gsPass result as it is to be get filtered after due to other factors in image capture plan.It is just to get require info in interpret result.\n",
    "\n",
    "    print(\"image_capture_plan_starting\")\n",
    "    #======================================================================================================================================================================================================\n",
    "    #image_selection\n",
    "    img_capture_result,capture_plan_data_input= select_img_opprtunity(input_dict['image_opportunity_df'],gs_pass_result_df,input_dict['eclipse_df_dict'],config)\n",
    "    img_capture_result['base_time'] = config['base_time_stamp_downlink']\n",
    "    #img_capture_result = img_capture_result[img_capture_result['operation']=='Imaging']\n",
    "    #readout_result = img_capture_result[img_capture_result['operation']=='Readout']\n",
    "    interpret_img_capture_resul_copy = img_capture_result.copy()\n",
    "    #======================================================================================================================================================================================================\n",
    "    # get APS success metrics \n",
    "    APS_success_metric_df = get_aps_success_metric(img_capture_result,capture_plan_data_input)\n",
    "    #======================================================================================================================================================================================================\n",
    "    print(\"Downlink_plan_starting\")\n",
    "    try:\n",
    "        print(dfd)\n",
    "        downlink_result = get_downlink_schedule(input_dict['image_downlink_df'],img_capture_result,config)\n",
    "    except:\n",
    "        print(\"downlink_schedule_has_some_error\")\n",
    "        downlink_result = pd.DataFrame()\n",
    "    downlink_result['base_time'] = config['base_time_stamp_downlink']\n",
    "    #======================================================================================================================================================================================================\n",
    "    #img_capture_result[img_capture_result['download_from_']]\n",
    "    gs_pass_result_df.to_csv(\"5_output_data/gs_pass_result_df.csv\",index=None)\n",
    "    img_capture_result.to_csv(\"5_output_data/img_capture_schedule.csv\",index=None)\n",
    "    APS_success_metric_df.to_csv(\"5_output_data/APS_success_metric.csv\",index = None)\n",
    "    downlink_result.to_csv(\"5_output_data/downlink_result.csv\",index = None)\n",
    "\n",
    "    interpret_image_opportunity_df = pd.read_csv(config[\"csv_file_path\"][\"image_capture_opportunity\"])\n",
    "    interpret_result_dict = interpret_result(interpret_image_opportunity_df,interpret_gs_pass_result_df_copy,interpret_img_capture_resul_copy,config)\n",
    "    for k,v in interpret_result_dict.items():\n",
    "        v['base_time'] = config['base_time_stamp_downlink']\n",
    "        v.to_csv(\"5_output_data/\"+k+\".csv\",index = None)\n",
    "\n",
    "    \n",
    "    only_img_capture_result = img_capture_result[img_capture_result['operation']=='Imaging'][['SatID','start_time','end_time','AoiID','StripID','base_time']]\n",
    "    only_img_capture_result['start_time'] = only_img_capture_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "    only_img_capture_result['end_time'] = only_img_capture_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "    only_readout_result = img_capture_result[img_capture_result['operation']=='Readout'][['SatID','start_time','end_time','base_time']]\n",
    "    only_readout_result['start_time'] = only_readout_result[['start_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['start_time']),axis=1)\n",
    "    only_readout_result['end_time'] = only_readout_result[['end_time','base_time']].apply(lambda a: pd.to_datetime(a['base_time']) + pd.DateOffset(seconds=a['end_time']),axis=1)\n",
    "\n",
    "    result_dict = {\"only_readout_result\":only_readout_result,\\\n",
    "                  \"only_img_capture_result\":only_img_capture_result}\n",
    "    result_dict.update(interpret_result_dict)\n",
    "\n",
    "    #print(only_img_capture_result,only_readout_result,downlink_result)\n",
    "#config['constraints'] = ['Thermal_constraints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conflicting_dict(self,df,data_dict,different_setup_time,conflicting_on = 'GsID',concat_filter ='concat_gsid_satid_TWIndex',LOS_column='LOSOffset',AOS_column='AOSOffset'):\n",
    "\n",
    "    for on_item in df[conflicting_on].unique():\n",
    "        this_df = df[df[conflicting_on] == on_item ]\n",
    "        # if different_master_key:\n",
    "        #     data_dict[different_master_key]['sgk_list'] [on_item] = this_df[concat_filter].unique()\n",
    "        for csgk in this_df[concat_filter].unique():\n",
    "            that_df = this_df[this_df[concat_filter] == csgk]\n",
    "            this_LOS = list(that_df[LOS_column].unique())[0]\n",
    "            this_AOS = list(that_df[AOS_column].unique())[0]\n",
    "\n",
    "\n",
    "            that_df1 = this_df[this_df[AOS_column] >= different_setup_time  + this_LOS]\n",
    "            that_df2 = this_df[this_df[LOS_column] <= this_AOS - different_setup_time]\n",
    "            that_df3 = pd.concat([that_df1,that_df2])\n",
    "            \n",
    "            not_needed = list(that_df3[concat_filter].unique())\n",
    "            that_df = this_df[~this_df[concat_filter].isin(not_needed)]\n",
    "\n",
    "            that_df = that_df[that_df[concat_filter] != csgk]\n",
    "\n",
    "            # if different_master_key:\n",
    "            #     data_dict[different_master_key]['domain_of_csgk'] [csgk] = list(that_df[concat_filter].unique())\n",
    "            # else:\n",
    "            data_dict[csgk] = list(that_df[concat_filter].unique())\n",
    "                \n",
    "    return data_dict \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def evaluate_eqn(t,temp_eqn):\n",
    "    t = t\n",
    "    return eval(temp_eqn)\n",
    "\n",
    "\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "heat_eqn = \"0.0000000728690314 * t**3 - 0.000138692964 * t**2 + 0.103057817 * t  + 1.88504399 \"\n",
    "# y = \"math.exp(x)\"\n",
    "T = 25\n",
    "initial_temp = 25\n",
    "limit_temp = initial_temp + 3\n",
    "\n",
    "\n",
    "a20 = -13.339128\t\n",
    "b20 = 0.504271\t\n",
    "c20 = 0.581774\n",
    "\n",
    "a40 = -13.503356\t\n",
    "b40 = 0.655062\t\n",
    "c40 = 0.397629\n",
    "\n",
    "y20 = 54.9\n",
    "y40 = 70.6\n",
    "\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    " \n",
    "Y = [[-13.339128,-13.503356],[0.504271,0.655062],[0.581774,0.397629],[y20,y40]]\n",
    "X = [[20,40],[20,40],[20,40],[20,40]]\n",
    " \n",
    "# test value\n",
    "interpolate_x = initial_temp\n",
    " \n",
    "# Finding the interpolation\n",
    "l1 =[]\n",
    "for i in range(4):\n",
    "    y_interp = interp1d(X[i], Y[i])\n",
    "    l1.append(y_interp(interpolate_x))\n",
    "\n",
    "# print(\"Value of Y at x = {} is\".format(interpolate_x),\n",
    "#       y_interp(interpolate_x))\n",
    "cool_eqn = str(l1[2])+\"*math.exp(1*t*\"+str(l1[0])+\")+\"+str(l1[1])\n",
    "x = 2\n",
    "#eval(y)\n",
    "temp_profile_df = pd.DataFrame()\n",
    "for i in range(1):\n",
    "    df = pd.DataFrame({\"time_index\":[i for i in range(1,T*60)]})\n",
    "    df['epoch'] = str(i)+'_'+'heat'\n",
    "    df['delta_temp_heat'] = df['time_index'].apply(lambda a:evaluate_eqn(a,temp_eqn = heat_eqn) ) \n",
    "    df['initial_temp'] =  initial_temp\n",
    "    df['temp']=df['delta_temp_heat']  + df['initial_temp']\n",
    "    df = df[df['temp']<=70]\n",
    "    #print(df)\n",
    "    max_heat_temp = df['temp'].max()\n",
    "    print(max_heat_temp)\n",
    "    df_cool = pd.DataFrame({\"time_index\":[i for i in range(1,T*60)]})\n",
    "    df_cool['epoch'] = str(i)+'_'+'cool'\n",
    "    df_cool[\"time_index_new\"] = df_cool[\"time_index\"]/1800\n",
    "    df_cool['delta_temp'] = df_cool['time_index_new'].apply(lambda a:evaluate_eqn(a,temp_eqn = cool_eqn) ) \n",
    "    df_cool['y'] = df_cool['delta_temp']\n",
    "    df_cool['delta_temp'] = df_cool['delta_temp']* l1[3]\n",
    "    df_cool['initial_temp'] = max_heat_temp\n",
    "    df_cool['temp'] = df_cool['initial_temp'] - df_cool['delta_temp'] \n",
    "\n",
    "    df_cool['temp'] = df_cool['delta_temp']#* l1[3]\n",
    "    \n",
    "    df_cool_check = df_cool[df_cool['temp']<= limit_temp]\n",
    "    cooled_upto = df_cool_check['temp'].max()\n",
    "    #df_cool = df_cool[df_cool['temp']>=limit_temp]\n",
    "    initial_temp = cooled_upto\n",
    "    \n",
    "    this_df = pd.concat([df,df_cool])\n",
    "    temp_profile_df = pd.concat([temp_profile_df,this_df])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# df[\"time_index_new\"] = df[\"time_index\"]/60/1800\n",
    "# df['delta_temp'] = df['time_index_new'].apply(lambda a:evaluate_eqn(a,temp_eqn = cool_eqn) ) \n",
    "# #\n",
    "# xs = np.arange(10)\n",
    "# ys = 2*xs + 1\n",
    "\n",
    "# interp_func = interp1d(xs, ys)\n",
    "\n",
    "# newarr = interp_func(np.arange(2.1, 3, 0.1))\n",
    "\n",
    "# print(newarr)\n",
    "# eval(Y, globals, locals)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_eqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df#[df['time_index']<=25*60]\n",
    "df_cool['delta_temp'].max()\n",
    "df_cool\n",
    "temp_profile_df\n",
    "df_cool\n",
    "#df#[df['time_index']==1499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_profile_df[temp_profile_df['epoch']=='1_cool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"math.exp(x)\"\n",
    "x = 1\n",
    "eval(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
